**Table of Contents**

*   Cover
*   Table of Contents
*   Title Page
*   Copyright
*   Dedication
*   Acknowledgments
*   Introduction
*   Notation
*   Chapter 1: The Map and the Territory
    *   1.1 The Securities
    *   1.2 Modes of Exchange
    *   1.3 Who Are the Market Participants?
    *   1.4 Where Do Excess Returns Come From?
    *   1.5 The Elements of Quantitative Investing
*   Chapter 2: Univariate Returns
    *   2.1 Returns
    *   2.2 Conditional Heteroskedastic Models
    *   2.3 State-Space Estimation of Variance
    *   2.4 Appendix
*   Chapter 3: Interlude: What Is Performance?
    *   3.1 Expected Return
    *   3.2 Volatility
    *   3.3 Sharpe Ratio
    *   3.4 Capacity
*   Chapter 4: Linear Models of Returns
    *   4.1 Factor Models
    *   4.2 Interpretations of Factor Models
    *   4.3 Alpha Spanned and Alpha Orthogonal
    *   4.4 Transformations
    *   4.5 Applications
    *   4.6 Factor Models Types
    *   4.7 Appendix
    *   4.8 Exercises
*   Chapter 5: Evaluating Risk
    *   5.1 Evaluating the Covariance Matrix
    *   5.2 Evaluating the Precision Matrix
    *   5.3 Ancillary Tests
    *   5.4 Appendix
*   Chapter 6: Fundamental Factor Models
    *   6.1 The Inputs and the Process
    *   6.2 Cross-Sectional Regression
    *   6.3 Estimating the Factor Covariance Matrix
    *   6.4 Estimating the Idiosyncratic Covariance Matrix
    *   6.5 Winsorization of Returns
    *   6.6 Advanced Model Topics
    *   6.7 A Tour of Factors
*   Chapter 7: Statistical Factor Models
    *   7.1 Statistical Models: The Basics
    *   7.2 Beyond the Basics
    *   7.3 Real-Life Stylized Behavior of PCA
    *   7.4 Interpreting Principal Components
    *   7.5 Statistical Model Estimation in Practice
    *   7.6 Appendix
*   Chapter 8: Evaluating Excess Returns
    *   8.1 Backtesting Best Practices
    *   8.2 The Backtesting Protocol
    *   8.3 The Rademacher Anti-Serum (RAS)
    *   8.4 Some Empirical Results
    *   8.5 Appendix
*   Chapter 9: Portfolio Management: The Basics
    *   9.1 Why Mean-Variance Optimization?
    *   9.2 Mean-Variance Optimal Portfolios
    *   9.3 Trading in Factor Space
    *   9.4 Trading in Idio Space
    *   9.5 Drivers of Information Ratio: Information Coefficient and Diversification
    *   9.6 Aggregation: Signals versus Portfolios
    *   9.7 Appendix
*   Chapter 10: Beyond Simple Mean Variance
    *   10.1 Shortcomings of Naive MVO
    *   10.2 Constraints and Modified Objectives
    *   10.3 How Does Estimation Error Affect the Sharpe Ratio?
    *   10.4 Appendix
*   Chapter 11: Market Impact-Aware Portfolio Management
    *   11.1 Market Impact
    *   11.2 Finite-Horizon Optimization
    *   11.3 Infinite-Horizon Optimization
    *   11.4 Appendix
*   Chapter 12: Hedging
    *   12.1 Toy Story
    *   12.2 Factor Hedging
    *   12.3 Hedging Tradeable Factors with Time Series Betas
    *   12.4 Factor-Mimicking Portfolios of Time Series
    *   12.5 Appendix
*   Chapter 13: Dynamic Risk Allocation
    *   13.1 The Kelly Criterion
    *   13.2 Mathematical Properties
    *   13.3 The Fractional Kelly Strategy
    *   13.4 Fractional Kelly and Drawdown Control
*   Chapter 14: Ex-Post Performance Attribution
    *   14.1 Performance Attribution: The Basics
    *   14.2 Performance Attribution with Errors
    *   14.3 Maximal Performance Attribution
    *   14.4 Selection versus Sizing Attribution
    *   14.5 Appendix
*   Chapter 15: A Coda ad Laborem
*   References
*   Index
*   End User License Agreement

---

**List of Illustrations**

*   Chapter 1:
    *   Figure 1.1 Frank Zappa’s Sideburn #1, page 9 (1977). Source: Dack.com/Zappa
    *   Figure 1.2 Chapter dependencies.
    *   Figure 1.3 The components of the investment process.
*   Chapter 2:
    *   Figure 2.1 Autocorrelation plots of daily log return series (symbols)...
    *   Figure 2.2 Quantile-Quantile plot for daily log returns (light gray dots) and GA...
    *   Figure 2.3 Relationship between K and κ := τ_v²/τ_w²
*   Chapter 4:
    *   Figure 4.1 A typical loadings matrix, partitioned into different blocks. The st...
    *   Figure 4.2 Factor models as graphical models.
    *   Figure 4.3 A factor model as the superposition of weighted factor loadings.
    *   Figure 4.4 Factor models as scalar products of per-stock loadings and factor re...
    *   Figure 4.5 A Singular Value Decomposition, full form.
    *   Figure 4.6 Singular Value Decomposition as a sequence of steps: rota...
*   Chapter 5:
    *   Figure 5.1 QLIKE and MSE comparison. Notice that QLIKE is skewed, with higher l...
*   Chapter 6:
    *   Figure 6.1 Clusters for idiosyncratic matrix.
    *   Figure 6.2 Left: credit-equity-linked factor covariance matrix. Right: country-...
*   Chapter 7:
    *   Figure 7.1 The eigenvectors associated with identical eigenvalues are not uniquely...
    *   Figure 7.2 (a) Probabilistic PCA for a universe of 1000 assets, with 10 factors...
    *   Figure 7.3 We estimate the risk model parameters using data in an interval of...
    *   Figure 7.4 (a) 1000 assets, normally distributed returns; (b) 1000 assets, t-di...
    *   Figure 7.5 Variances of the eigenvalues (normalized to the variance of the first)...
    *   Figure 7.6 Cumulative percentage of variance described by the first m factors,...
    *   Figure 7.7 Eigenvector turnover for different covariance matrices. Top: total...
    *   Figure 7.8 Distances between column subspaces of the first eight eigenvectors in...
    *   Figure 7.9 L₂ factor turnover for the first four eigenvectors. The eigenvectors are...
*   Chapter 8:
    *   Figure 8.1 A scheme of the cross-validation procedure. Dashed boxes are validat...
    *   Figure 8.2 A scheme of the cross-validation procedure. Data is split into two...
    *   Figure 8.3 Cross-validated Sharpe for (a) Scenario 1, (b) Scenario 2.
    *   Figure 8.4 Two common walk-forward schemes. The top one uses fixed-length trai...
    *   Figure 8.5 Rademacher complexity for poor strategies, with iid Gaussian returns...
*   Chapter 9:
    *   Figure 9.1 Left: the decentralized solution to portfolio combination. Right: th...
*   Chapter 10:
    *   Figure 10.1 Level plots of the loss of PnL (and Sharpe Ratio) as a function of...
    *   Figure 10.2 Fraction loss in Sharpe ratio for two strategies with Sharpe Ratios...
*   Chapter 11:
    *   Figure 11.1 Market impact over time for a single trade executed at time t₀...
    *   Figure 11.2 Market impact over time. The dashed line is the permanent market im...
*   Chapter 13:
    *   Figure 13.1 Cumulative returns under the dynamic and static policies. All the cu...
    *   Figure 13.2 (a) Time series of cumulative returns for different fractions of the...
    *   Figure 13.3 Expected value of the log of the single-period growth, which is max...
    *   Figure 13.4 The optimal Kelly size in the presence of parameter uncertainty is a...
    *   Figure 13.5 Percentage reduction factor (1 – D)/(1 – d_k).
    *   Figure 13.6 Comparison of fractional Kelly and Grossman–Zhou strategies. Both st...
*   Chapter 14:
    *   Figure 14.1 Top: PnL from factor performance attribution. Bottom: Maximal attrib...
    *   Figure 14.2 A taxonomy of performance attribution.

---

**List of Tables**

*   Chapter 2:
    *   Table 2.1 Sample skewness and kurtosis of daily log returns and (*italic p* equals 0.01)...
    *   Table 2.2 Distances between the theoretical normal distribution and the empir...
    *   Table 2.3 Estimated tail index for left and right tail of probability density func...
*   Chapter 6:
    *   Table 6.1 Ticker and company names of cluster components in Figure 6.1.
*   Chapter 7:
    *   Table 7.1 Summary of impact of High Factor Turnover
*   Chapter 8:
    *   Table 8.1 Backtesting results for the two simulated scenarios; the conversion...
    *   Table 8.2 Comparison of R̂ and Massart’s bound
    *   Table 8.3 Simulations for normally distributed returns
    *   Table 8.4 Simulations for t-distributed returns
    *   Table 8.5 Summary data for the factors in Jensen et al.’s database
    *   Table 8.6 Summary data for the factors in Zimmermann and Chen’s database
   

Okay, I will extract the text from the provided screenshots and compile it into a single Markdown file, maintaining the order and attempting to capture formatting like headings and lists.

```markdown
Everand

**Introduction**

This book originates from notes I wrote for two university courses. The first is ORIE5250: Topics in Risk Management and Portfolio Construction, a course offered in the program for M.S. in Financial Engineering at Cornell University. The second is MATH-GA2011: Algorithmic Trading & Quantitative Strategies, offered in the program for M.S. in Mathematics in Finance at NYU Courant. Since this book’s objective was to write the quantitative finance book I had wanted to read at the beginning of my journey in finance. Given the scope and goals of quantitative investing, it is only possible to cover a small fraction of it in a course, or even in a book. To address this problem, I made three choices.

First and most important, I aim for synthesis. A book is, first of all, a knowledge filter. In his tribute to his editor, Robert Caro, Robert writes that he wanted to title his book, *Editor*, Kelley, saying that Kelley’s gift was to make a book that was five hundred pages long, but still feels fresh and necessary today. In order to keep my book of manageable length, my working principle has been to focus on real-world problems and then use the simplest techniques that allow me to address the problem at some level of detail. This means some topics are missing in this book, or are covered at the expense of others. My choice of topics reflects my subjective view of secondary importance, material that was too hard for the payoff that it gave the reader, and also topics or ideas that are not sufficiently well-formed, or too experimental. Even if you choose not to read my book, I implore you to internalize the previous sentence. Focus on problems, not on tools. Enough said about problem selection. There are thousands and thousands of finance papers. In line with technical virtuosity but oblivious of reality. Do not fall into temptation, by applications be driven.[1]

Second, I consider risk management and portfolio management as intrinsically connected. Asset return modeling, volatility estimation, portfolio optimization, errors in data and in-sample performance analysis are all related. For example, hedging belongs to risk management, but it is also a form of portfolio construction. Therefore, portfolio construction I have avoided redundancy as much as possible. Sections often refer to earlier ones or are linked to later ones. As I was revising my book draft, whenever I found I had introduced some topic (often because I was infatuated with it) that was not connected to others, I ruthlessly cut it out. This is called “killing your darlings,” but here in reverse. That is, the subject of the book is a tree, not a pruning tool. One can grow with a bit of pruning. Out of metaphor, there is a lot of material in this book, and I am challenging at times.

Third, I occasionally integrate some standard financial results approaches with tools from the field of statistical learning. The former is applied to fundamental factor modeling, portfolio optimization, and performance attribution. I use the latter in the context of return prediction and backtesting. My hope is that the integration of these different approaches is seamless.

---
(Right Sidebar Text from Page 17)

The questions that this address in this book are:

*   How do I model returns in a way that allows me to generate risk and return forecasts?
*   What are excess returns?
*   How do I model and forecast returns?
*   How do I describe and forecast risk?
*   How do I test risk forecasts and return forecasts?
*   How do I define alpha?
*   How do I measure these signals?
*   How do I combine these signals?
*   What is the impact of risk and alpha errors on performance?
*   How do I account for transaction costs in portfolio management?
*   How do I hedge a portfolio?
*   How do I optimize?
*   How do I allocate risk over time?
*   How do I distinguish skill from luck?

The style of the book is also different. I have kept in mind the six qualities Italo Calvino proposes to apply to literature in his *Six Memos for the Next Millennium*: Lightness, Quickness, Exactitude, Visibility, Multiplicity and Consistency. My aversion to advanced mathematics notwithstanding, I must warn the reader that the book is not easy. During my lectures, I have advised more than one student not to take my course. After all, there are few financial engineering or quantitative finance positions available. Moreover, financial engineering and quantitative finance are not easily learned. A handful have become portfolio managers at hedge funds and risk managers. Yet, it is the easiest book I could write for the task, and it is written in the friendliest style I am capable of. Also, I would be lying—and contrary to the spirit of this book—if I pretended that this is a book to be read once and put aside, that the book is the last word on the subject. On the contrary, you and I are in this book together, and together we shall keep a beginner’s mind (Suzuki, 1970): a spirit of openness and curiosity, even when facing advanced topics. I will provide you with the theory behind the operations, and if you do work with me, you will gain enough skill to use the tools. If you need further help, you may remember a cyclostyled zine (Figure 1). On its second page it showed three open chords; below them, a command: “NOW FORM A BAND.” May this book be your field guide to being a pure quantitative researcher. It will be a life well lived.

---

[Image: Figure 1: Frank Zappa's Sideburn #1, page 9 (1977). Source: Dack.com/Zappa]

**Prerequisites**

The book should be accessible to a beginning graduate or advanced undergraduate student in Physics, Mathematics, Statistics, or Engineering. This means having a working relationship, and possibly a semantic one, with advanced linear algebra, probability theory, and statistics. The ideal reader has some previous interest in quantitative modeling of real-life phenomena. Many readers will be either members of a systematic trading team, or work as quantitative researchers in the central team of a hedge fund or a quantitative asset manager.

The book’s material is organized in such a way that you do not need to go through mathematical proofs. You can rely only on informal statements of mathematical results in the main body of the chapter. Some detail will be provided for some results. The reader can find the end of the chapter contains more rigorous statements, proofs, and background material. If you plan on actively doing research, you should study them, eventually.

Even if you read only the main body, you should be used to thinking in mathematical models. The Book of Nature is written in a mathematical language, Be comfortable with linear algebra, at the level of Strang (2019) and Trefethen and Bau (1997).

Some applied probability, at the level of Ross (2013). Exposure to time series, at the level of Tsay (2010), helps. Many students who come to this from economics, statistics, and finance find Hastie et al. (2017), control theory (Simoncelli), or statistics (Freydman et al., 2008).

Some asset return modeling is a plus. The first few chapters of Gned and biotechnology (2009) could be ideal. However, I will cover the basic theory in an appendix.

**Organization**

Like Caesar’s Gaul, the book is broadly divided into three parts. The first part focuses on return modeling. I cover the basics of GARCH early on because they are needed for factor modeling, and then cover factor models, both statistical and fundamental. These topics are covered in Chapters 2 through 6. Fundamental and statistical models. These topics are covered in depth, and both the treatment and some of the modeling approaches are novel. Finally, I cover data snooping/backtesting as a separate chapter, since it is a central element of the investment process.

The second part is devoted to portfolio construction and performance analysis, both ex ante and ex post. The focus is on mean-variance optimization (MVO). I emphasize the geometric interpretation of MVO, its connection to linear regression, covariance estimation, and error propagation. This allows for a synthetic, elegant characterization of performance and for concise proofs. The statistics of the Sharpe Ratio are covered in some detail. The decomposition of portfolio performance into components (factor and idiosyncratic Profit and Loss (P&L), and portfolio construction error) is also novel. As in the previous section, model error plays an important role in this part. If the optimization problem is Othello, then model error must be Iago: it can drive the optimization insane. Unlike in Shakespeare’s tragedies, we can try to rewrite the endings and turn them into comedies.

The third part is the shortest. It contains results about intertemporal volatility allocation and performance attribution. These are essential components of the investment process and belong in a book with the word “Elements” in the title.

Each chapter is organized like an article. You first read a survey the essential results in the main body of the chapter. Sections that are more advanced or sections marked with a star “*” are more advanced and can be skipped on a first reading. Proofs of new results or basic technical material are relegated to the appendices at the end of the chapters. The goal is not to disrupt the flow of learning. As mentioned at the beginning of this preface, the contents of this book are not first read in a linear fashion. I envision that the book will be used as a reference, and it should be suitable for self-study. The dependencies among the chapters are shown in Figure 2.

[Image: Figure 2: Chapter dependencies.]
(Diagram shows dependencies: 2. Basic Portfolio Management -> 3. Performance -> 4. Univariate Returns; 2 -> 5. Linear Models; 5 -> 6. Evaluating Risk; 5 -> 7. Fundamental Factor Models; 5 -> 8. Statistical Factor Models; 2 -> 10. Advanced Portfolio Management; 10 -> 11. Term Asset Allocation; 10 -> 12. Hedging; 10 -> 13. Dynamic Risk Management; 13 -> 14. Skill, Luck, Persistence)

Giuseppe ‘pino’ F. Paleologo
Raanana, New York
March 21, 2022

**Notes**

[1] References to “By Demons Be Driven” by Pantera and to Macduff’s famous speech.
[2] “Philosophy is written in this grand book, the universe, which stands continually open to our gaze. But the book cannot be understood unless one first learns to comprehend the language and read the letters in which it is composed. It is written in the language of mathematics, and its characters are triangles, circles, and other geometric figures without which it is humanly impossible to understand a single word of it; without these, one wonders about in a dark labyrinth.” (Galilei, 1623).

---

**Notation**

(This section contains a very long list of mathematical symbols and their definitions. Transcribing it fully and accurately from the image is challenging. Here's a sample of the structure and some entries):

*   $\mathbb{R}$ The set of real numbers
*   $\mathbb{R}_+$ The set of non-negative real numbers
*   $\mathbb{R}_{++}$ The set of positive real numbers
*   $\mathbb{R}^N$ The set of $N$-dimensional real vectors
*   $\mathbb{R}^{N \times K}$ The set of $N \times K$ real matrices
*   $x$ A scalar
*   $\mathbf{x}$ A vector
*   $X$ A matrix
*   $x_i$ The $i$-th component of vector $\mathbf{x}$
*   $X_{ij}$ The element in the $i$-th row and $j$-th column of matrix $X$
*   $\mathbf{x}'$ or $\mathbf{x}^T$ Transpose of vector $\mathbf{x}$
*   $X'$ or $X^T$ Transpose of matrix $X$
*   $\|\mathbf{x}\|$ Euclidean norm of vector $\mathbf{x}$, $\|\mathbf{x}\| = \sqrt{\mathbf{x}'\mathbf{x}}$
*   $\|\mathbf{x}\|_1$ $L_1$ norm of vector $\mathbf{x}$, $\|\mathbf{x}\|_1 = \sum_i |x_i|$
*   $\text{diag}(\mathbf{x})$ A diagonal matrix with the elements of $\mathbf{x}$ on the diagonal
*   $\text{diag}(X)$ A vector containing the diagonal elements of matrix $X$
*   $\mathbf{1}_N$ An $N$-dimensional vector of ones
*   $I_N$ An $N \times N$ identity matrix
*   $\text{tr}(X)$ Trace of matrix $X$
*   $\det(X)$ or $|X|$ Determinant of matrix $X$
*   $X^{-1}$ Inverse of matrix $X$
*   $X^{1/2}$ Square root of matrix $X$
*   $X \succ 0$ Matrix $X$ is positive definite
*   $X \succeq 0$ Matrix $X$ is positive semidefinite
*   $P(A)$ Probability of event $A$
*   $E[X]$ Expected value of random variable $X$
*   $\text{Var}(X)$ Variance of random variable $X$
*   $\text{Cov}(X, Y)$ Covariance between random variables $X$ and $Y$
*   $\Sigma$ Covariance matrix
*   $\rho(X, Y)$ Correlation between random variables $X$ and $Y$
*   $f_X(x)$ Probability density function (PDF) of random variable $X$
*   $F_X(x)$ Cumulative distribution function (CDF) of random variable $X$
*   $N(\mu, \sigma^2)$ Normal distribution with mean $\mu$ and variance $\sigma^2$
*   $N(\mathbf{\mu}, \Sigma)$ Multivariate normal distribution with mean vector $\mathbf{\mu}$ and covariance matrix $\Sigma$
*   $t_{\nu}(\mu, \sigma^2)$ Student's t-distribution with $\nu$ degrees of freedom, mean $\mu$, and scale $\sigma^2$
*   $\chi^2_{\nu}$ Chi-squared distribution with $\nu$ degrees of freedom
*   $U(a, b)$ Uniform distribution on the interval $[a, b]$
*   $r_t$ Return at time $t$
*   $\mathbf{r}_t$ Vector of returns at time $t$
*   $\mu_t$ Expected return at time $t$
*   $\sigma_t^2$ Variance of returns at time $t$
*   $\sigma_t$ Volatility of returns at time $t$
*   $\alpha$ Alpha, or abnormal return
*   $\beta$ Beta, or systematic risk exposure
*   $w_i$ Weight of asset $i$ in a portfolio
*   $\mathbf{w}$ Vector of portfolio weights
*   $R_p$ Portfolio return
*   $SR$ Sharpe Ratio
*   $IR$ Information Ratio
*   $P\&L$ Profit and Loss
*   $VaR$ Value at Risk
*   $CVaR$ Conditional Value at Risk, or Expected Shortfall
*   $LOB$ Limit Order Book
*   $OTC$ Over-The-Counter
*   $ETF$ Exchange Traded Fund
*   $CDS$ Credit Default Swap
*   $APT$ Arbitrage Pricing Theory
*   $CAPM$ Capital Asset Pricing Model
*   $PCA$ Principal Component Analysis
*   $OLS$ Ordinary Least Squares
*   $MLE$ Maximum Likelihood Estimation
*   $GARCH$ Generalized Autoregressive Conditional Heteroskedasticity
*   $MVO$ Mean-Variance Optimization
*   $iid$ Independent and identically distributed

---

**CHAPTER 1 The Map and the Territory**

**The Questions**
1.  What are the essential components of quantitative investing?
2.  What types of securities are involved and how are they traded?
3.  Who are the main market participants and what roles do they play?
4.  Where do excess returns in investing come from?
5.  What are the key elements that form the analytical framework of a quantitative portfolio manager?

This chapter is a guide to the essential components of quantitative investing. When considering the meaning of a word, it’s often instructive to go back to its etymology. So let’s play this game. Despite being a Germanic language, English adopted many words from Latin, sometimes by way of French. “Investing” comes from “investire,” which in Latin meant “to vest with a robe, to clothe, to surround.” This meaning is still used in English, as in “the investiture of a new pope.” It is also the favorite garment of hedge fund managers. In the Middle Ages, the verb took on the additional meaning of “to surround, to take ownership of.” It is also possible that the modern meaning overtook the old because, in ceremonies in which someone was given possession of an office, they were often given a robe or other symbolic item. “Investire” is the direct successor to Latin—the old meaning is gone, and “investire” only means “to receive possession of something.” As for “quantitative,” that is Latin too. “Quantum” means denoting something that can be measured, increased or decreased. So, we deal with measurements, sums, and budgets. Quantitative investing can be measured, increased and decreased. This is the map, while the territory is the world of finance. You can own a house, a painting, a bet on the survival of humankind, or even an idea. Each one of these investment topics deserves its own book, written by a competent author. In writing this book, I have chosen to trade off generality in favor of depth. I have confined myself to the goal of this book: that you should be sufficiently equipped to understand, to implement, and to critique. However, even an analytical book needs an introduction that puts things in their proper context. In this chapter, I aim to provide that context. You will have a broad understanding of the classes of securities to which these methods apply, and of the way they are traded. We will also look at the market participants, and the roles they play. We will also explore fundamental questions: Where are excess returns coming from? What causes these trading opportunities? Finally, I will present the essential components that make up the analytical framework of a quantitative portfolio manager. The underlying message is that to be successful, an investor must understand how things work. A seminal early book on investing is titled, *The Intelligent Investor* (Graham, 2003). To double down on Latin, the original meaning of “intelligent” is “to read into something,” similar to “insightful” in the English language. Your success as a quantitative investor will depend on your ability to read into the data, governing the trading of your assets, and the functioning of exchanges. Many budding quants focus on quantitative methods. The fact is that theory is cheap and is often not hard. What is hard is putting the right tool at the service of the right insight.

Finally, this is the only chapter without mathematics. You should enjoy it while it lasts.

---

**1.1 The Securities**

We will be concerned with standardized products that are liquid. We explain these concepts in more detail.

To “own” an object is effectively to own a claim on that object. In the future, if you have a house, you don’t own it outright. You own a claim on it. This claim is not absolute, however. In most countries, the local or central government may need your property for reasons of public welfare and can require you to exchange your claim for cash at a fair price. If you own a painting, you may enjoy it in the comfort of your home, but you may not be able to sell it easily. The claim is not standardized, and the market for paintings is illiquid. We will be concerned with point claims that prevent it from paying (e.g., consider a zombie apocalypse scenario). Defining ownership of an “idea” is especially challenging and prone to be treated on an ad-hoc basis. Compared to the infinite and ever-changing universe of possible claims, financial markets deal with a very small subset of these claims: the subset of claims that are standardized and liquid. We buy and sell standardized claims. These claims come in a few varieties, and their attributes are clearly defined and known to all potential buyers and sellers. Examples are:

*   Equities and Exchange Traded Funds (ETFs). These give us partial ownership in companies, or groups of companies, and entitle us to future cash payments generated by the economic activities of these companies.
*   Futures. These contracts deliver a physical commodity or a cash payment contingent on the state of the world at a future date, at a price determined today.
*   Bonds. These are contracts that allow the transfer of debt claims among parties. An investor lends money to a borrower in exchange for a fixed cash flow in the future (e.g., periodic interest payments and a final payment). A bond makes this claim transferable to other lenders.
*   Options. These are claims that depend on the future value of some underlying asset. For example, you may secure the right (but not the obligation) to buy a stock at a future date, at a price determined today. The nature of these claims is standardized, hence the term “vanilla.”
*   Interest Rate Swaps (IRSs). These contracts allow the exchange of a certain, deterministic cash flow stream for an uncertain one, which depends on interest rates at future dates.
*   Credit Default Swaps (CDSs). These contracts insure the buyer against the default of a company’s debt. The buyer pays a periodic premium to the seller in exchange for receiving the par value of the debt if the company defaults.

These further contracts are liquid. For our purposes, a liquid contract is one that can be bought and sold in large enough sizes, and at sufficiently short time horizons, to enable quantitative strategies to be implemented. This means that if we plan to buy or sell a contract, we should be able to do so without incurring a large cost, and that the price at which we transact should not be too different for small trading sizes, and that the waiting time due to searching for a counterparty should not be so long as to make the transaction economically unattractive.

The properties of standardization and liquidity are closely intertwined. Increased standardization tends to enhance liquidity by consolidating demand, as it aggregates dispersed demand from bespoke products toward a smaller set of standardized ones. Increased standardization also streamlines the trading process, which reduces search costs and settlement complexity. Both of these effects reduce risk and thus attract more participants, thus enhancing liquidity. However, the downside is that customers may sacrifice the ability to trade custom useful product characteristics. Determining the optimal level of customization, even at the expense of some liquidity, is an ongoing process that depends on industry circumstances, refer to the 2008 financial crisis (Acharya, Cooley, Richardson, Van Nieuwerburgh, and White, 2010). For example, the CDS market evolved rapidly. However, the “Big Bang” initiated by the International Swaps and Derivatives Association (ISDA) on April 8, 2009, simplified contract terms, including standardizing coupon rates (100 bps and 500 bps) and introducing a standard upfront payment, played a pivotal role in restoring confidence in this asset class (Nosal, 2010).

Trading and liquidity are at the core of the book. In order to better understand the trading process and the nature of liquidity, we should describe in some detail how trading on exchange and over-the-counter happens.

---

**1.2 Modes of Exchange**

At any given time, economic agents want to buy or sell contracts. They want to do so quickly, cheaply, and reliably. The most optimal setup which leads to this currently organized are exchanges, over-the-counter, and dark pools. Exchanges are venues in which the orders of buyers and sellers are anonymized and matched against each other. Orders are characterized by size, the number of contracts, direction (buy or sell), and price. An exchange requires that its members respect its contracts. The exchange usually sets strict rules and a high bar as to the limit order book (LOB), and employs a set of priority rules to match buy and sell orders in the exchanges—aptly named a matching engine. In order to trade on an exchange, one must be a member of that exchange. Membership entails apparent costs (fees) and non-apparent costs (compliance). Multiple participants must maintain sound governance, risk processes, and capital structure.

Exchanges evolve continuously due to two driving forces. On one side, there is a push toward consolidation, which reduces operating costs and gives the owner pricing power. On the other side, technical and process innovations introduce new competitors into the market. In the United States alone, there are more than a dozen equity stock exchanges. Nowadays, most exchanges are electronic, but some (Knez and Ready, 1996), including futures exchanges, are still open outcry, although this condition is neither necessary nor sufficient: some exchange-traded assets are traded in minimal volumes and, therefore, are not liquid, and some very liquid products are traded off-exchange.

Other assets are not traded on exchanges, but over-the-counter (OTC). In this case, the buyer or seller transacts through an institutional market participant, the broker-dealer, or directly with each other. This applies to a broad range of assets, such as loans, bonds, IRSs, Forex and commodities, structured products, and CDSs, examples of contracts traded OTC. Some of these, like currencies, are among the world’s most liquid contracts. A precondition for liquidity is standardization. Think of a house. The New York housing market is very different from the stock market or the bond market. Houses are not standardized. Each of them is unique and distinguishable from the other and sells in a matter of seconds. In contrast, a house has many attributes that make it unique: location, size, age, blueprint, and condition. Another characteristic of liquid markets is the large number of participants. When the number of counterparties becomes too small, competition for a security wanes, while the number of counterparties becomes too large, and eventually the bilateral bargaining diminishes. The ability of any individual participant to influence the price is significantly reduced. To illustrate, consider the housing market as a counterpoint: when selling a house, you typically negotiate with one specific buyer or seller. The negotiation process may take several days or weeks. You may list the property and may engage in intense bargaining, sometimes to the point of contention, to secure the best possible price.

Finally, Dark Pools (a type of ATS, or Alternative Trading System, which does not make its LOB transparent) are additional venues that are distinct from exchanges and OTC markets where trades happen. Dark Pools allow large buyers and sellers, institutional investors to trade orders without displaying their trading intentions. By design, Dark Pools hide order details and only make trades details available after execution. As of 2014, approximately 15% of U.S. shares are traded on Dark Pools.

---

**1.3 Who Are the Market Participants?**

It is convenient to partition traders into the sell side and the buy side. The former is in the business of providing services; the latter executes trades for their own benefit. Below I describe the participant types. For a more detailed description, see Harris (2003).

**1.3.1 The Sell Side**

The sell side comprises brokers, dealers, and broker-dealers.

*   Dealers. These are market participants that provide liquidity, meaning they make the market for the assets they trade. They are profitable if they can buy (bid) at a price lower (higher) than what they usually paid to buy (sell) the asset. The difference between buy and sell prices is the spread. When dealers interact with clients, they quote the buy price (the bid) and the sell price (the ask). The dealer’s goal is to make transactions possible. In OTC markets, dealers are the primary liquidity providers. The most sophisticated among such markets allow the dealers to quote prices, quantities, and other attributes continuously, for example, via electronic trading platforms such as Tradeweb or Bloomberg. In order to make markets in the highly bespoke products, the dealers quote on request, possibly one-sided quotes for a specific quantity and with an expiration time. The quote, or the spread if the quote is two-sided, depends on the dealer’s inventory, the dealer’s risk appetite, and the dealer’s view on the market. Dealers can also take speculative positions, meaning they hold a portfolio (or an inventory of positions) and face the issue of trading counterparties that may be more informed than themselves. Unlike speculators, dealers are passive traders, in that they respond to orders. Dealers are subject to intense scrutiny from financial regulatory bodies. Retail dealers often choose their own execution venues for their clients; they are informed agents, often serving the needs of the client. The dealer’s profit originates from the realized spread. The inside spread (which is usually lower than the quoted spread) is also the source of the dealer’s profit. The dealer’s profit also comes from the order flow. One specific type of flow originates from retail investors (who we introduce later in this chapter). These investors access the market indirectly through brokers. Brokers have special arrangements with dealers to route their clients’ orders to them. In summary, dealers are liquidity providers, and they are compensated for services through trading profits.
*   Brokers, trade on behalf of their clients. When the broker receives an order from a client, together with information about the client’s needs, the broker will try to find a counterparty to execute the order in accordance with these preferences. For example, a client sends a broker an order to buy a certain number of shares of a company. The broker is a member of all major exchanges. It submits the order to one or more exchanges and ensures that the transaction is settled. The broker may also execute the order with one of its own clients or its expected cost. Dealers, brokers are intermediaries who take no risk by holding contract positions at any given time. The intermediation service they provide is beneficial, however. It comes with a cost. The broker charges a commission for its services. Non-member clients and firms provide OTC dealer access to non-institutional clients. Institutional clients, too, may want to enlist a broker when interacting with dealers, since the broker anonymizes the clients. Further, brokers provide several other useful settlement, clearing, and technological products often free of charge. Clients need to know and trust their counterparty to protect themselves from insolvency, reneging, or non-compliance. There is a small number of brokers compared to the number of traders, so that a client has to be opaque and use the broker to buy or sell securities. Anonymity is important in this case, and this is its use. This use does not eliminate counterparty risk. It transfers it to the brokers. The brokers manage it by vetting the clients, and by requiring that clients deposit capital at the broker, which the broker uses in case of default. The amount of capital depends on the riskiness of the client. In addition to these services, brokers, and especially prime brokers, the solicitation of brokers servicing hedge funds and other sophisticated investors, offer their clients other services. Common services brokers ensure include receipt, recording, and safekeeping of financial assets.
    Rehypothecation. Clients may allow the brokers to use their securities for the brokers’ own needs in exchange for fees or rebates. For example, brokers may use client securities as collateral to borrow cash from other institutions. In turn, brokers lend clients securities from their own inventory or from other clients.
    Margin loans. Brokers lend clients short-term capital to buy securities. They charge them SOFR[2] plus a spread.
    Lending of short positions. Clients may want to short stocks (i.e., sell stocks they do not own). Brokers will source the stock with the expectation that future prices will be lower than current ones. Brokers enable these transactions by lending shares from a third party and making them available to clients. The clients then sell them in the open market, buy them back at a later time, and return them to the broker. After the initial sale, but before the buyback, the broker receives the proceeds from the sale as collateral. The broker receives from the broker SOFR minus a spread.
    Research reports and services, as well as broker-specific data. These services used to be bundled in broker commissions but are now unbundled as a result of MiFID II regulation; they are now charged separately.
    Capital introductions, in which brokers facilitate the connection between hedge funds and potential investors.
    In summary, brokers offer diversified services, the most important of which are execution, clearing, settlement, custody, financing, and communication, interest on cash balances, research on trading, and payment for order flow (PFOF), which is the compensation brokers receive from market makers for routing orders to them.
*   Broker-dealers, also called dual traders, combine the previous two functions in a single entity. They act on both behalf of the client and on their own behalf. This introduces a tension. As dealers (a term we use to refer to the dealer function of a broker-dealer), they make markets. Maybe the simplest action is front-running: the dealer is aware of incoming buying or selling demand for a security, and buys it in advance before this demand manifests in the market and is reflected in prices. To mitigate this conflict of interest, regulations are in place that require broker-dealers to separate their client-facing and proprietary trading desks, and broker-dealers is the Securities Exchange Act of 1934 (or “1934 Act”).

**1.3.2 The Buy Side**

The buy side usually trades with the sell side. You (the reader of this book) are likely to be on the buy side, even if you entertain the notion of becoming a sell-side dealer. The buy side is more diverse than the sell side. The main goal of the buy-side drama are, because you will continuously interact with them, and your excess returns will be the outcome of this interaction. We could classify the buy side actors according to several criteria. For example, the sub-industry to which they belong (e.g., insurance vs. hedge funds), but I opt not to classify them purely based on the type of institution.

*   Passive institutional investors. These portfolios replicate the composition of the benchmark, or rather, generated by data providers like MSCI, S&P, Russell, CRSP, or from exchanges like FTSE 100, TOPIX, and Deutsche Borse. These indices are updated on a quarterly or biannual basis, and they comprise broad indices as well, like the Bloomberg Agg (until 2016 owned by Barclays). Sectoral indices (e.g., financials or technology), or style indices (e.g., value or small cap). Large firms in this group are Blackrock, Vanguard, and State Street. Indexers make up a large and growing share of the total asset base. According to estimates by Charles Schwab, passive investing now represent over 50% of the U.S. stock market capitalization as of 2019.
*   Hedgers are firms participating in markets with the primary objective of reducing financial risk originating from their core business activities. For example, currency risk is faced by any firm doing business internationally. Commodity price risk is faced by firms using or producing commodities (e.g., airlines purchase fuels; oil, gas, firms, and miners). Interest rate risk is faced by firms whose price variability can be very disruptive. Hedgers primarily participate in derivative markets: futures, swaps, and options. Hedge funds differ from other participants who also hedge, such as dealers or hedgers. In fact, that hedging is the primary activity they perform.
*   Institutional active managers are firms investing on behalf of their clients. They run strategies that are sometimes benchmarked to common market indices. Examples are mutual funds, sovereign wealth funds, insurance or pension funds, endowments, and family offices. See SPIVA reports, or the Refinitiv study (Chow, 2021). Both show that over 60% of funds underperform their benchmarks over a one-year trading basis. The subperformance of funds over one year is not surprising. What is surprising is that the majority of funds underperform the S&P500 over the previous 15 years. On the other side, funds serving institutions seem to beat their benchmarks (Pástor and Linnaimaa, 2021). The term used for the process is mean reversion. Otherwise, active managers would not be in business. The risk they take is compensated by the return they generate. Active managers are often constrained by a benchmark, and discretionary positions of a “tracking portfolio.” A large tracking error gives the funds much discretion; a low one places their returns close to the indices, and makes them resemble index funds. Active managers also differ in the degree of discretion they manage portfolios. Some portfolios are restricted to a single asset class. Within an asset class, the portfolio closely follows a representative benchmark. One can view asset allocation as messages that communicate to clients the desired relative weight of each asset class in the portfolio. Asset classes are broadly defined. Commonly asset classes are equities, bonds, commodities, and cash equivalents; in addition, asset classes invest in alternative asset managers like private equity firms, venture capital, hedge funds, and real estate.
*   Informed traders include primarily hedge funds and principal trading firms. These firms are usually organized as partnerships, although a minority of them are publicly traded. They are active investors. They manage money for themselves and for their clients. Principal trading firms only have general partners (GPs, the principals) investing their own money; hedge funds also have limited partners (LPs) who do not invest actively.[3] These firms aim to generate returns that are not correlated with traditional asset classes.[4] They exhibit low correlation to the returns of major classes.[5] Informed traders invest heavily in human capital, technology, and data to achieve this goal. They fulfill two major functions. The first one is price discovery. By using all information available to them, they form an estimate of the true value of a security. If the security prices differ from their estimates, they trade to exploit the mispricing. If the price is lower than their estimate, they buy the security. In the process, they increase its price and bring it closer to equilibrium. Mispricing can take many forms. If the mispricing is a result of temporary liquidity dry-ups, then the actions of this large subset of informed traders will try to exploit the difference; of course, this may not be easy to do as the difference either persists, or disappears very quickly due to technology investment in low-latency trading. The second function is risk transfer. If a security is mispriced, then, instead of arbitrage, certain is applicable to a certain degree. I provide examples in Section 1.4. Hedge funds and market makers develop specialized strategies that predict imbalances. Hold (or short) securities because liquidity need materializes. These strategies are often based on statistical arbitrage. The subtle interplay between prediction and event can be vast—from sub-second for high-frequency market makers to weeks or months for hedge funds.
*   Retail investors trade for their own account via retail brokers. In most countries, retail investors make up a small fraction of total volume; the share was slightly higher than 10% in 2011. Several studies, across different national markets and periods, have shown that retail traders are consistently unprofitable (Barber and Odean, 2013); retail traders lose money, on average. The main reason is that they trade too often, after the dealers, who will pay the retail brokers for routing it to them (payment for order-flow).

---

**1.4 Where Do Excess Returns Come From?**

Now that we have introduced the main actors in the play, a usually unasked, rarely answered, and occasionally a source of meaning, we can discuss the sources of excess returns. The “excess” qualifier means “in excess of portfolio invested in risk-free assets, such as short-dated U.S. treasuries.” This topic is central both to academic financial research and to practitioners. Academic finance is primarily concerned with the question of efficiency in the words of Malkiel (1987).

A capital market is said to be efficient if it fully and correctly reflects all available information in determining security prices. Formally, the market is said to be efficient with respect to some information set $\mathcal{I}$ if security prices would be unaffected by revealing that information to all participants. Note that the definition of market efficiency based on information set $\mathcal{I}$ implies that it is impossible to make economic profits by trading on the basis of information set $\mathcal{I}$.

An exceptionally concise definition, if there ever was one. As is now in the Fama-French tradition, we can distinguish three forms of market efficiency, depending on the information set. This could be, for example, the set of all historical prices of the traded securities. Moreover, this information can be obtained with relatively little effort. A different set of information set is publicly available information, defined in the United States as “any representation or statement, including general news or industry reports, (1) made by or on behalf of an issuer of securities, (2) contained in any reports, proxy statements, registration statements, or other documents filed with Federal, state, or local governmental agencies or self-regulatory organizations, or (3) contained in any widely disseminated media (e.g., public disclosures to the general public that are required to be made by federal, state, or local law).” An even finer information set is the set of all information available to any investor. Academic research tries to assess the validity of the efficient market hypothesis (EMH) by testing whether it is possible to predict future prices. Indeed, there is empirical evidence that asset prices are predictable. However, the hypothesis is that current prices may not be affected. We do not trade in the direction of returns, up to the point that the investing horizon is very long. The reason is that the signal-to-noise ratio of the prediction is too low. One reason is that the uncertainty around the prediction is too high for us to take advantage of it. For example, say that, to the best of our knowledge, the expected return of the S&P500 is 6% per year, with a standard deviation of 20%. Even if we are confident that our estimate of the expected return is correct, the standard deviation of market returns is 20%, a little too high for comfort. Risk, however, is not the only reason. Another one is liquidity. Indeed, the road to hell is paved with good intentions. There are many examples of assets that are predictable but not easy to trade. A famous example is the Palm-Pilot (later Palm, a now defunct mobile device company) vs 3Com (a telecom equipment maker, also defunct) in 2000. 3Com floated on the public market 5% of the shares of Palm, while retaining the other 95%. Right after the initial public offering (IPO), Palm had a market value of $53B, while 3Com had a market capitalization of $28B. The implied value of 3Com assets was -$25B, even though the company had no debt. This is an example of pure arbitrage. An investor could have shorted Palm shares and bought 3Com shares and pocketed $25B. However, the investor could not therefore bought 3Com shares and shorted Palm for an equal amount. The portfolio comprising these two assets was a synthetic asset whose return could be predicted. There was a problem, however: the shares of Palm were short-sale constrained. This means that there was a limited supply of Palm shares available to be shorted. The cost of borrowing Palm shares was very high, so high as to make the trade either unattractive or impossible.

Risk and liquidity are not the only two factors limiting the exploitation of information. We list three more. The first one is funding. Consider a scenario in which certain assets, or certain portfolios, have lost much of their value due to market distress. We are managing a small hedge fund, which has also lost money in this market. The fund’s investors are redeeming their capital. We are forced to liquidate our positions. Such scenarios, also called “fire sales,” are common. This is often called “unwinding spirals.” However, we do not have much capital available to post as margin. In addition, we need a capital buffer in order to withstand a possible additional loss in the very short term. Funding constraints prevent us from buying the asset, in spite of our accurate forecast.

A significant source of excess returns comes from flow predictability. Some agents, such as index funds, mutual funds, and retail investors, trade in a way that is not based on known securities on dates. Speculators can then take advantage of this information by providing liquidity beforehand. One of the most important instances of this is index rebalancing. Several index providers update the weights of the stocks in their indices on a regular basis, usually quarterly or semiannually. The additions to the index are made public, and the new weights are effective on a given date, often with an updated weight. The term used for this process is index rebalancing. For example, TSLA was added to the NASDAQ 100, effective July 15, 2013. The announcement was made on July 10, 2013, but several investors could have foreseen this event. The price of TSLA shares increased by 10% between July 10 and July 15. The demand for TSLA shares and therefore the change of index have an obligation to buy TSLA is the close of that day, and the resulting demand is likely to push up the stock price. Informed investors anticipating this may do so by buying the stock beforehand. The information that drives these predictable flows is not related to the company’s fundamentals but rather from company-specific or industry-specific issues. These, however, is the remote that that the reconstitution be cancelled or postponed. The size of passive investing is large and to estimate ranges from 5% (Frazzini, 2013) to 38% (Chavez and Samadi, 2016). The cost of such trades is large, and it is borne by the passive investors. The total cost of such predictable flows is in the order of $1B-$2B per year. A prominent example of predictable flows, but several others exist, usually smaller in size, but also not as widely known as index rebalancings. Their common feature is the existence of institutional or procedural constraints (sometimes driven by internal processes, other times by regulatory requirements) that introduce predictability in the demand of securities.

Finally, we consider a last source of excess returns: informational advantage. This means that the investors not only differ by their risk attitude, their tolerance to illiquidity, or their funding constraints, but also by the quality of their information. Some investors have better, more accurate forecasts of future prices or returns. This is what is often meant by “statistical arbitrage:” the ability to predict returns accurately based on insights our competitors do not have.

In summary, even assuming accurate information owned by participants, some of them cannot exploit this information. We have listed several possible causes of return predictability:

*   pure arbitrage;
*   heterogeneous risk preferences;
*   liquidity;
*   funding;
*   flow predictability;
*   informational advantages.

These causes are not exhaustive. For example, flow predictability and liquidity are related, albeit not identical, and the distinction between being compensated for risk-taking and holding an actual information advantage is usually unclear. However, these broad classes can help us reason about one strategy’s edge.

---

**1.5 The Elements of Quantitative Investing**

The investment process is usually viewed as a highly structured process. There are several ways to represent it; the development of which is the responsibility of remote teams. In Figure 1.1 I show a possible organization of these components, which I follow in the organization of the book. I review them below.

[Image: Figure 1.1: The components of the investment process.]
(Diagram shows: Data -> Before the Trade (Prices, Risk, Expected Returns, Signal Aggregation, Constraints, Optimization) -> During the Trade (Execution, Hedging, Leverage) -> After the Trade (Profit and Loss, Performance Attribution, Risk Control, Intertemporal Volatility Allocation). Data also feeds into Characterization and Time Series.)

**Data**. The essential inputs to investing are under the “Data” section to the extreme left.
Prices and trading volumes are often collected at regular intervals (e.g., every minute, every 5, 10, 15 minutes, or daily). For high-frequency strategies it may be necessary to use order-level exchange data.
Characteristics are numerical scalars associated with a security and a timestamp. Common examples are descriptions of the security, like the free cash flow generated by the firm in the most recent quarter, divided by the market capitalization of the stock. Or the stock’s beta, calculated using daily returns over the last six months.
Time series are often derived from characteristics (which are multivariate time series). Examples are time series of the Consumer Price Index (CPI), which can be used to estimate the inflation rate in the United States. Yield of the 10-year U.S. Treasury bond, the VIX index, the effective federal funds rate, the overnight rate for unsecured lending of reserves among commercial banks, and the VIX, a forward-looking measure of U.S. equities market volatility.
Unstructured data are the dark matter of financial data. Prices, characteristics, and time series are structured data: numerical, categorical, or ordinal (i.e., rankings), and in tabular form. Unstructured data are usually character sequences representing natural language (e.g., earnings transcripts and firm news) or images (e.g., satellite images), video/audio recordings, or network data (e.g., social media data). Often, unstructured data is used to develop the above formats).

**Before the trade**. Data are used to develop three components that enter the portfolio construction during the trade. Because they precede the trading process, I classify their development as being “Before the trade.”
Risk. The word “risk” can mean many things. In the context of this book, we will use portfolio volatility as a proxy for risk. Estimating this volatility for an arbitrary portfolio is a challenging task.
Expected returns. In order to be profitable, a trading strategy needs to have information predictive of future returns. This is often viewed as the paramount concern of a quantitative investor and to a large extent it is. Many modern trading strategies focus on predicting returns over short horizons of minutes or hours. The number of estimates can run into the thousands of millions.
Transaction costs and market impact. Trading securities is expensive. Transaction costs can be explicit (e.g., commissions) or implicit (e.g., the bid-ask spread). Market impact is the adverse price movement caused by our trading. Among other things, transaction costs and market impact determine whether a predicted return at some horizon can be turned into a profitable strategy or not, and what is the maximum profit that can be extracted from such a strategy.
During the trade. The portfolio construction procedure happens “During the trade,” because the portfolio construction procedure results in real-time trading decisions, and these decisions determine the Profit and Loss (P&L) of the strategy. The decisions taken in this part form the core of portfolio construction.
Incorporation of risk constraints. A strategy’s P&L is a function of the maximum risk that it can take. This is usually represented in the portfolio construction problem either in the form of constraints (e.g., the portfolio volatility must be less than a given value) or as a term in the objective function. Risk constraints and sensitivities can have a very material impact on the performance of the strategy.
Signal aggregation. We use the term signal for a model of expected returns. For a given asset, we can have many signals. For example, we can have a signal based on momentum and a signal based on value. In practice, combining such signals into a single signal.
Hedging decision. Certain trading strategies have exposure to systematic risk. In layman’s terms, they can lose money because their returns are correlated to market-wide sources of risk. Some of these sources can be hedged, which means that such risk can be counterbalanced. This is an important consideration that can make or break a strategy.

**After the trade**. The trading process generates a time series of P&L, both for the overall portfolio and for its constituents.
Performance attribution. In the portfolio construction phase we estimate the expected P&L of the portfolio. Performance attribution is the practice of tracing back performance to its possible sources, to see what worked and what did not, so that we can learn from the experience. Moreover, performance attribution is essential for communicating with investors.
Risk control. Risk control is the set of procedures employed to assess whether we have shift in sizing our bets.
Intertemporal volatility allocation and leverage. How should we allocate risk across periods? This decision is very consequential. For example, should we increase or decrease our leverage in response to changes in the market environment? This is one of the core questions of the Capital Asset Management Model (CAM) of the portfolio and Assets Under Management (AUM).

I stress that different arrangements are possible, for example, Narang (2014) employs a simpler scheme, and Pedersen (2015) has yet another one. Some of the individual elements I introduce are present in their models of quantitative investing.

**The Takeaways**

*   Market participants can be broadly classified into sell-side and buy-side participants. The sell-side participants are:
    *   Dealers
    *   Brokers
    *   Broker-dealers
    The buy-side participants are:
    *   Passive institutional investors
    *   Hedgers
    *   Institutional active managers
    *   Asset allocators
    *   Informed traders (e.g., hedge funds, principal trading firms)
    *   Retail investors
*   Excess returns come from five major sources:
    1.  Pure arbitrage
    2.  Risk
    3.  Liquidity
    4.  Flow predictability
    5.  Funding constraints
    6.  Informational advantages
*   Predictable flows
    Informational advantage in predicting future returns
*   Quantitative investing employs analytical models that can be partitioned into three broad groups:
    *   Risk measurement models and data
    *   Market impact models
    *   Expected return models and data
*   The investment process has several stages:
    *   Data collection: Prices, trading volumes, asset characteristics, time series data, and unstructured data
    *   Pre-trade analysis: Risk assessment, expected return estimation, and transaction cost analysis
    *   Portfolio construction: Aggregation of signals, incorporation of risk constraints, and hedging
    *   Post-trade evaluation: Performance attribution and risk adjustments based on intertemporal volatility and leverage considerations.

**Notes** (Right Sidebar from Page 56)

[1] Cf. to Harris (2003).
[2] Secured Overnight Financing Rate (SOFR) is a measure of the interest rate charged for overnight cash loans.
[3] GPs in hedge funds are both principals (since they invest their own money) and agents (on behalf of the LPs). To resolve this conflict of interest, the SEC regulates the class of investors who can be LPs (high-net-worth individuals), and gives LPs special privileges within the fund.
[4] This is not always true in practice because (a) some hedge funds have an explicit market exposure and (b) some hedge funds have an asymmetric exposure to the market (Agarwal and Naik, 2004).
[5] The “market” here denotes a set of common risk factors. For a long time most of good quality accounting for corporate actions, is hard, expensive, and requires skill.
[6] COST OF OBTAINING FINANCIAL INFORMATION UNDER TITLE V OF THE GRAMM-LEACH-BLILEY ACT OF 1999 (GLBA) IS 15 U.S.C. § 6802 (a).
[7] As in the case of the past GameStop, we can represent portfolios as synthetic assets.
[8] Note that this is not the same as front-running. The latter also consists of buying or selling a security based on a demand forecast of said security. But in the latter case, the forecast relies on non-public information.

```

Okay, here is the Markdown compilation of the text from the second set of screenshots, covering Chapter 2.

```markdown
Everand

**Chapter 2**
**Univariate Returns**

**The Questions**

1.  What are the definitions and types of returns, including dividend-adjusted and excess returns?
2.  What are the “stylized facts” of stock returns, and why are they important?
3.  How do we estimate prices and returns while accounting for market microstructure effects?
4.  What are Conditional Heteroskedastic Models (CHMs), and how do they model volatility?
5.  How does the GARCH(1,1) model capture the stylized facts of returns?
6.  What is realized volatility and how is it estimated using high-frequency data?
7.  How can state-space models and the Kalman filter be used for variance estimation?
8.  How does GARCH(1,1) relate to Exponentially Weighted Moving Averages (EWMA) in volatility estimation?

We begin with models of univariate returns for two reasons. First, single-asset returns are the basic constituents of portfolios. We cannot hope to understand portfolio returns if we do not have a solid understanding of the returns of single assets. It is necessary to summarize the salient empirical properties of stock returns and the most common processes employed to model them, specifically to model volatility effectively. Second, these models have general applicability and are even more useful when we combine them with models of multiple assets. We introduce GARCH and exponentially weighted moving averages as essential tools for the estimation of volatility. In the process, I introduce models that justify their use. Exponential moving averages find their motivation in linear state-space models, while GARCH is an instance of a non-linear state-space model. These models will be your friends for life. The chapter is organized as follows. First, we define returns and their basic properties. Then, we introduce some “stylized facts” (empirical features of returns that are ubiquitous and relevant to risk management). As part of basic volatility modeling, we will introduce GARCH models and realized volatility models. Given that these topics are vast, I make no attempt to be exhaustive; the goal here is to present the essentials, their associated insights, and to provide a working knowledge of the models. Finally, I will touch on the state-space models for variance estimation.

---

**2.1 Returns**

**2.1.1 Definitions**

We have a set of $N$ assets and a currency, also called the numeraire. Throughout this book, the numeraire is the U.S. dollar. The price of an asset $i$ is the amount of numeraire necessary to acquire one unit of these assets. In defining returns, we buy today the equivalent of 1 unit of currency for asset $i$. We denote the value of the asset tomorrow by some future price $P_{i}(t+1)$. An equivalent way to define returns is from the closing prices of security $i$ on days $t$ and $t-1$, which we denote $P_i(t)$ and $P_i(t-1)$ respectively. The return is defined as

$$ r_i(t) = \frac{P_i(t) - P_i(t-1)}{P_i(t-1)} $$

We extend this definition to the case in which the security pays a dividend. The holder of the asset receives an amount $D_i(t)$. The dividend-adjusted return is defined as

$$ r_i(t) = \frac{P_i(t) + D_i(t) - P_i(t-1)}{P_i(t-1)} $$

In a universe of $N$ assets, the vector of daily returns between times $t-1$ and $t$ is denoted
$$ \mathbf{r}(t) = (r_1(t), \dots, r_N(t))' $$
For a portfolio $p$, let $w_{ip}$ be the monetary amount invested in asset $i$. Thus, a single period return is given by the change in the value of the portfolio. The number of shares owned in asset $i$ is calculated as $w_{ip} / P_i(0)$. The value of the portfolio at period $t$ is
$$ \sum_i w_{ip} (P_i(t) / P_i(0)) P_i(1) $$
, and the change in value is
$$ w_p \frac{P(1) - P(0)}{P(0)} = \sum_i w_{ip} $$
In vector form, this equals $w_p'$. The volatility of a random return is its standard deviation:
$$ \sigma_i := \sqrt{E[(r_i - E(r_i))^2]} $$

The variance is the square of the volatility. Occasionally, when the approximation $P(t) \approx E[P(t)]$ holds, we will approximate the volatility by the second moment of the return, $E[r_i^2]$. The compounded return over $T$ periods of investing one unit of currency in asset $i$, which has been invested in a security yielding returns $r_i(t)$, is:

$$ r_i(1:T) = \frac{P_i(T)}{P_i(0)} - 1 $$
$$ = \frac{P_i(T)}{P_i(T-1)} \frac{P_i(T-1)}{P_i(T-2)} \dots \frac{P_i(1)}{P_i(0)} - 1 $$
$$ = \prod_{t=1}^T (1+r_i(t)) - 1 $$

**2.1.2 Excess Returns**

In the rest of the book, we will not use security returns, but excess returns: the risk-free rate $r_f$. For example, we model daily returns, the risk-free rate $r_f$ is the interest rate paid by the investor for borrowing cash over the same period, or paid to the investor for cash held in their account. If we hold a security, we pay interest on the cash we used to buy the security. If we short a security, we receive cash. Cash is an asset with a security, but a value in the future that is much less uncertain than other modeling purposes, negligible volatility than the other risky assets. We borrow or lend an amount equal to the Fair Market Value (FMV) of our portfolio, i.e., the sum of the values of each position. The return of a portfolio is
$$ \sum_i w_{ip} r_i - \sum_i w_{ip} r_f = \sum_i w_{ip} (r_i - r_f) $$
The formula shows us that the risk-free rate is subtracted from the portfolio and provides a natural interpretation of security returns as returns in excess of a rate received in the absence of investing. In the United States, the reference rate is a reference overnight lending rate, like the Secured Overnight Financing Rate (SOFR).[2]

**2.1.3 Log Returns**

If $r_i(t)$ follows a multivariate Gaussian distribution, then so does the portfolio’s P&L. The variance of the portfolio can be computed by just using two pieces of information: the portfolio weights and the covariance matrix of the returns.

The question of whether net returns are Gaussian is an empirical one. We at least know that the distribution of daily returns is not Gaussian. Log returns are additive over time. However, there are not easily tractable time-series available. For example, consider the compound return over period $T$, $\prod_{t=1}^T (1+r_i(t))$. If $r_i(t)$ are normally distributed, the cumulative total return is not normally distributed, and its distribution rapidly diverges from the normal distribution. The variance of the cumulative returns is not a simple function of the single-period variances.

On the other side, log returns are attractive because they are additive. Let
$$ \tilde{r}_i(t) := \log(1+r_i(t)) $$
Then, the log of the compound return is equal to the sum of the log returns in the single periods. If the log returns are normal, then the sum of the continuously compounded returns are also normally distributed, and the variance of the sum is equal to the sum of the variances. We can reconcile the two views of returns—raw and log—if the approximation
$$ \log(x) \approx x-1 + o(|x-1|^2) $$
is sufficiently accurate, i.e., if net returns are small. In this case, we can make the approximation $\tilde{r}_i(t) \approx r_i(t)$, which is sufficiently accurate provided the returns are not too large.

A common approximation for the compounded net return of an asset over time is given by
$$ \prod_{t=1}^T (1+\tilde{r}_i(t)) - 1 = \exp\left(\sum_{t=1}^T \tilde{r}_i(t)\right) - 1 $$
$$ \approx 1 + \sum_{t=1}^T \tilde{r}_i(t) - 1 $$
$$ = \sum_{t=1}^T \tilde{r}_i(t) $$
Above we rely on the accuracy of the approximation. For example, comparing the estimates of models developed using $r_i(t)$ and $\tilde{r}_i(t)$. The approximation is in general optimistic (see Exercise 2.1). When the assets are equities, the approximation is usually considered adequate for daily internal measurements or shorter. For long time intervals (e.g., yearly) or very volatile returns, the approximation is poor.

**2.1.4 Estimating Prices and Returns**

To estimate a security’s price, $P(t)$, we need prices. Prices, however, depend crucially on the way a market is organized. OTC markets (Harris, 2003) differ from exchanges that use limit-order books (Bouchaud et al., 2018). Within a single exchange, the trading mechanisms can change over the course of the day, with auctions often taking place at the beginning and at the close of the trading day. As a result of market design, the price of a security is not unique. There are many prices. The most common example of ambiguity is the bid-ask spread. In limit-order books, the best bid (ask) price is the price attribute (the “bidding” price per share the buyer is willing to pay) and a quantity. Similarly, the sell orders have a price attribute, or “asking prices,” and a quantity. Buying orders have higher asking prices, and the difference is called the bid-ask spread. This spread is a measure of liquidity. In order for a transaction to occur, a buy order or a sell order must cross the spread; either event can occur. As a result, the transaction price will be either at the top or the bottom of the bid-ask spread interval. Successive transactions will have different prices, even if the value of the asset is constant. Among transactions, the bid-ask spread implies that there is not the only source of randomness in prices. Observed prices can differ by exchanges, and the selection of price by timestamp depends on the choice of data integration. Then, there may be slight measurement errors. It is important to consider the outset the fact that prices are imperfectly observed, and that this imperfection is a source of noise in the returns. This noise is, perhaps, the simplest model is the Roll model for asset prices (Roll, 1984). In this model, $m_t$ is the “true” price. The true asset evolves as an arithmetic random walk, and we imperfectly observe the price $P_t$. In formulas:
$$ m_{t+1} = m_t + \sigma_m \epsilon_{t+1} \quad \text{(evolution)} $$
$$ P_{t+1} = m_{t+1} + \sigma_\eta \eta_{t+1} \quad \text{(observation)} $$
where $\epsilon_{t+1}, \eta_{t+1}$ are random variables, independently distributed (specifically, and from each other) according to a standard normal distribution.

Before we try to estimate prices, the model presents an immediate and testable consequence: consecutive price differences are negatively correlated. The price difference is
$$ \Delta P_{t+1} = P_{t+1} - P_t = (m_{t+1} - m_t) + \sigma_\eta (\eta_{t+1} - \eta_t) $$
which is zero in expectation. However,
$$ E[\Delta P_{t+1} \Delta P_t] = -\sigma_\eta^2 $$
The lag-one autocorrelation, $E[\Delta P_{t+1} \Delta P_t] / \text{Var}(\Delta P_t)$ can also be used to estimate the measurement error. Equation (2.2) can also be used to estimate the measurement error. The presence of large non-zero autocorrelations beyond lag one may point to model inadequacy, in the sense that there are actual long-term dependencies in prices. The true price $m_t$ is not observed. We can estimate it, however, by using the Kalman filter. The Kalman filter is described in the Appendix, Section 2.4, and specifically in Example 2.2 of Section 2.4.2. The estimator is given by
$$ \hat{m}_{t+1|t} = (1-K) \hat{m}_{t|t-1} + K P_t $$
where the optimal formula $K \in (0,1)$ is given in the Appendix. The smaller the ratio $\sigma_m^2 / \sigma_\eta^2$, the higher the $K$, which makes sense: we do not need to average observations if the price observations are accurate. The value of the estimate is an exponentially weighted average of past prices. The value of the estimate $m_t$ is the price in the measurement period. If we want the daily closing price, for example, we may want to use a weighted average of 5-minute interval prices in the preceding intervals. There is a caveat, however. Suppose we have estimates $\hat{m}_n$ and we use these estimates to compute returns
$$ \hat{r}_n := \hat{m}_n / \hat{m}_{n-1} - 1 $$
Because we employ the same observed prices $P_n$ (both in $\hat{m}_n$ and $\hat{m}_{n-1}$), the estimates are positively correlated. One should always check that $(1-K)^2 < 0.5$, otherwise this spurious correlation.

[Image: ACF plots for (a) IBM, (b) MSFT, (c) XOM, (d) AAPL, (e) SPY, (f) XLK. Figure 2.1: Autocorrelation plots of daily log return series (symbols). The horizontal dashed lines delimit the 95% confidence interval for the autocorrelations.]

**2.1.5 Stylized Facts**

Before building the house, we need to look at the bricks, namely, the statistical properties of the single-stock returns. Below we list some “stylized facts” about stock returns and discuss their relevance to risk modeling and management. Returns have a lower signal-to-noise ratio, and their statistical properties of
$$ \tilde{r}(t) = \log(1+r(t)) $$
We focus on the properties of $\tilde{r}(t)$ because they are additive. The uncentered volatility of the log returns is $\tilde{\sigma}(t) = \sqrt{E[\tilde{r}^2(t)]}$. These properties are well known (Cont, 2001; Taylor, 1986; Tsay, 2010; Ruffini-Crouzet et al. (2019)).

1.  Absence of autocorrelations. Logged stock returns are uncorrelated unless you observe prices and returns at time scales at which the market microstructure becomes relevant (say, intraday). See Figure 2.1.
2.  Heavy tails. The unconditional distribution of returns shows heavy tail behavior. That is, the probability of large returns is much larger than the probability of large returns under a normal distribution. This means that the probability of a large return is much higher than what would be consistent with any “thin-tailed” distribution with infinite moments. Examples of sample kurtosis are in Table 2.1. The conditional (say, conditional on the entire past history up to time $t-1$) distribution of returns may have “heavy tails” behavior as well, but with lighter tails than the unconditional one.

**TABLE 2.1**
Sample skewness and kurtosis of daily log returns and “hold” (italic p equals 0.01) confidence intervals estimated using non-parametric bootstrap with replacement (5000 variations). Range: 1/1/2000–12/31/2017.

| Stock | Skewness Left | Skewness Right | Kurtosis Left | Kurtosis Right |
| :---- | :------------ | :------------- | :------------ | :------------- |
| AAPL  | -0.2          | 0.2            | 5.7           | 7.8            |
| IBM   | -0.5          | 0.2            | 3.6           | 3.6            |
| XOM   | -0.4          | 0.3            | 7.1           | 8.7            |
| MSFT  | -0.3          | 0.2            | 5.8           | 8.1            |
| WAT   | -1.0          | -0.3           | 12.8          | 40.1           |
| SPY   | -0.3          | -0.7           | 8.6           | 11.4           |
| XLK   | -0.3          | 0.1            | 6.5           | 16.0           |

Regarding heavy tails for asset returns, we restrict our attention to power-tailed distributions. Then the complement of the cumulative distribution function follows a power law:
$$ P(Z > x) = P(|Z| > x) \approx Cx^{-\alpha} $$
for large $x$, where $Z$ is the random variable (e.g., daily log returns), $C > 0$ is a constant, and $\alpha > 0$ is the tail index. Compare this to a Gaussian return: $P(Z > x)$ is the cumulative distribution function (CDF) of the Gaussian. There is a common approximation (Wasserman, 2004) for the tail probability is
(2.4)
$$ \frac{1}{\sqrt{2\pi}} \frac{1}{x} e^{-x^2/2} \left(1 - \frac{1}{x^2}\right) \le P(Z>x) \le \frac{1}{\sqrt{2\pi}} \frac{1}{x} e^{-x^2/2}, x > 0 $$
The right-side inequality can be used to bound the error in the left tail and the symmetric inequality of the right tail for $x > K$ where $K \approx 0.025$.
(2.5)
$$ P(x) \le \frac{1}{\sqrt{2\pi}} e^{-x^2/2} \left(1 - \frac{1}{x^2}\right) \left(1 - \frac{1}{2x^2} (1 - \frac{1}{x^2})\right)^{-1} $$
(2.6)
$$ P(x) \ge \frac{1}{\sqrt{2\pi}} e^{-x^2/2} \left(1 - \frac{1}{x^2}\right) \sqrt{1 - \frac{2}{x^2} \log(2\sqrt{2\pi} \cdot 1)} $$
The approximation is quite accurate. Let the Cumulative Density Function $F(x) = 1 - P(x)$. We have the bounds
$$ \frac{1}{\sqrt{2\pi}(1+x)} e^{-x^2/2} \le P(x) \le \frac{1}{\sqrt{2\pi}x} e^{-x^2/2} \quad (x > 0) $$
$$ (1-d) < K < 0.025 $$
A Gaussian random variable has finite moments of any order. A power-law random variable with exponent $\alpha$ has finite moments only up to $k < \alpha$. A Gaussian random variable has finite moments of any order. A power-law random variable with exponent $\alpha$ has finite moments only up to $k < \alpha$. If $\alpha \in (2,4]$, the unconditional distribution of log returns has heavy tails. It is still not settled what the exponent $\alpha$ associated with the distribution. It seems, however, that $\alpha \in (2,4]$. This is important for several practical purposes. A sufficient condition for the applicability of the Central Limit Theorem says that if we have $n$ iid random variables with mean $\mu$ and variance $\sigma^2 < \infty$, then their sum converges in distribution to a Gaussian random variable with mean $n\mu$ and variance $n\sigma^2$. The Theorem allows us to establish the asymptotic distribution of estimators. However, if $\alpha \le 2$, then the variance of the returns is infinite. This seems to be the case. However, a related question is whether the conditional distribution is heavy-tailed, and it is possible to model returns as a process with conditional Gaussian returns.

3.  Autocorrelation of absolute returns and second moments. The time series of $|r(t)|$ or $r^2(t)$ shows positive, significant, and slowly decaying autocorrelation functions (the “volatility clustering” effect in the literature (Taylor, 1986; Granger and Ding, 1995)). Thus, large realized return movements persist over time, and so do small realized return movements. This phenomenon is sometimes termed volatility clustering.
4.  Aggregational Gaussianity. At longer time scales (say, weekly or monthly returns, as opposed to daily or intraday returns), the distribution of log returns becomes closer to a Gaussian distribution. Reality, is in stark contrast with simple models of univariate price dynamics like the geometric Brownian motion process or other simple discrete-time models.
    $$ dP(t) = \mu P(t)dt + \sigma P(t)dW(t) $$
    (price change) (drift) (noise)
    This model predicts Gaussian, independent log returns, which are inconsistent with the empirical evidence. First, returns show little serial autocorrelation. This does not mean that returns are independent, nor that returns are unpredictable based on their history. Some authors interpret the absence of autocorrelation as evidence that returns are not serially predictable. Regarding the latter, returns are predictable. This is not only an article of faith of active investors, who usually do a terrible job at it, but also a relatively uncontroversial empirical finding among academics.[7] Nevertheless, even though they are predictable, they are not so linearly predictable.

... heavy-tailed unconditional ones. This family, the Conditional Heteroskedastic Models (CHM), is rich and the subject of the following subsection. We won’t cover models with jumps, which are also popular. We also won’t cover models like Levy processes and FARIMA models. No model covers all the empirical features observed in stock returns. GARCH models (and mixture models in general) have the benefit of being easy to interpret, simulate, and estimate.

---

**2.2 Conditional Heteroskedastic Models**

This family of models was first proposed in the early 1980s by Engle (1982), Engle and Bollerslev (1986). By the mid-1990s they had been generalized and applied in several economic domains.[8] They are extensively covered in any econometrics book.

The most popular and studied model in this family is the GARCH(1,1) model. It has good empirical properties, its theoretical properties have been characterized, and it can be estimated efficiently. It also conveys the gist of the large set of models in this family. The GARCH(1,1) model is a part of the class of stochastic process. The form of the GARCH(1,1) is:
(2.8)
$$ h_t^2 = \alpha_0 + \alpha_1 r_{t-1}^2 + \beta_1 h_{t-1}^2 $$
(2.9)
$$ (\alpha_0 > 0, \alpha_1 \ge 0, \beta_1 \ge 0, \alpha_1 + \beta_1 < 1) $$
In the equations above, $h_t^2$ is the volatility at time $t$ (and $h_{t-1}^2$ is the variance) and it is conditional on the value of $r_{t-1}^2$. The parameters $\alpha_0, \alpha_1, \beta_1$ are constants that need to be estimated. The sum of the parameters $\alpha_1 + \beta_1$ determines by Equation (2.8). To gain some intuition, let us look at the second equation of the GARCH process when we remove the term $r_{t-1}^2$. The equation can be rewritten as:
(2.10)
$$ h_t^2 = \alpha_0 + \beta_1 h_{t-1}^2 $$
$$ h_t^2 - \beta_1 h_{t-1}^2 = (h_t^2 - h_{t-1}^2) + (1-\beta_1) h_{t-1}^2 $$
where
$$ h_t^2 = \frac{\alpha_0}{1-\beta_1} $$
This value $h^2$ converges to $h_t^2$ at a geometric rate, so long as $0 < \beta_1 < 1$. The term $\alpha_1 r_{t-1}^2$ in Equation (2.8) increases the probability of large squared returns in the following period, giving rise to a rich dynamic behavior. The increase in volatility can not continue unabated, because the term $(1-\alpha_1-\beta_1)h_{t-1}^2$ will dampen variances that are much greater than the “equilibrium level” $h^2$. This can be seen through substitution in the second equation of the model.

(2.11)
$$ h_t^2 = h^2 + \alpha_1 \sum_{i=1}^\infty \beta_1^{i-1} (r_{t-i}^2 - h^2) $$
One could replace the true values $h^2, \alpha_1, \beta_1$ with their estimates, and interpret the formula as saying that the current variance an exponential moving average of non-iid squared returns, since they are modulated by $h^2$ in light of Equation (2.11).

**2.2.1 GARCH(1,1) and Return Stylized Facts**

The GARCH(1,1) model improves on the distributional properties of conditional returns by making them closer to the Gaussian distribution, see Figure 2.2. How does the GARCH(1,1) model stack up against the stylized facts?

[Image: Figure 2.2 Quantile-Quantile plot for daily log returns (light gray dots) and GARCH(1,1) (dark gray dots) for (a) AAPL, (b) IBM, (c) XOM, (d) MSFT, (e) SPY, (f) XLK. The theoretical quantiles are from a $t$-distribution with $\nu$ degrees of freedom ($t_\nu(0,0001 \cdot 1.8)$ for XLK).]

1.  Absence of autocorrelations. This property is satisfied (not hard to verify directly).
2.  Heavy tails. The unconditional returns are leptokurtic (Cont, 2001).

In GARCH models (Mikosch and Stărică, 2000), the distribution of the unconditional returns is heavy tailed. In GARCH(1,1) models estimated on daily stock returns, the tail index $\alpha$ of the unconditional returns is often close to a Gaussian distribution; see Table 2.2. The tail indices of $r_t^2$ are also higher than those of $r_t^2$; see Table 2.3. These are desirable properties of GARCH processes.

**TABLE 2.2**
Distances between the theoretical normal distribution and the empirical distribution of the residuals of GARCH(1,1). The distances are produced for all stocks, with the values reported in the table for the two proxies for the market (SPY) and the technology sector (XLK). N.B.: We use the Kolmogorov–Smirnov distance. Background on this statistic can be found from Theil (1971) and Conover (1971, Ch. 6).

| Stock Uncond. | GARCH(1,1) Left parenthesis | GARCH(1,1) Left parenthesis epsilon sub t right parenthesis |
| :------------ | :-------------------------- | :------------------------------------------------------- |
| AAPL          | 0.039                       | 0.041                                                    |
| IBM           | 0.079                       | 0.047                                                    |
| XOM           | 0.060                       | 0.060                                                    |
| MSFT          | 0.061                       | 0.060                                                    |
| WAT           | 0.100                       | 0.091                                                    |
| SPY           | 0.098                       | 0.040                                                    |
| XLK           | 0.091                       | 0.043                                                    |

**TABLE 2.3**
Estimated tail index for left and right tail of probability density
*hold-italic p equals 0.05*, proportional to *hold-italic alpha*, a super-negative *hold-italic alpha*.
We use the Maximum Likelihood Estimator (MLE) *alpha hat* equals one plus *hold-italic alpha* times left square bracket *n* times sum from *i* equals one to *n* of log of *hold-italic x sub i* over *hold-italic x sub min* right square bracket *hold-italic alpha* sub *n* right square bracket super negative one
where *hold-italic x sub min* is the minimum value of *hold-italic x* (Clauset et al. 2009). The value of *hold-italic x sub min* is set to -2.5% and 2.5%, respectively. Estimates of *hold-italic alpha* increase stability for the two indexes SPY and XLK.

| Stock Uncond. | Left Tail GARCH(1,1) *hold-italic alpha* | Right Tail GARCH(1,1) *hold-italic alpha* |
| :------------ | :--------------------------------------- | :---------------------------------------- |
| AAPL          | 4.8                                      | 4.8                                       |
| IBM           | 3.8                                      | 4.2                                       |
| XOM           | 4.0                                      | 4.6                                       |
| MSFT          | 3.9                                      | 3.8                                       |
| WAT           | 3.4                                      | 4.1                                       |
| SPY           | 3.0                                      | 4.2                                       |
| XLK           | 3.0                                      | 4.4                                       |

3.  Autocorrelation of absolute and squared returns. The ACF for GARCH(1,1) is positive for both absolute and squared returns; for squared returns, it has the form (He and Teräsvirta, 1999; Ruppert and Matteson, 2015)
    $$ \rho_k = \begin{cases} \frac{\alpha_1 (1-\alpha_1 \beta_1 - \beta_1^2)}{1-2\alpha_1 \beta_1 - \beta_1^2} & \text{if } n=1 \\ \rho_1 (\alpha_1 + \beta_1)^{k-1} & \text{if } n > 1 \end{cases} $$
    However, the decay for squared returns and squared residuals is too slow. The model appears that the autocorrelation predicted by the model for a given observed horizon level is too high compared to that observed in practice. See Teräsvirta (2009a).
4.  Aggregational Gaussianity. A GARCH process aggregated over longer horizons is GARCH with different parameters and still heavy-tailed (Drost and Nijman, 1993). This is consistent with the autocorrelation issue above: roughly, GARCH has a “long-term memory” that is too long, and not completely in agreement with empirical data.

Summing up, some but not all of the stylized facts about log returns are captured by GARCH(1,1).

**2.2.2 GARCH as Random Recursive Equations**

We now look at GARCH(1,1) through different modeling approaches. First, we could reformulate it as a random-iterated function. Rewrite Equation (2.8) as
$$ h_t^2 = \alpha_0 + \alpha_1 \epsilon_{t-1}^2 h_{t-1}^2 + \beta_1 h_{t-1}^2 $$
Set
$$ a_t := \beta_1 + \alpha_1 \epsilon_t^2, \quad b_t := \alpha_0 $$
The random variables $a_t, b_t$ are iid. Then
$$ h_t^2 = a_{t-1} h_{t-1}^2 + b_{t-1} $$
This formulation shows that the process is a linear state-space model and also that it is governed by an autoregressive moving average with random coefficients. By recursive iteration (Embrechts, 2006), we can rewrite the equations as
$$ h_t^2 = (\prod_{j=0}^{k-1} a_{t-j}) h_{t-k}^2 + \sum_{j=0}^{k-1} (\prod_{i=0}^{j-1} a_{t-i}) b_{t-j-1} $$
This allows us to study the process using the toolkit of random recursive equations.[12]
The distribution of $\log a_t$ plays the essential role in the convergence of the process. Nelson (1990) characterizes the conditions for convergence. In the case $\alpha_0 > 0$:
1.  If $E[\log a_t] < 0$, then $h_t^2 \xrightarrow{d} h^2$, where $h^2$ is a non-degenerate distribution.
2.  If $E[\log a_t] \ge 0$, then $h_t^2 \xrightarrow{p} \infty$ as $t \to \infty$.
3.  If $E[\log a_t] = 0$, then $h_t^2$ converges to a non-degenerate distribution with support on $[h_0^2/(1-\beta_1), \infty)$.
The kurtosis of the process is
$$ \frac{3(1-(\alpha_1+\beta_1)^2)}{1-(\alpha_1+\beta_1)^2 - 2\alpha_1^2} - 3 = \frac{6\alpha_1^2}{1-3\alpha_1^2 - 2\alpha_1\beta_1 - \beta_1^2} > 0 $$
as long as $\alpha_1 > 0$, so that the process is leptokurtic. How about skewness? The unconditional returns are not skewed, because
$$ E(r_\infty - E(r_\infty))^3 = E(h_\infty^3) E(\epsilon_\infty^3) = 0 $$
Finally, we point out that not only are the unconditional returns leptokurtic, but they do in fact have Pareto tails, provided the process is stationary: $P(r_t > x) \sim C x^{-\kappa}$ for some $\kappa > 0$, see Mikosch and Stărică (2000); Basrak, Buczkowski et al. (2008).

**2.2.3 GARCH(1,1) Estimation**

Although GARCH models are highly general, the vast majority of CHM applications use GARCH(1,1). This is not an accident. GARCH(1,1) is easy to estimate, and its properties are well understood. Generalization to higher-order models is straightforward. Define $\theta = (\alpha_0, \alpha_1, \beta_1)$, and let $f$ be the log-density function of the standard normal distribution.
$$ \tilde{r}_t = h_t \epsilon_t $$
$$ h_t^2 = \alpha_0 + \alpha_1 \tilde{r}_{t-1}^2 + \beta_1 h_{t-1}^2 $$
where $h_0^2$ is defined by the right-hand side in Equation (2.10). By repeated substitution, we can express the unobserved variance $h_t^2$ as a function of the sequence $\tilde{r}_1, \dots, \tilde{r}_{t-1}$ and $\theta$. The log-likelihood of the sequence $\tilde{r}_1, \dots, \tilde{r}_T$ is
$$ L(\theta) = \sum_{t=1}^T f\left(\frac{\tilde{r}_t}{h_t(\tilde{r}_1, \dots, \tilde{r}_{t-1}, \theta)}\right) $$
We can then estimate the parameters $\theta$ of the model by maximizing the log-likelihood. As an example, consider the GARCH(1,1) model. The recursive equation for $h_t^2$ is given by Equation (2.11). We solve

$$ \min_\theta \sum_{t=1}^T \left( \log h_t^2(\theta) + \frac{\tilde{r}_t^2}{h_t^2(\theta)} \right) $$
s.t. $h_t^2 = (1-\beta_1)h^2 + \alpha_1 \sum_{i=1}^\infty \beta_1^{i-1} (\tilde{r}_{t-i}^2 - h^2)$, $i=1, \dots, T$

**2.2.4 Realized Volatility**

CHMs model the asset volatility as an (unobserved) state of the return stochastic process. Once we have an estimate of the volatility at time $t-1$ returns, the next arrival. An alternative route would be to estimate directly the volatility of the returns. This is the approach taken by realized volatility (RV) measures. This approach would not work if the time intervals at which we need the estimates are days, and we only have daily data. In recent years, tick-level price data have become widely available; indeed, order-book-level data are also available with high-frequency price data or order arrivals, trades, and cancellations. Realized volatility is computed non-parametrically, making it possible to estimate the volatility of daily returns by using these high-frequency data. Below we review some of the statistical properties of realized volatility (RV) measurements. The starting point is Equation (2.7), i.e., a diffusion process for the log price $p(t) = \log P(t)$
$$ dp = \alpha dt + \sigma dW $$
where $W(t)$ is a Brownian motion process, the term $\alpha dt$ is the drift, and $\sigma > 0$ is the volatility. We are interested in estimating $\sigma$. In practice, the drift is much smaller than the volatility ($|\alpha| \ll \sigma$). The quantity $\sigma/\sqrt{n}$ is termed the Sharpe Ratio and will figure prominently in the rest of the book. We observe the process in the interval $[0, T]$ and measure the state variable $p$ at intervals of length $T/n$. The measured returns are
$$ r(j) = p(j T/n) - p((j-1)T/n) $$
The RV is an unbiased estimator of $\sigma^2$.
$$ RV(n) = \frac{n}{T} \sum_{j=1}^n r(j)^2 \sim N(\sigma^2, \sigma^4/n) $$
The MLEs for drift and moments are
[Eq. 2.16]
$$ \hat{\alpha} = \frac{1}{T} \sum_{j=1}^n r(j) = \frac{1}{T} (p(T) - p(0)) $$
$$ \hat{\sigma}_n^2 = \frac{1}{T} \sum_{j=1}^n (r(j) - \hat{\alpha}/n)^2 $$
We also consider the uncentered estimator of the volatility $\hat{\sigma}_n^2$.
The first remarkable phenomenon is that the MLE for the drift, Equation (2.16), does not depend on the number of intermediate observations. Since our focus is on volatility, we assume $\alpha=0$. Then
$$ \text{Var}(\hat{\alpha}) = \text{Var}(p(T)-p(0)) = \sigma^2 T $$
and
$$ p(T) - p(0) \sim N(0, \sigma^2 T) $$
, so that $\text{Var}(\hat{\alpha}) = \sigma^2 T$. The estimation error does not depend on the number of intermediate observations $n$. To estimate the variance of $\hat{\sigma}_n^2$, we need a bit of gymnastics. The variance of $\hat{\sigma}_n^2$ is the sum of $n$ terms of a chi-square random variable with mean $\sigma^4/n$ and variance $2\sigma^8/n^2$.
(2.17)
$$ E[\hat{\sigma}_n^2] = \sigma^2 $$
(2.18)
$$ E[(\hat{\sigma}_n^2)^2] = \sigma^4 \left(1 + \frac{2}{n}\right) + \frac{\sigma^4}{n} \left(\frac{\alpha T}{n \sigma^2}\right)^2 $$
so that
(2.19)
$$ \text{Var}(\hat{\sigma}_n^2) = \frac{2\sigma^4}{n} \left(1 + \frac{2}{n}\right) + \frac{2\sigma^4}{n^2} \left(\frac{\alpha T}{n \sigma^2}\right)^2 $$
and
$$ E[\hat{\sigma}_n^2] = \sigma^2 + \frac{\sigma^2}{n} \quad \text{from Equation (2.17)} $$
$$ \text{Var}(\hat{\sigma}_n^2) = \frac{2\sigma^4}{n} \left(1 + \frac{4}{n}\right) + \frac{\sigma^4}{n^2} \quad \text{from Equation (2.19)} $$
The estimator $\hat{\sigma}_n^2$ has a small finite-sample bias and is asymptotically consistent.

**Insight 2.1: Estimating variance**
Based on Equations (2.17), (2.18), and (2.19), you can use uncentered returns for variance estimation, since the bias is inversely proportional to $n$, and the estimator is consistent.

Let us reflect on the steps we took. We discretized the interval over which the price process evolves into $n$ sub-intervals of length $T/n$. We assumed the price had no measurement error. We saw that the drift estimator is unbiased, but its variance does not depend on the discretization, $n$. We saw that the drift estimator is unbiased, but its variance does not depend on the discretization, $n$; there is no easy way to measure the drift, but they are noisy. Unfortunately, there is no easy way to measure the drift. It is estimated by returns, which have variance $\sigma^2 T$. We have used an uncentered estimator of the true variance $\sigma^2$. As the number of intervals approaches infinity, the estimator is unbiased, its variance decreases like $2\sigma^4/n$, which is good news in principle. We can use estimates to address daily volatility using very short time intervals, and we can combine these estimates to get an estimate of volatility over longer periods. If you need volatility estimates over a long time scale for your decisions (e.g., days), but have data over a shorter time scale (e.g., minutes), you do not have to throw a generative model like CHMs or others. What assumptions do not hold in this line of reasoning? There is a list of issues to consider:
1.  Intraday market microstructure. One source of noise is the bid-ask spread (Harris, 2003). When the buyer initiates a transaction, he pays the ask price. When the seller initiates it, he receives the bid price. There is an intrinsic error in the measurement of price, which is systematically biased toward the bid-ask spread. The model error by assuming that log returns are iid normal, when the noise terms $\eta_t$ are independent, identically distributed random variables.
2.  Another form of microstructure imperfection is thinly traded securities. If a stock trades less than once every 5 minutes on average, using 1-minute returns is probably not a good modeling choice.
3.  We assumed that volatility is changing slowly, or is ideally constant. This is not the case in practice. One approach is to impose a model on the time series of realized variances, so that we can produce out-of-sample forecasts. For example, a simple AR(1) model
    $$ \sigma_{t+1}^2 = \alpha + \beta \sigma_t^2 + \epsilon_{t+1} $$
    where $\epsilon_{t+1} \sim N(0,1)$.
4.  We ignored the distinction between open-to-close and close-to-open intervals. Close-to-open returns are often fundamentally driven. Also, we are ignoring the large volatility and bid-ask spreads in the first minutes of the trading day.

For the interested reader, McAleer and Medeiros (2008) and Andersen et al. (2013) compare a broad set of estimators, with several choices of parameters, for assets in different asset classes (equities, futures, indices). They use Romano and Wolf’s procedure for multiple comparison (Romano and Wolf, 2005) and the “model confidence set” (Hansen et al., 2011). They conclude that the RV estimator performs competitively across various assets and asset classes.[13]

---

**2.3 State-Space Estimation of Variance**

**2.3.1 MA(q) Original Model EWMA**

A very popular estimator of the expected value of a time series $\{x_t\}$ based on data up to time $t-1$ is the exponentially weighted moving average (EWMA). It takes the form
$$ \hat{x}_t = (1-K) \sum_{j=0}^\infty K^j x_{t-j-1} $$
for some $K \in (0,1)$. We discount the past by giving its observations exponentially decreasing weights, which makes sense, and even more so when we write the estimate as a recursion:
$$ \hat{x}_t = (1-K) x_{t-1} + K \hat{x}_{t-1} $$
A low value of $K$ forgets the past faster. The formula is computationally efficient both in terms of storage and of computation. For the uncentered variance estimation of a return, this takes the form:
(2.22)
$$ \hat{\sigma}_t^2 = (1-K) r_{t-1}^2 + K \hat{\sigma}_{t-1}^2 $$
**Insight 2.2: GARCH vs EWMA with an offset**
Recall Equation (2.11):
$$ h_t^2 = \frac{\alpha_0}{1-\beta_1} + \alpha_1 \sum_{j=1}^\infty \beta_1^{j-1} (r_{t-j}^2 - \frac{\alpha_0}{1-\beta_1}) $$
This is, save for an offset, very similar to Equation (2.22):
$$ \hat{\sigma}_t^2 = (1-K) \sum_{j=0}^\infty K^j r_{t-j-1}^2 $$
(we have changed the indexing convention to make it consistent with GARCH). The two are identical when $\alpha_0 = 0$, $\alpha_1 = 1-K$, and $\beta_1 = K$. Why not use GARCH then, provided that estimating the parameters per asset is doable? There is no fundamental objection. Commercial models favor simplicity (the half-life in each model, respectively $1/\log(1/K)$ or $1/\log(1/\beta_1)$ is often set to 20-60 days). If $K$ is chosen appropriately, the value of $\hat{x}_t$ is close to $h_t^2$, or because the performance improvement is not high enough to justify the additional complexity in parameter estimation and, in the case of commercial models, communication of the model’s characteristics to clients.
The half-life $T_{1/2}$ is such that $K^{T_{1/2}} = 1/2$, i.e., $T_{1/2} = \log(1/2) / \log K$.

In academic journals, GARCH receives relatively low attention compared to CARCH models. For example, RiskMetrics (J.P. Morgan, 1996) uses EWMA for forecasting volatility, including major commercial risk systems like RiskMetrics, Barra, and Axioma. It is the other way around. Aside from these practical considerations, is it possible to motivate the approach based on a model? We devote this section to understanding and extending this simple formula.

We will employ linear state-space models and Kalman filters, which are briefly covered in the Appendix, Section 2.4. Rather than giving a full general treatment, we will focus on a specific example. It is a simple model, but it is rich enough to illustrate the main ideas. As it happens, this example is also the simplest non-trivial example of a state-space model. The model (Muth, 1960) posits that there is a scalar state $x_t$ that evolves randomly over time with the addition of a Gaussian disturbance to its previous value. We observe the state imperfectly; the observation $y_t$ is a noisy measurement of $x_t$. In formulas:
$$ x_{t+1} = x_t + \tau_w \epsilon_{t+1} $$
$$ y_{t+1} = x_{t+1} + \tau_v \eta_{t+1} $$
$$ \epsilon_t \sim N(0,1), \quad \eta_t \sim N(0,1) $$
The innovations and the measurement noises are Gaussian with mean zero, and they are independent of each other (i.e., $\epsilon_t \perp \eta_s$ for all $t$ and $s$, and $\epsilon_t \perp \epsilon_s$ for all $t \ne s$, and $\eta_t \perp \eta_s$ for all $t \ne s$). I skipped the derivation; the interested reader can find it in the Appendix. Define the ratio of measurement to innovation noise as $\kappa := \tau_v^2 / \tau_w^2$. The stationary MLE estimate of the variance is given by
$$ \sigma_{t+1|t}^2 = \tau_w^2 \frac{1 + \sqrt{1 + (2\kappa)^2}}{2\kappa} $$
$$ \sigma_{t|t}^2 = \tau_w^2 \frac{1}{2\kappa} $$
and the optimal estimation recursion is
$$ K_t := \frac{\sigma_{t|t-1}^2}{\sigma_{t|t-1}^2 + \tau_v^2} $$
$$ \hat{x}_{t+1|t} = (1-K_t) \hat{x}_{t|t-1} + K_t y_t $$
The relationship between the measurement/innovation noise and $K_t$ is illustrated in Figure 2.3 for $y_t$ formula simplifies.

[Image: Figure 2.3 Relationship between $K$ and $\kappa := \tau_v^2 / \tau_w^2$. Plot shows K decreasing from 1 to 0 as kappa increases from 0 to 10.]

This is an exponential weighted average with a simple interpretation. Imagine that the state does not change at all. Then we want to use all of the history we can, since old observations and new ones are drawn from the same distribution. The half-life of EWMA is indeed long. Conversely, when the state changes at a rapid pace, i.e., $\kappa \ll 1$, then we want to discount the past very aggressively.

According to Muth’s original model applied to volatility estimation, the state is the instantaneous variance, and the observation $y_t$ is $r_t^2$, which is equal to $\sigma_t^2$ in expectation.

The model has obvious shortcomings. If returns are normally distributed, then the observation error is not normally distributed. More importantly, the model allows for negative values of the variance, and does not realistically model the evolution of the sum of iid innovations. Over time, the distribution of the variance becomes increasingly spread out: the standard deviation of the distribution grows as the square root of the number of periods. In practice, however, volatility appears to revert to its long-term average.

We cannot directly address the first problem. However, Kalman filters can work well with non-normal innovations and measurement errors, provided that these are not too heavy-tailed. As for the other shortcomings, we can refine the model to accommodate them. For example, we can introduce a mean-reverting model of variance, so that it behaves like an autoregressive process. We slightly extend the state equation by adding a mean-reversion term:
$$ x_{t+1} = \lambda x_t + (1-\lambda)\mu + \tau_w \epsilon_{t+1}, \quad \lambda > 0 $$
The state reverts to value $\mu$ when it is away from this equilibrium value. The stationary distribution of $x_t$ is Gaussian, with the expected value equal to $\mu$ and standard deviation equal to $\tau_w / \sqrt{1-\lambda^2}$. The optimal variance estimator is still
$$ \hat{x}_{t+1|t} = (1-K_t) \hat{x}_{t|t-1} + K_t y_t $$
However, compared to the first model, the value of $K_t$ is smaller. Otherwise stated, the mean reversion term makes the distribution of the true variance more concentrated around its long-term mean. This implies that we discount the past less. The detailed derivation of these formulas is in the Appendix, Section 2.4.2.

**2.3.2 The Harvey-Shepherd Model**

As a final example of the flexibility that linear state-space models can offer, I present the model by Harvey and Shephard (1996), which has several desirable features: it has a closed-form solution, the volatility is by design positive and the distribution of the volatility itself is log-normal, hence right-skewed, as we would expect, and the stock returns are locally log-normal.
The generating process for returns $r_t$ is assumed to be
(2.23)
$$ r_t = \exp(x_t/2) \xi_t - 1 $$
where $\beta$ is a known constant, and $\xi_t \sim N(0,1)$. Hence, returns are, at any point in time, log-normally distributed. Define
$$ u_t := \log(1+r_t) - \beta $$
$$ \Rightarrow \quad \log u_t^2 = x_t + \log \xi_t^2 $$
where
$$ \gamma := E(\log \xi_t^2) \approx -1.27 $$
, and $\xi_t$ is a zero-mean random variable with standard deviation given by
$$ \text{stdev}(\log \xi_t^2) \approx 2.22 $$
Define
$$ y_t := \log u_t^2 - \gamma $$
$$ y_t = [\log(1+r_t) - \beta]^2 - \gamma $$
so that we get an observation equation:
$$ y_t = x_t + \eta_t $$
Now, we posit an evolution equation for $x_t$:
$$ x_{t+1} = b + a x_t + \epsilon_t $$
This is the same model as (2.8), from which we obtain an estimate $\hat{x}_{t+1|t}$. If $\beta=0$, then the formulas take a simple form for $y_t = \log(1+r_t)$, and the state estimate is given by
$$ \hat{x}_{t+1|t} = (1-K) \hat{x}_{t|t-1} + K [\log(1+r_t)] - \gamma $$
Since
$$ r_t = \exp(\hat{x}_{t|t-1}/2) \xi_t - 1 $$
is a log-normal random variable, the estimated standard deviation of $r_t$ is
$$ \hat{\sigma}_{t+1|t} = \sqrt{(\exp(\hat{\sigma}_{\hat{x}_{t+1|t}}^2) - 1) \exp(2\hat{x}_{t+1|t})} $$
A simplified Harvey-Shepherd model starts with Equation (2.23), in which it assumes the first-order approximation $\gamma^2-1 \approx \gamma$, and the parameter $\beta=0$
$$ r_t = \exp(x_t/2) \xi_t $$
Define
$$ \log r_t^2 = x_t + \log \xi_t^2 $$
$$ = x_t + \eta_t + \gamma $$
where $\eta_t$ and $\xi_t$ are defined as for the Harvey-Shepherd model above. The model is completed by the following equations, also from the original model:
$$ x_{t+1} = b + a x_t + \epsilon_t $$
$$ y_t = \log r_t^2 - \gamma $$
The state and volatility estimates are
$$ \hat{x}_{t+1|t} = (1-K) \hat{x}_{t|t-1} + K [\log r_t^2 - \gamma] $$
$$ \hat{\sigma}_{t+1|t}^2 = e^{\hat{x}_{t+1|t}/2} $$

---

**2.4 Appendix**

**2.4.1 The Kalman Filter**

This section contains a short treatment of the Kalman filter (KF). The KF is in its modern form dates to the early 1960s, with work by Kalman (1960a,b). Its intellectual lineage can be traced back to Gauss’s work on least squares. It has become available that made calculations feasible in real time. This made the rediscovery of the filter by Kalman very timely. Rockets used by the Apollo program contained implementations of the KF as early as 1968. Since then, the study of linear control and filtering has blossomed. There are several excellent books on the KF, and there are several monographs covering the KF in detail from different viewpoints: econometric (Whittle, 1996; Simon, 2006), statistical (Harvey, 1993), and econometric (Hansen and Sargent, 2013). I cover the KF because, for somewhat mysterious reasons, the derivation of the KF is often more complicated than it should be. A rigorous, yet accessible proof essentially fits in half a page and should save the reader a few hours.

We need the following elementary fact. Let $\mathbf{z}' = [\mathbf{x}', \mathbf{y}']'$ be a multivariate normal random vector with mean and covariance matrix
$$ \mu_{\mathbf{z}} = \begin{bmatrix} \mu_{\mathbf{x}} \\ \mu_{\mathbf{y}} \end{bmatrix}, \quad \text{COV}(\mathbf{z}) = \Sigma_{\mathbf{z}} = \begin{bmatrix} \Sigma_{\mathbf{x}\mathbf{x}} & \Sigma_{\mathbf{x}\mathbf{y}} \\ \Sigma_{\mathbf{y}\mathbf{x}} & \Sigma_{\mathbf{y}\mathbf{y}} \end{bmatrix} $$
The random vector $\mathbf{x}$, conditional on $\mathbf{y}=\mathbf{b}$, is still normally distributed, with conditional mean and covariance matrix equal to
(2.24)
$$ E(\mathbf{x}|\mathbf{y}=\mathbf{b}) = \mu_{\mathbf{x}} + \Sigma_{\mathbf{x}\mathbf{y}} \Sigma_{\mathbf{y}\mathbf{y}}^{-1} (\mathbf{b} - \mu_{\mathbf{y}}) $$
(2.25)
$$ \text{COV}(\mathbf{x}|\mathbf{y}=\mathbf{b}) = \Sigma_{\mathbf{x}\mathbf{x}} - \Sigma_{\mathbf{x}\mathbf{y}} \Sigma_{\mathbf{y}\mathbf{y}}^{-1} \Sigma_{\mathbf{y}\mathbf{x}} $$
This can be verified directly by integration.

Our model has two components. The first is a state, represented by a random vector $\mathbf{x}_t$. This vector follows a simple evolution rule: $\mathbf{x}_{t+1} = A \mathbf{x}_t + \epsilon_{t+1}$. The vector $\epsilon_t$ is random, serially independent (i.e., $\epsilon_t \perp \epsilon_s$ for $t \ne s$), and distributed according to a multivariate normal distribution. The state $\mathbf{x}_t$ is not observable directly; the only thing we know is its probability distribution at time $t$. We assume its mean is $\hat{\mathbf{x}}_{t|t-1}$ and its covariance matrix is $\Sigma_{t|t-1}$. The second component is a vector $\mathbf{y}_t$, which is a linear transformation of $\mathbf{x}_t$, corrupted by noise:
$$ \mathbf{y}_{t+1} = B \mathbf{x}_{t+1} + \eta_{t+1} $$
Once you read Chapter 5, you will note the similarity with the factor model equation:
$$ \text{state} \leftrightarrow \text{factor return} $$
$$ \text{observation} \leftrightarrow \text{asset return} $$
The vector $\eta_t$ is random, serially independent, independent of $\epsilon_t$ ($ \eta_t \perp \epsilon_s, \dots$), and distributed according to a multivariate normal distribution.
Summing up, the distributions of $\mathbf{x}_t, \epsilon_t, \eta_t$ are given by
$$ \mathbf{x}_t \sim N(\hat{\mathbf{x}}_{t|t-1}, \Sigma_{t|t-1}) $$
$$ \epsilon_t \sim N(0, \Sigma_\epsilon), \quad \eta_t \sim N(0, \Sigma_\eta), \quad t \ne s $$
and the linear state-space model is given by
(2.26)
$$ \mathbf{x}_{t+1} = A \mathbf{x}_t + \epsilon_{t+1} $$
(2.27)
$$ \mathbf{y}_{t+1} = B \mathbf{x}_{t+1} + \eta_{t+1} $$
I denote $\hat{\mathbf{x}}_{t+1|t}$ the conditional estimates for the mean and covariance matrix of the state $\mathbf{x}_{t+1}$, based on information $\mathcal{F}_t = \{\mathbf{y}_1, \dots, \mathbf{y}_t\}$. And I denote $\hat{\mathbf{x}}_{t+1|t+1}$, the estimates based on information $\mathcal{F}_{t+1}$.
The vector $\mathbf{z}_t$ is defined as the combination of state and observation:
$$ \mathbf{z}_t := \begin{bmatrix} \mathbf{x}_t \\ \mathbf{y}_t \end{bmatrix} $$
Based on information up to time $t-1$, the covariance of $\mathbf{z}_t$ is
$$ \text{Cov}(\mathbf{z}_t) = \begin{bmatrix} \Sigma_{t|t-1} & \Sigma_{t|t-1} B' \\ B \Sigma_{t|t-1} & B \Sigma_{t|t-1} B' + \Sigma_\eta \end{bmatrix} $$
We observe $\mathbf{y}_t$. The vector $\mathbf{x}_t$ is normally distributed. We compute the conditional covariance of $\mathbf{x}_t$ given $\mathbf{y}_t$ using Equations (2.24) and (2.25).
$$ \Sigma_{t|t} = \Sigma_{t|t-1} - \Sigma_{t|t-1} B' (B \Sigma_{t|t-1} B' + \Sigma_\eta)^{-1} B \Sigma_{t|t-1} \quad \text{(update step)} $$
$$ = \Sigma_{t|t-1} (I - B' (B \Sigma_{t|t-1} B' + \Sigma_\eta)^{-1} B \Sigma_{t|t-1}) $$
$$ \hat{\mathbf{x}}_{t|t} = \hat{\mathbf{x}}_{t|t-1} + \Sigma_{t|t-1} B' (B \Sigma_{t|t-1} B' + \Sigma_\eta)^{-1} (\mathbf{y}_t - B \hat{\mathbf{x}}_{t|t-1}) $$
Once we have the posterior distribution given the observation $\mathbf{y}_t$, the conditional distribution of $\mathbf{x}_{t+1}$ follows from Equation (2.26) is Gaussian with the following conditional mean and covariance matrix:
(2.28)
$$ \Sigma_{t+1|t} = A \Sigma_{t|t} A' + \Sigma_\epsilon \quad \text{(prediction step)} $$
(2.29)
$$ \hat{\mathbf{x}}_{t+1|t} = A \hat{\mathbf{x}}_{t|t} + A \Sigma_{t|t-1} B' (B \Sigma_{t|t-1} B' + \Sigma_\eta)^{-1} (\mathbf{y}_t - B \hat{\mathbf{x}}_{t|t-1}) $$
The measurement and time update equations above are the whole of the KF. If we combine Equation (2.28) and (2.29), the covariance matrix evolves according to the equation
$$ \Sigma_{t+1|t} = A \Sigma_{t|t-1} A' - A \Sigma_{t|t-1} B' (B \Sigma_{t|t-1} B' + \Sigma_\eta)^{-1} B \Sigma_{t|t-1} A' + \Sigma_\epsilon $$
This is called a Riccati recursion. In steady state the covariance matrix does not change in consecutive periods: $\Sigma_{t+1|t} = \Sigma_{t|t} = \Sigma$. We can solve for the stationary matrix
$$ \Sigma = A \Sigma A' - A \Sigma B' (B \Sigma B' + \Sigma_\eta)^{-1} B \Sigma A' + \Sigma_\epsilon $$
This is a discrete-time algebraic Riccati equation.
The matrix
$$ K_t = \Sigma_{t|t-1} B' (B \Sigma_{t|t-1} B' + \Sigma_\eta)^{-1} $$
is called the optimal Kalman gain. The equations become
(2.30)
$$ \Sigma_{t|t} = (I - K_t B) \Sigma_{t|t-1} $$
(2.31)
$$ \hat{\mathbf{x}}_{t|t} = (I - K_t B) \hat{\mathbf{x}}_{t|t-1} + K_t \mathbf{y}_t $$
(2.32)
$$ \hat{\mathbf{x}}_{t+1|t} = A \hat{\mathbf{x}}_{t|t} = A \Sigma_{t|t} A' + \Sigma_\epsilon $$
(p. 93) $\hat{\mathbf{x}}_{t+1|t} = A \hat{\mathbf{x}}_{t|t}$

**2.4.2 Kalman Filter Examples**

Example 2.1:
(Muth, 1960)
$$ x_{t+1} = x_t + \tau_w \epsilon_{t+1} $$
$$ y_{t+1} = x_{t+1} + \tau_v \eta_{t+1} $$
This is the simplest possible state-space model. The stationary estimate $\hat{\sigma}_{t+1|t}^2$ is given by the solution to the Riccati equation:
$$ \hat{\sigma}_{t+1|t}^2 = \tau_w^2 \frac{1+\sqrt{1+(2\kappa)^2}}{2\kappa} $$
$$ \hat{\sigma}_{t|t}^2 = \tau_w^2 \frac{1}{2\kappa} $$
$$ K = \frac{\hat{\sigma}_{t|t-1}^2}{\hat{\sigma}_{t|t-1}^2 + \tau_v^2} $$
$$ \hat{x}_{t+1|t} = (1-K) \hat{x}_{t|t-1} + K y_t $$
where we have reintroduced the parameter
$$ \kappa = \tau_v^2 / \tau_w^2 $$
Loosely, this is a noise-to-signal ratio. $K$ is high when the measurement error is high compared to the optimal change of the state per period. For $\kappa \gg 1$, the formula simplifies to $K \approx 1/(1+\kappa)$.
$$ \hat{x}_{t|t} = \frac{\kappa}{1+\kappa} \hat{x}_{t|t-1} + \frac{1}{1+\kappa} y_t $$
Example 2.2:
(AR(1) model) In this model, the state equation is
$$ x_{t+1} = \alpha x_t + \tau_w \epsilon_{t+1} $$
If there is a mean-reverting process, introduce a long-term mean value $\mu > 0$ and a situation contains $\lambda = \beta_1$, and set
$$ (y_t|\mathcal{F}_{t-1}) \sim N(\mu, \lambda) $$
Equation (2.26) becomes
$$ x_{t+1} = \lambda x_t + (1-\lambda)\mu + \tau_w \epsilon_{t+1} $$
The state reverts to value $\mu$ when it is away from this equilibrium value. The stationary distribution of $x_t$ is Gaussian, with mean $\bar{\mu}$ and standard deviation $\tau_w / \sqrt{1-\lambda^2}$.
Define
(2.33) $u_t := x_t - \bar{\mu}$
(2.34) $v_t := y_t - \bar{\mu}$
We rewrite the equation as
$$ u_{t+1} = \lambda u_t + (1-\lambda)(\mu - \bar{\mu}) + \tau_w \epsilon_{t+1} $$
$$ v_{t+1} = u_{t+1} + (1-\lambda)(\mu - \bar{\mu}) + \tau_v \eta_{t+1} $$
The state-space equations are
$$ u_{t+1} = a u_t + \tau_w \epsilon_{t+1} $$
$$ v_{t+1} = u_{t+1} + \tau_v \eta_{t+1} $$
The Riccati equation is
$$ (1-\kappa^2) \hat{\sigma}_{t+1|t}^4 - \tau_w^2 \hat{\sigma}_{t+1|t}^2 - \tau_w^4 = 0 $$
$$ \Rightarrow \quad \hat{\sigma}_{t+1|t}^2 = \frac{\tau_w^2}{2(1-\kappa^2)} [1 + \sqrt{1+4(1-\kappa^2)}] $$
$$ = \frac{\tau_w^2}{2(1-\kappa^2)} [1 + \sqrt{1+4\kappa^2-4\kappa^4}] $$
$$ = \frac{\tau_w^2}{2(1-\kappa^2)} [1 + \sqrt{(1-2\kappa^2)^2 + 4\kappa^2(1-\kappa^2)}] $$
$$ = \frac{\tau_w^2}{2(1-\kappa^2)} [1 + \sqrt{(1-2\kappa^2)^2}] $$
$$ = \frac{\tau_w^2}{2(1-\kappa^2)} [1 + |1-2\kappa^2|] $$
$$ = \begin{cases} \frac{\tau_w^2}{1-\kappa^2} & \text{if } |1-2\kappa^2| = 1-2\kappa^2 \\ \frac{\tau_w^2 \kappa^2}{1-\kappa^2} & \text{if } |1-2\kappa^2| = -(1-2\kappa^2) \end{cases} $$
$$ = \tau_w^2 \frac{1}{1-\kappa^2} \left(1 - \frac{2\kappa}{1+\sqrt{1+(2\kappa)^2}}\right) $$
$$ K = \frac{\hat{\sigma}_{t|t-1}^2}{\hat{\sigma}_{t|t-1}^2 + \tau_v^2} $$
Now replace $K_t$ using Equation (2.30) and (2.32).
$$ \hat{x}_{t+1|t} = (1-K) \hat{x}_{t|t-1} + K y_t $$
For $\kappa \ll 1$, the formula is identical to that of Example 2.1. It is straightforward to verify that $K_t$ is decreasing in $\kappa$, and consequently also $K$ is decreasing in $\alpha$. There are two insights to be drawn from this:
1.  The EWMA is still an optimal estimator for a mean-reverting model of volatility.
2.  In the process of mean reversion, $K$ decreases, everything else being equal. We discount the past less, because mean reversion causes future conditional volatility to be more concentrated than past conditional volatility is emerging less from past data, and observations become more informative.

---

**2.5 Exercises**

**Exercise 2.1:**
Prove that
$$ \left[ \prod_{t=1}^T (1+r_t) \right]^{1/T} - 1 \le \frac{1}{T} \sum_{t=1}^T r_t $$

**Exercise 2.2:**
Provide an example of two random variables that are uncorrelated but dependent.

**Exercise 2.3:**
Provide a second example, employing an entirely different rationale for the lack of correlation from the first one.

**Exercise 2.4:**
With respect to Equation (2.10), prove that if $E[h_0^2]$ is finite, i.e., $E[h_0^2] < \infty$, a stationary distribution exists, i.e.,
$$ E_t[\log(\beta_1 + \alpha_1 \epsilon_t^2)] < 0 $$
(Hint: Use Jensen’s inequality.)

**The Takeaways**

1.  Importance of Univariate Models. Understanding single-asset returns is foundational for modeling portfolio returns, especially in terms of volatility. GARCH and exponential moving averages are key tools for this.
2.  Types of Returns. Definitions include simple returns, dividend-adjusted returns, compounded returns, and log returns. Excess returns, adjusted for a risk-free rate, are also essential in portfolio management.
3.  Stylized Facts of Returns. Common features of returns include a lack of autocorrelation, heavy tails, volatility clustering, and aggregational Gaussianity.
4.  GARCH Models. GARCH(1,1) captures some stylized facts like heavy tails and volatility clustering, but has limitations, such as overly high long-term memory.
5.  Realized Volatility. Estimating volatility directly using high-frequency data (e.g., tick or minute-by-minute) is effective, though market microstructure effects (e.g., bid-ask spreads) and thinly traded securities pose challenges.
6.  EWMA as a Volatility Estimator. Exponentially weighted moving averages offer a practical, interpretable method for estimating volatility, often used in commercial risk systems.
7.  State-Space Models. Kalman filters and state-space models provide a structured way to estimate time-varying volatility, allowing for enhancements like mean reversion in volatility.

**Notes** (Right Sidebar from Page 99)

1.  This word comes from the Latin *summaarius*, or “a number”.
2.  Defined in Section 1.2.
3.  Geometric returns and dividend-adjusted returns are in Connor et al. (2010) and Ruppert and Matteson (2015).
4.  The two rates are not exactly the same: when borrowing, the effective rate charged to the borrower by the lending institution is the risk-free rate plus a spread; when lending (holding cash), the rate paid to the investor is the risk-free rate minus a spread. For modeling purposes, we consider them identical.
5.  As of publication time, the minimum tick size is $0.01 in U.S. exchanges for stocks trading above $1.
6.  A detailed discussion of the Roll model and its extensions is in Hasbrouck (2007).
7.  Note, however, that I am not including the leverage effect among the stylized facts. In the words of Cont (2001), “Most measures of volatility of an asset are negatively correlated with the returns of that asset.” This effect is not sufficiently robust across asset data, as shown by Ruffini-Crouzet et al. (2019). Whether to take it into account or not is left to the reader, and on the specific application they are considering.
8.  John Cochrane has written extensively on the subject, e.g., Cochrane (2005) and the long story “Predictability and Covariation” (Cochrane, 2011).

---
(Notes continued from Page 103)

9.  The literature on GARCH models alone is immense. Zivot and Wang (2003); Ghalanos (2019); Tsay (2010); Clark et al. (2006); Ruppert and Matteson (2015); Bollerslev (2008) are good starting points. The original ARCH model is in Engle (1982). The GARCH model is in Bollerslev (1986). The book Andersen et al. (2009) has dedicated chapters covering univariate GARCH, EGARCH (Teräsvirta, 2009b), moments of GARCH models (Teräsvirta, 2009a), their statistical inference properties (Davis and Mikosch, 2009), and multivariate GARCH. For a review of the empirical performance of GARCH, TARCH, GJR-GARCH, and a few other models, see Hansen and Lunde (2005); Brownlees et al. (2011).
10. The convergence properties of Random Recursive Equations (RREs) were studied by Kesten (1973). Diaconis and Freedman (1999) further developed the theory. The general form of an RRE is $X_{n+1} = f(X_n, Y_{n+1})$, where $\{Y_n\}_{n \ge 1}$ is an iid random sequence, of which RREs are a special case. A monograph on RREs, covering both the univariate and multivariate case, is Buraczewski et al. (2016).
11. The kurtosis of log returns, which is to a first approximation close to the daily Sharpe Ratio computed on returns.
12. An early analysis of the “vanilla” realized variance estimator is Barndorff-Nielsen and Shephard (2002), and a survey is Andersen and Benzoni (2009). Also relevant are the surveys of Andersen et al. (2001b, 2003), which introduced realized volatility as a measure of risk management purposes. Essential readings on realized volatility estimators are Zhang et al. (2005), which presents several estimators and introduces the idea of sub-sampling for RV; the series of papers Barndorff-Nielsen et al. (2008, 2009, 2011), which introduced several estimators, the two-scales RV estimator (Zhang et al., 2005), the multi-scale RV estimator (Aït-Sahalia et al., 2011), and the kernel RV estimator. This list of estimators is not exhaustive. For example, Hansen and Lunde (2006a) analyze an autocorrelation-adjusted estimator introduced by French et al. (1987). Different estimators are studied by Patton (2011) and Liu et al. (2015), and the minimum bias estimator is by Bandi and Russell (2008). However, these estimators depend on several parameters, like sampling and subsampling intervals, or the choice of kernel.
13. There are a few cases where this is not true. When high-frequency measurements are available, the estimator is contaminated by a microstructure noise term $O_p(1/\sqrt{n})$ for fixed sampling intervals (Barndorff-Nielsen et al., 2008b). In addition, at lower frequencies, a systematic truncated RV (Mancini, 2001, 2009) also outperforms vanilla RV; see Liu et al. (2015).
14. In the notation of the book (e.g., Eq. (2.24)), we use the following properties for random vectors $\mathbf{z}, \xi$ and a commensurable matrix $\mathbf{B}$:
    $$ \text{cov}(B\xi, \mathbf{z}) = B \text{cov}(\xi, \mathbf{z}) $$
    and
    $$ \text{cov}(\xi, B\mathbf{z}) = \text{cov}(\xi, \mathbf{z}) B' $$

```

Okay, here is the Markdown compilation for Chapter 3.

```markdown
Everand

**Chapter 3**
**Interlude: What Is Performance?**

**The Questions**

1.  What are the key performance metrics for a portfolio manager?
2.  How are they related to each other?

A discretionary portfolio manager satisfies; a quantitative portfolio manager optimizes. While such a statement is overly flat, a discretionary portfolio manager, like Odysseus, may optimize too, like using shark repellent for food intake or migrating warblers minimize traveling distance to Cuba. On the other side, optimization is part of the job description of a quant. This chapter introduces and justifies the investment metrics that will appear in later chapters. In some cases, the metrics enter the objective function directly or indirectly, through constraints. The role played by objectives and constraints is, to some extent, interchangeable.

The performance metrics of a portfolio manager are, by and large, these:

*   The expected return of the strategy.
*   The volatility of the strategy.
*   The Sharpe ratio and the Information ratio.
*   Capacity.

---

**3.1 Expected Return**

The expected return of the strategy, $\mu$, defined as the rate of Profit and Loss (P&L) to Assets Under Management (AUM). With the possible exception of Mother Teresa, investors prefer more money to less, and returns are an adequate way to describe this. Returns are preferred to actual money because the normalization makes the measure stationary, i.e., having (approximately) the same distribution across different time periods. The interview (or vignette) for estimating $\mu$ is independent of the universe of assets. The same considerations apply to comparison across assets and across funds. Returns can be optimized either over the course of an investment period or over the lifetime of the strategy. In practice, the two problems are separable: we solve a sequence of single-period problems, which we embed in a larger multi-period problem.

---

**3.2 Volatility**

We introduced the volatility of returns in Section 2.1. The use of volatility is vexing. It is ubiquitous, which, however, does not make it justified. There are, however, several arguments in favor of volatility. The first one is empirical. Cont (2001) reports a tail index for stock returns that is greater than 2 but smaller than 5; only fourth moments of returns may be finite. Therefore volatilities are finite and can be estimated. But there is no assurance that skewness or kurtosis may be estimated. The second reason is related to specific assumptions, described below.

Say that the investor, whose single-period utility maximization problem of the form $\max_w E[u(w'R)]$, the utility function describes the preferences of the investor, and is increasing and concave. Then, one can justify the use of volatility using three different sets of assumptions (Huang and Litzenberger, 1988):

1.  The utility function is well approximated by a second-order Taylor expansion centered at the expected payoff, so that
    $$ u \approx a E(w'R) - b E[(w'R - E(w'R))^2] $$
    ...and the returns are arbitrarily distributed but with finite variance.
2.  The utility takes a specific form (aside from the above quadratic utility):
    $$ u(w'R) = \begin{cases} - \exp(-w'R) \\ (w'R)^{1-\gamma} & \gamma \in (0,1) \\ \log(w'R) \end{cases} $$
3.  Lastly, one can assume arbitrary utility and returns to be normally distributed.

As we discussed in Chapter 2, there is agreement that returns of many securities have finite variance. The assumption that we can approximate utility with a quadratic function is not unrealistic, since the optimization horizon or quantitative investing is short, and the payoffs are small. Quadratic utility is not quadratic, and this will be exploited by the active asset manager. The risk aversion parameter, often $b$. A higher value of the ratio $b/a$ can be interpreted as penalizing more the uncertainty of payoffs relative to their expected values, i.e., being more risk-averse.[1] I am not discussing this further, since the topic is covered extensively in textbooks, such as Huang and Litzenberger (1988), and is not essential to the remainder of this book.

---

**3.3 Sharpe Ratio**

The Sharpe Ratio (SR) is defined as the ratio of expected excess returns of a strategy to its volatility over the previous two quantities by measuring returns in units of volatility over a certain period of time. The Information Ratio (IR) is defined analogously to the Sharpe Ratio but employs a different type of returns: the idiosyncratic returns of a strategy. These returns will be introduced in Chapter 5; for now, it suffices to say that active asset management returns describe the “intrinsic” returns of the strategy, i.e., the component of returns that is not driven by common factors affecting all returns at once.

If we assume that the returns $\xi$ of a strategy are identically distributed and independent, the Sharpe Ratio is the same as the t-statistic of the mean of the return distribution. In finance, the Sharpe Ratio is named after William F. Sharpe, one of the authors of the Capital Asset Pricing Model (CAPM). The Sharpe Ratio has drawbacks. For example, it is not additive across assets, it is not well defined as a metric that ranks uncertain outcomes. Aside from decision-theoretic considerations,[2] the Sharpe Ratio of a portfolio with negative expected return of $-\sigma$ and volatility $2\sigma$ is lower than the Sharpe Ratio with the same negative return, and volatility $0.5\sigma$. This is counter-intuitive at best and wrong at worst. Second, it assumes that investors’ risk attitude is measured solely by volatility. This implicitly assumes that there is only one source of risk, of which there is a near-infinite supply.[3] There are advantages, however. First, the Sharpe Ratio is intuitive, return in units of “risk.” Second, it comes with a rich arsenal of theoretical results. We have confidence intervals and generalizations of the empirical properties of portfolio returns. The Sharpe Ratio is related to the probability of underperforming the risk-free rate. The Sharpe Ratio also implies a bound on the probability of incurring a certain loss. This follows from Cantelli’s inequality. For a random variable $\xi$ with mean $\bar{\mu}$ and standard deviation $\bar{\sigma}$, this inequality states that
$$ P(\xi < \bar{\mu} - \lambda) \le \frac{\bar{\sigma}^2}{\bar{\sigma}^2 + \lambda^2} $$
$$ \Rightarrow \quad P(\xi < -\lambda) \le \frac{\bar{\sigma}^2}{\bar{\sigma}^2 + (\lambda + \bar{\mu})^2} $$
If $\xi$ is the annual return of a strategy, and SR is the annualized Sharpe Ratio of the strategy, and the loss is expressed as a multiple of standard deviations $-L\sigma$, an practitioner often asks, then the inequality is
$$ P(\xi < -L\sigma) \le \frac{1}{1 + (L + \text{SR})^2} $$

(Right Sidebar Text from Page 110)

This holds for any distribution of returns with Sharpe Ratio SR. For example, consider an annualized Sharpe Ratio of 1 and an annualized volatility of $L=3\sigma$. The probability of a loss of more than three standard deviations is not greater than $1/(1+(3+1)^2) = 1/17 \approx 6\%$. This is a much looser bound than one would obtain under the assumption of normal returns. In that case, the probability of a loss would be a $P(Z < -3) \approx 0.1\%$.

**FAQ 3.1: What are the dimensions of the Sharpe Ratio?**
Return, volatility, and Sharpe Ratio depend on the time horizon over which they are measured. Daily return vs. daily PnL, etc. Annualized return, where we assume the mean daily PnL (return) is $\bar{\mu}$ and volatility is $\bar{\sigma}$.[4] We assume that returns have zero mean, so that $\bar{\mu} = 0$. An example: a strategy has a return of $x\% / \sqrt{N}$ days / $x\% / N$ days. Provided that returns are serially uncorrelated (see Section 2.1.5), the variance of the sum of $T$ identically distributed returns is equal to $T$ times the variance of the single-period returns. The square root of variance and has the dimension $[\text{time}]^{-1/2}$. The Sharpe Ratio has the dimension $[\text{time}]^{-1/2}$.
$$ [\text{time}]^{-1/2} / [\text{time}]^{-1/2} = [\text{time}]^{-1/2} $$
When converting the horizon of a Sharpe Ratio for an equity strategy from a daily horizon to a monthly one, we multiply the daily Sharpe Ratio by $\sqrt{T_M}$, where $T_M$ is the number of trading days in a month (typically 21). The most common annualized Sharpe Ratio in the United States is $\sqrt{252}$.
[4] The number of trading days depends on the country, the asset class, and the year. In the United States, as of 2014, the stock market is open 252 days a time.

**FAQ 3.2: What is the confidence interval for the Sharpe Ratio?**
Suppose you observe $T$ consecutive returns (or PnLs), and estimate the Sharpe Ratio from these data. What is the confidence interval of this estimator? First, the Sharpe Ratio estimator is
$$ \hat{\mu} = \frac{1}{T} \sum_{t=1}^T r_t, \quad \hat{\sigma}^2 = \frac{1}{T} \sum_{t=1}^T (r_t - \hat{\mu})^2 $$

---
(Continuation from Page 114)

For excess returns $r_t$ that are iid and with finite variance, the estimator is normally distributed in the limit $T \to \infty$, with standard error
$$ \text{SR} = \frac{\hat{\mu}}{\hat{\sigma}} $$
$$ \text{SE(SR)} = \sqrt{\frac{1 + \text{SR}^2/2}{T}} $$
Compare this to the case in which we knew in advance the standard deviation of the returns. The Sharpe Ratio is then $\text{SR} = \hat{\mu}_0 / \sigma$ and the SE is $\sigma/\sqrt{T}$.
In the case of autocorrelated returns with $\text{corr}(r_t, r_{t-1}) = \rho \ne 0$, the Sharpe Ratio estimator is the cross-sectional $\hat{\mu}'$:
$$ \text{SR}_{\text{adj}} = \frac{\hat{\mu}}{\hat{\sigma}} \sqrt{\frac{1-\rho}{1+\rho}} \approx \frac{\hat{\mu}}{\hat{\sigma}} (1-\rho) $$

---

**3.4 Capacity**

Whereas the returns and the Sharpe Ratio are well known and defined, the capacity of a strategy is not unequivocally defined. Its informal definition is “capacity is the highest expected P&L that a strategy is able to produce over a certain horizon”. You may ask, “but isn’t expected P&L just equal to Sharpe Ratio times dollar volatility?” Capacity is essentially the maximum volatility at which we can run a strategy.[5] This would be fine if the Sharpe Ratio were independent of volatility, but in that case, capacity would be infinite. Sharpe Ratio is, at best, flat for low values of volatility; however, it almost always a decreasing function of volatility. For a large enough volatility, the Sharpe Ratio becomes zero, and beyond this threshold the strategy is unprofitable. The capacity of a strategy can be defined as the maximum P&L that can be achieved, subject to a constraint that the Sharpe Ratio exceeds a certain acceptable level. Alternatively, we could require a minimum bound on the expected return in capital. Defined this way, the capacity is an important parameter for hedge fund managers and portfolio managers alike. A strategy may have attractive return and Sharpe Ratio when run at low volatility. If it can yield only a modest P&L, it will be economically unattractive.

**The Takeaways**

1.  Expected Return: Represents profit relative to assets under management. It's stationary and intensive, allowing for comparisons across funds and periods.
2.  Volatility: A standard measure in portfolio optimization, particularly useful for assets with finite variance, used under assumptions about investor utility functions.
3.  Sharpe Ratio: Represents returns per unit of "risk" (volatility), widely adopted but has limitations such as dependence on risk aversion choice and unsuitability for outcomes with negative returns.
4.  Capacity: Refers to the maximum Profit and Loss (P&L) achievable within a strategy's acceptable risk (Sharpe Ratio) limits, crucial for assessing the economic viability of a strategy.

**Notes**

1.  [1] A sufficient condition for the asymptotic consistency of the variance estimator is that the fourth moment be finite.
2.  [2] Or, more commonly, the excess returns, i.e., the returns of a strategy in excess of the risk-free rate. We assume, for simplicity only, that the cost of holding a self-financing security: we borrow one dollar in the first period at the risk-free rate, and buy one dollar of the security. In the second period, we receive the security return, and pay off the loan.
3.  [3] See Huang and Litzenberger (1988).
4.  [4] For these, see [Skipping text] for a list of risk metrics, both theoretically justified and heuristic.

```

Okay, I will extract the text from the screenshots that belong to Chapter 4 and compile it into a single Markdown file.

```markdown
Everand

**Chapter 4**
**Linear Models of Returns**

**The Questions**

1.  What is a factor model for asset returns, and how is it formulated?
2.  What are the different interpretations of factor models (graphical model, superposition of effects, single-asset product)?
3.  How do alpha spanned and alpha orthogonal components contribute to asset returns?
4.  What are the different transformations applied to factor models (rotations, projections, push-outs), and how do they affect the models?
5.  What are the practical applications of factor models in finance, such as performance attribution, risk management, portfolio construction, and alpha research?
6.  What are the different types of factor models (characteristic, statistical, macroeconomic), and how are they used in practice?

Linear models of asset returns are a cornerstone of this book. They are flexible, interpretable, perform well in applications, and have supporting theory. For this reason, they fit like a glove with mean-variance optimization and can be used as a basis for a number of important tasks, like risk management and performance analysis. It is possible that you, the reader, will find this class of models inadequate in some way, at some point. But just because you have outgrown them does not mean that you will find them useless. This chapter enables later chapters about the entire investment process, and some of the theory we use in later.

---

**4.1 Factor Models**

We saw in Chapter 2 how to model single-asset returns. It is more convenient to model returns as an independent process. This would not be adequate, however, because the returns are dependent. It is a natural step to model the common dependency among stocks as being generated by a few common sources of randomness, called factors, and then to keep a random shock per security that is independent of the factors. The model that describes returns in terms of common factors is called a factor model, and takes the form:
$$ r_{it} = \alpha_i + \mathbf{B}_i' \mathbf{f}_t + \epsilon_{it} $$
where
$i \in \{1, \dots, N\}$ denotes the discrete time period.
The random vector $\mathbf{f}_t$ denotes $K$ asset returns minus the risk-free rate (see Section 2.1.2).
The term $\alpha_i$ is a scalar, the idiosyncratic alpha vector.
The random vector $\mathbf{\epsilon}_t$ denotes $N$ factor returns. $N$ is much smaller than $K$ in most models. Interpret factor returns as pervasive sources of uncertainty in the market, affecting in some ways all asset returns.
$\mathbf{B}_i$ is an $N \times K$ loading matrix. The row-vector $\mathbf{B}_{i \cdot}$ is the loading of asset $i$ on the factors. The element $B_{ik}$ is the loading of asset $i$ on factor $k$. Interpret $\mathbf{B}_i$ as a matrix specifying how factor returns map to asset returns.
$\epsilon_{it}$ is the random vector of idiosyncratic returns.[1] You can interpret these returns in two ways. The positive interpretation is “returns that are specific to the asset and are uncorrelated with all other returns in the universe.” The negative interpretation is “component of returns that are left over after removing the pervasive sources of risk”.

If the random vector $\mathbf{f}_t$ had a generic distribution, we would gain nothing in tractability. Instead, we assume that (i) the vector $\mathbf{f}_t$ is independent of the factor returns $\epsilon_{it}$ at time $t$, (ii) $E[\mathbf{f}_t] = \mathbf{0}$, (iii) $E[\epsilon_{it}] = 0$, (iv) the $N \times N$ covariance matrix $\Omega_{ff} = E[\mathbf{f}_t \mathbf{f}_t']$ is diagonal, (v) the $N \times N$ covariance matrix $\Omega_{\epsilon\epsilon} = E[\mathbf{\epsilon}_t \mathbf{\epsilon}_t']$ is diagonal. Often, we assume that the idiosyncratic returns $\epsilon_{it}$ are uncorrelated across assets and serially uncorrelated. The idiosyncratic component of asset returns.

We usually refer to the term $\mathbf{B}_i' \mathbf{f}_t$ as the systematic component of asset returns. We assume that the pair $(\mathbf{f}_t, \mathbf{\epsilon}_t)$ is either identically distributed across periods or has a slowly varying distribution, and that $\mathbf{f}_t$ and $\mathbf{\epsilon}_t$ are independent for each $t$. We denote $E[\mathbf{f}_t \mathbf{f}_t'] = \Omega_f$ and $E[\mathbf{\epsilon}_t \mathbf{\epsilon}_t'] = \Omega_\epsilon$. Then, the $N \times N$ covariance matrix of assets is
(4.1)
$$ \Omega_r = \mathbf{B} \Omega_f \mathbf{B}' + \Omega_\epsilon $$
This decomposition is at the core of volatility modeling with linear returns and the

(Right Sidebar from Page 120)
subject of Chapters 5 and 7.

**FAQ 4.1: Why is the covariance matrix**
$$ \Omega_r = \mathbf{B} \Omega_f \mathbf{B}' + \Omega_\epsilon $$
?
The covariance matrix $\Omega_r$ does not depend on the intercept $\alpha_i$ and the terms $E[\mathbf{f}_t]$ and $E[\mathbf{\epsilon}_t]$ are independent, so that
$$ \text{cov}(\mathbf{Bf}_t, \mathbf{\epsilon}_t) = \text{cov}(\mathbf{Bf}_t) + \text{cov}(\mathbf{\epsilon}_t) = \mathbf{0} $$
The term $\mathbf{Bf}_t$ is a linear transformation of $\mathbf{f}_t$. For any random vector $\mathbf{z}$ with covariance $\Omega_z$. For any
$$ \text{cov}(\mathbf{Bz}) = \mathbf{B} \Omega_z \mathbf{B}' $$
, because
$$ \text{cov}(\mathbf{B}_{i \cdot} \mathbf{z}, \mathbf{B}_{j \cdot} \mathbf{z}) = E[(\mathbf{B}_{i \cdot} \mathbf{z} - E[\mathbf{B}_{i \cdot} \mathbf{z}]) (\mathbf{B}_{j \cdot} \mathbf{z} - E[\mathbf{B}_{j \cdot} \mathbf{z}])'] = \mathbf{B}_{i \cdot} \Omega_z \mathbf{B}_{j \cdot}' $$

In this chapter we set aside the very important issue of estimating the parameters of Equation (4.1). We take data, and focus instead on the usage and interpretation. There is a plan for the rest of the chapter. First, we review the interpretations of factor models, of which there are three:
1.  As a graphical model.
2.  As the superposition of low-dimensional cross-sectional returns vectors.
3.  As the overlap of the factor return vector with the asset loadings vector.

We then review the concepts of alpha, namely alpha spanned and alpha orthogonal. These are fundamental sources at the core of the research process. Third, we review the transformations that can be operated on factor models. There are three of those too:
1.  Rotations keep the dimension of the model unchanged and its predictions “invariant”.
2.  Projections reduce the dimension of the model.
3.  Push-outs increase the dimension of the model by adding factors.
These mathematical operations are versatile tools in the hands of the quantitative manager, to reformulate, simplify, or extend a model.

Fourth, we describe the uses of factor models. There are quite a few:
1.  Forecast and decompose volatility, so that we can separate wanted versus unwanted risk.
2.  Be a fundamental input to portfolio construction.
3.  Understand performance and separate skill from luck.
4.  Serve as a foundation for alpha research.

---

**4.2 Interpretations of Factor Models**

Before attempting to interpret factor models, let us make the factor model more concrete with an example. In Figure 4.1 we list a “typical” loading matrix used in a risk model. K, the number of columns contain style loadings. Other columns consist of dummy variables, indicating whether the stock belongs to a particular industry. There may be a column for “energy explorers and producers,” a column for “biotechnology companies,” and so on. A stock will have a “1” loading if it belongs to the industry, “0” otherwise. Finally, there are columns that consist of dummy variables indicating country classification, similarly to industry. When the factor return for a country or an industry is high, it will move all the stocks in the industry. The factor structure captures comovement among stocks with certain obvious commonalities, as well as less obvious ones.

[Image: Figure 4.1: A typical loadings matrix, partitioned into different blocks. The style loadings comprise an “intrinsic factor” (sometimes termed “fundamental factor”). The loadings of style and the industry and country classifications are the same for all stocks. The other style loadings are often standardized. The country and industry loadings take values equal to 1 if the asset belongs to the country or industry.]
(Table shows example factor loadings for assets: style (e.g., size, value, momentum), country (e.g., US, EU, JP), industry (e.g., tech, fin, healthcare))

Even though Equation (4.1) is older than modern statistics (having really originated in the unpublished work of Gauss), it is surprisingly rich in meaning, and becomes even richer when used in financial applications. First, let’s review some interpretations of the equation.

**4.2.1 Graphical Model**

The first one is as a graphical model.[2] Since $r_i - \alpha_i = \mathbf{B}_{i \cdot} \mathbf{f}$ for each asset $j$, this equation holds:
Each of the many asset returns is dependent on all, or some of, the few factor returns. In a typical regional risk model (say, America, Asia, or Europe) we have up to 10,000 assets and up to 100 factors. Figure 4.2 shows the relationship. The dependency of asset returns on factor returns is through the links provided by loadings $\mathbf{B}$ (arrows). When the matrix $\mathbf{B}$ is sparse, the corresponding graph is sparse.

[Image: Figure 4.2: Factor models as graphical models. Diagram shows Factor Returns at the top, connected by Loadings (arrows) to Asset Returns at the bottom.]

**4.2.2 Superposition of Effects**

The second interpretation is as an overlap of influences on asset returns. A model for the co-direction of returns, i.e., the vector of returns at a given point in time. Let $\mathbf{B}_{\cdot j}$ be the $j$-th column of the matrix $\mathbf{B}$. We rewrite $E(r - \alpha) = \mathbf{Bf}$ as
$$ E(r_i - \alpha_i | \mathbf{f}) = \sum_j B_{ij} f_j $$
The vector of expected excess returns is the superposition of a small number of vectors (the loadings $\mathbf{B}_{\cdot j}$ for a specific factor), weighted by the factor return. This makes it clear that the factor component of the cross-section lies in a low-dimensional space (the column subspace of $\mathbf{B}$). This is shown in Figure 4.3.

[Image: Figure 4.3: A factor model as the superposition of weighted factor loadings. Diagram shows Asset Returns (R_i,1, R_i,2) as a vector sum of f1 and f2, where f1 and f2 are scaled factor loadings.]

[Image: Figure 4.4: Factor models as scalar products of per-stock loadings and factor returns. Diagram shows a vector R_i,1 with projections onto factor vectors (f_1, B_i,1), (f_2, B_i,2), (f_3, B_i,3).]

**4.2.3 Single-Asset Product**

The last interpretation applies to single assets. The expected return of an asset given the factor returns is equal to the scalar product of the asset loadings and the vector of factor returns:
$$ E(r_i - \alpha_i | \mathbf{f}) = \langle \mathbf{B}_{i \cdot}, \mathbf{f} \rangle $$
While this formula is rarely used at the asset level, it does show up all the time when we apply it to portfolios. Let $w_i$ be the weight of asset $i$, where $w_i$ is the Asset Market Value invested in asset $i$; for instance, $w_i$ is the stock price times the number of shares held long or short. The expected PnL of the portfolio is
$$ E(\mathbf{w}' \mathbf{r} | \mathbf{f}) = E \left( \sum_i w_i (\alpha_i + \mathbf{B}_{i \cdot} \mathbf{f}) \right) $$
$$ = \sum_i w_i \alpha_i + \left( \sum_i w_i \mathbf{B}_{i \cdot} \right) \mathbf{f} $$
The relationship is illustrated in Figure 4.4.[3] In the special case of $K=1$, we still have an interpretation of the term $\langle \mathbf{B}_{i \cdot}, \mathbf{f} \rangle$. This is the PnL attributable to factor returns. We explain this PnL factor of a portfolio in terms of a scalar product, and within the scalar product identify the largest contributor, the degree of dispersion of PnL among the factors, and so on. This is the jumping-off point for performance attribution, which we will cover extensively later in the book.

---

**4.3 Alpha Spanned and Alpha Orthogonal**

Consider the factor equation
$$ \mathbf{r}_t = \alpha + \mathbf{B} \mathbf{f}_t + \mathbf{\epsilon}_t $$
where $\mathbf{f}_t$ and $\mathbf{\epsilon}_t$ are iid mean zero, and $\mathbf{f}_t$ and $\mathbf{\epsilon}_t$ are independent on $t=s$, with zero unconditional mean and finite variance. Decompose $\alpha$ as the sum of its projection on the column subspace of $\mathbf{B}$ (i.e., the image of the operator $\mathbf{B}$) and the orthogonal complement: $\alpha = \mathbf{B} \lambda + \alpha_\perp$. By construction, the equality $\mathbf{B}' \alpha_\perp = \mathbf{0}$ holds. So we have
$$ \mathbf{r}_t = \mathbf{B} \lambda + \alpha_\perp + \mathbf{B} \mathbf{f}_t + \mathbf{\epsilon}_t = \mathbf{B}(\lambda + \mathbf{f}_t) + \alpha_\perp + \mathbf{\epsilon}_t $$
In this relationship, you can see that there is an indeterminacy in the factor model. It is useful to rewrite the model as
$$ \alpha_\perp := \mathbf{B} \lambda + E[\mathbf{r}_t] - \mathbf{B} E[\mathbf{f}_t] - E[\mathbf{\epsilon}_t] + E[\mathbf{\epsilon}_t] $$
where
$$ \alpha_s := \mathbf{B} \lambda + E[\mathbf{r}_t] - E[\mathbf{\epsilon}_t] $$
The “alpha” spanned by the column subspace of $\mathbf{B}$ is indistinguishable from the expected returns of the factors. However, it shows that $\alpha$ can be split into the sum of two orthogonal (by construction) terms. In the remainder of the book, we will use $\alpha$ and $\mu_f = E[\mathbf{f}_t]$. Now, if you choose a portfolio proportional to the alpha vector
$$ \mathbf{w} = \frac{\alpha_\perp}{\|\alpha_\perp\|} $$
its payoff is
$$ \mathbf{w}' \mathbf{r}_t = \frac{1}{\|\alpha_\perp\|} \alpha_\perp' \mathbf{r}_t = \frac{1}{\|\alpha_\perp\|} \alpha_\perp' (\alpha_\perp + \mathbf{\epsilon}_t) = \|\alpha_\perp\| + \frac{\alpha_\perp' \mathbf{\epsilon}_t}{\|\alpha_\perp\|} $$
The expected return and variance of this portfolio are
$$ E(\mathbf{w}' \mathbf{r}_t) = \|\alpha_\perp\| $$
$$ \text{var}(\mathbf{w}' \mathbf{r}_t) = \frac{\alpha_\perp' \Omega_\epsilon \alpha_\perp}{\|\alpha_\perp\|^2} $$
There is an upper bound for the variance, given by the operator norm:
$$ \frac{\alpha_\perp' \Omega_\epsilon \alpha_\perp}{\|\alpha_\perp\|^2} \le \|\Omega_\epsilon\| $$
So that
$$ \text{SR} = \frac{E(\mathbf{w}' \mathbf{r}_t)}{\sqrt{\text{var}(\mathbf{w}' \mathbf{r}_t)}} \ge \frac{\|\alpha_\perp\|}{\sqrt{\|\Omega_\epsilon\|}} $$
In the case of a diagonal matrix, $\|\Omega_\epsilon\|$ is the largest element on the diagonal. Assume that it has an upper bound. This has interesting implications. Consider the case, for example, where the average absolute orthogonal return per asset is positive:
$$ \frac{1}{N} \sum_i |\alpha_{\perp i}| = \bar{\alpha}_\perp > 0, \text{ or, equivalently, } \|\alpha_\perp\|_1 = N \bar{\alpha}_\perp $$
Now, use the simple inequality between $L_1$ and Euclidean norm $\|\alpha_\perp\|_1 \le \sqrt{N} \|\alpha_\perp\|$. Hence $\|\alpha_\perp\| \ge \sqrt{N} \bar{\alpha}_\perp$. Apply this to the Sharpe Ratio of the alpha-orthogonal strategy, and we obtain a lower bound on the Sharpe Ratio:
(4.2)
$$ \text{SR} \ge \frac{\|\alpha_\perp\|}{\sqrt{\|\Omega_\epsilon\|}} \ge \sqrt{N} \frac{\bar{\alpha}_\perp}{\sqrt{\|\Omega_\epsilon\|}} $$
Let’s summarize the assumptions made so far, besides the fact that the factor model is correct. If we assume that:
1.  the largest idiosyncratic variance $\|\Omega_\epsilon\|$ is uniformly bounded in the number of assets, and
2.  the average absolute value of the coordinate of $\alpha_\perp$ is bounded below by $\bar{\alpha}_\perp$.

We have obtained a lower bound on the Sharpe strategy of a portfolio. And if these bounds are uniform for increasing values of $N$, then we have a sequence of Sharpe Ratios going to infinity! This is highly unlikely in real life, so that at least one of the assumptions we made—factor model, bound on idiosyncratic variances, bound on orthogonal expected returns—is likely incorrect. Under the assumption that the factor model is correct, and that the idiosyncratic variances are bounded, common fields in practice. This leaves us with the fact that the idiosyncratic orthogonal expected returns are vanishing as $N \to \infty$. Let us summarize this result in concrete terms:

*   If a linear model is a good approximation of returns, then alpha is either “spanned” or “orthogonal”.
*   Alpha spanned is extremely valuable. If you have positive alpha spanned, then your Sharpe Ratio increases at the rate $\sqrt{N}$, a typical rate that arises when you can diversify risk without giving up on returns.
*   There are excess returns, but they are more likely to come from “alpha spanned” than alpha, as we will see in the next chapter, sources with ties that does not diversify away with large number of assets.

---

**4.4 Transformations**

A factor model is not uniquely identified. Let $C$ be an $m \times m$ invertible matrix, and define
$$ \tilde{\mathbf{B}} = \mathbf{B} C^{-1} $$
$$ \tilde{\mathbf{f}} = C \mathbf{f} $$
The columns of $\tilde{\mathbf{B}}$ span the same subspace as the columns of $\mathbf{B}$. The model
$$ \mathbf{r} = \alpha + \tilde{\mathbf{B}} \tilde{\mathbf{f}} + \mathbf{\epsilon} $$
has the same returns as the original model. This is usually termed rotational indeterminacy of the factor model.
The covariance matrix of the transformed factors is $\tilde{\Omega}_f = C \Omega_f C'$. There will be several applications of rotational indeterminacy in the book. Rotations enable us to provide final users with different views of the same model. We explore the impact of factor covariance, orthonormal factors, and returns on three instructive examples: identity factor covariance, orthonormal loadings, and user’s needs.
Identity factor covariance matrices. Sometimes, users of a model would like to see uncorrelated factor returns with unit variance. Under this perspective, exposures to the portfolio can be interpreted directly as the squared volatilities, and the factor PnL of a portfolio is the sum of the squared exposures, without covariance terms.
This risk model perspective can be obtained by taking the Singular Value Decomposition (SVD) of $\Omega_f = U S U'$ and then setting $C = S^{-1/2} U'$. It follows that
$$ \tilde{\Omega}_f = C \Omega_f C' = S^{-1/2} U' U S U' U S^{-1/2} = I $$
Orthonormal loadings. We can also choose a representation so that the factor loadings are orthonormal $\tilde{\mathbf{B}}' \tilde{\mathbf{B}} = I_K$. This means that each column of $\tilde{\mathbf{B}}$ has unit norm (but not unit variance, since the columns may have non-zero means), and is orthogonal to the other. In this case the transformation is $C = V S^{1/2}$, where $V$ comes from the SVD $\mathbf{B}' \mathbf{B} = U S V'$. Then $\tilde{\mathbf{B}} = \mathbf{B} V S^{-1/2} U'$.
User’s needs. The choice of factor loadings is a common procedure. It consists of a linear rescaling of the loadings of one or more factors, so that the new loadings have zero mean and unit variance (once they are zero-mean, they also have unit squared norm). The benefit of this transformation is that it makes it easier to relate to the stock characteristics. What is the average exposure to the factor? How much? What is the average portfolio exposure to the factor on a standardized basis? Such a linear transformation resulting in an equivalent

(Right Sidebar from Page 135)
**FAQ 4.2: Is a scoring factor loadings changing a factor model?**
A scoring the loadings of a model will result in a model that makes the same predictions as the original one. The “new loadings” are a linear combination of the original factor loadings. For example, if the first factor is $f_1$, the second factor is $f_2$, ..., the $K$-th factor is $f_K$, a linear combination of the loadings vectors of the original model. A special case is the one where the “scoring factor” (or “derived factor”) is a scoring of the original factors. Even if the scoring factor results in a model that produces different risk forecasts and performance attributions.

factor model is possible by multiple the loadings of factor $j$ by constant $c_j$, and just consider
$$ C := \text{diag}(c_1, \dots, c_m, \dots, c_K) $$
which is always invertible. However, in general it is not possible to center the loadings (you can try to find a counterexample in Exercise 4.2). However, assume that the unit vector is in the subspace spanned by the loadings (i.e., there is a vector $\mathbf{v}$ such that $\mathbf{1}_N = \mathbf{Bv}$). In this case, the centering is possible, if we want to add constants $b_k$ to the loadings, then
$$ \tilde{\mathbf{B}} = \mathbf{B} E' E + (\mathbf{1}_N \mathbf{a}' - \mathbf{B} \mathbf{A}') \mathbf{B}' \mathbf{B} (\mathbf{v}) $$
, hence our transformation is
$$ C^{-1} = I_{m \times m} + \mathbf{A} \mathbf{a}' \mathbf{B} \text{ diag}(\mathbf{v}) $$
This assumption is verified in two common cases. The first one is the use of a “market” factor, defined as a linear combination of all asset returns. The second case is when there are country or industry factors, such that for each asset the sum of the loadings across industries is exactly one. In this case $a_k = B_{ik}$ for a vector that has ones in positions corresponding to the industry factors, and zero otherwise.

---

**4.4.2 Projections**

Occasionally, we want to use a risk model with fewer factors compared to the original one. At first glance, this operation may seem unjustified. If we have a better risk model in the model, why would we want to replace it with a different one? The reasons are many. For example, it may be the case that in practice the loadings of one or more factors are changing so fast as to make portfolio management from the hedge fund difficult. Another reason is that we are using a limited set of factors, perhaps because of limitations in the data available, or because we want to provide the end user with a “simplified” risk model that is as accurate as possible, while retaining the full model for other uses. For these reasons and more, we need to find a different risk model that is close, in some sense, to the original one.
We have a model $r = \alpha + Bf + \epsilon$ and associated covariance matrix
$$ \Omega_r = B \Omega_f B' + \Omega_\epsilon $$
...but we want to employ a different loadings matrix $\tilde{A}$, which the range of $\tilde{A}$ is contained in the range of $B$. If we model returns as $r = \alpha + \tilde{A}g + \eta$, the covariance model would be
$$ \Omega_r = \tilde{A} \Omega_g \tilde{A}' + \Omega_\eta $$
What is the model resulting in the best approximation to our original model? Let the range of $\tilde{A}$ be the subspace spanned by the first $k$ columns of $B$. Let $\tilde{B}$ denote the first $k$ columns of $B$. The optimal approximating factor returns are $g = B_k' f$, where
$$ \tilde{A} = (B_k' B_k)^{-1} B_k' B $$
The corresponding value is $\Omega_g = B_k' \Omega_f B_k$.

(Right Sidebar from Page 139)
**FAQ 4.3: Which projections?**
What types of projections are useful in practice?
1.  The columns of the matrix $\tilde{A}$ are a subset of the columns of the matrix $B$. In this case, we are attributing all the common risk and return to a restricted factor model derived from the original one. This is by far the main application of projections.
2.  The subspace spanned by the columns of $\tilde{A}$ is not contained in that spanned by the columns of $B$. In this case, the application is the qualitative ability of the second model to describe the factor risk predictions of the first model.

We call the operator $\Pi$ a projection because, like geometric projections, they are idempotent. An idempotent linear operator $\Pi$ is such that $\Pi^2 = \Pi$. The geometric meaning is that, if we project a vector onto a plane, projecting the result of the projection onto the same plane does not result in another vector, since the input vector is already on the plane.

**4.4.3 Push-Outs**

In the previous two sections we introduced a transformation that preserves the number of factors and a transformation that reduces it. This last section focuses on a transformation that increases the number of factors. We identify the $k$ columns of $B$ that are of interest, and we want to retain them as they are in the original one. Why could this be of interest? A possible scenario that occurs in practice is that our factor model may have been developed on historical data that are not representative of the current regime. As a result, the idiosyncratic returns show some systematicity that we believe they are amenable to be formulated as a different factor model.
$$ \epsilon = Ag + \eta $$
with $A \in \mathbb{R}^{N \times m}$, $g \in \mathbb{R}^m$ random variable (e.g. taking values in $\mathbb{R}^m$) and $\eta \in \mathbb{R}^N$ taking values in $\mathbb{R}^N$. The new model becomes
$$ r = \alpha + Bf + Ag + \eta $$
with $\eta$ uncorrelated from $f, g$. In the specification of the new model (4.3), we require that $A'B = 0$. If not, then some of the original factors would have to be re-defined. Assume that $B = [B_1, B_2]$, where we can write the original model as $r = \alpha + B_1 f_1 + B_2 f_2 + \epsilon$. We can then choose $A$ as the sum of parallel and orthogonal components. In matrix terms, $A = BC - B_1$. For some $C \in \mathbb{R}^{K \times m}$, it follows that the model $r = \alpha + B_1(f_1 - Cg) + B_2 f_2 + Ag + \eta$ is
$$ r = \alpha + B_1(f_1 + Cg) + B_2 f_2 + \eta $$
1.  $y_1' B_1 = 0$ (original model orthogonality condition)
2.  $y_2' B_2 = 0$ (residual model orthogonality condition)
3.  $(y_1' B_1 + Ag)' = 0$ (final model orthogonality condition)
from the second and third equalities it follows that $g'A'B_1 = 0$; the first equality can be rewritten as
$$ 0 = (g'A' + \eta') B_1 = g'A'B_1 $$
for all realizations of $f, g$, hence $A'B_1 = 0$. The example above assumed that the idiosyncratic returns of each asset have the same volatility (homoskedastic volatility). In Exercise 4.3 we will see how to augment a risk model in a characteristic model framework where idiosyncratic returns are heteroskedastic.

**Exercise 4.1 (Excess Returns and Factor Models):**
In the academic literature the standard factor model (4.1) models the excess returns, defined as $r_{it} - r_{ft} = \dots$ as per Section 2.1.2. On the other side, practitioners think in terms of returns, not excess returns.
*   When in portfolio management is it incorrect to reason in terms of excess returns? When is it not?
*   Show that a model of excess returns could be recast as a model of returns using factors.
*   Can you extend the modeling to incorporate sensitivities to interest rates?

---

**4.5 Applications**

**4.5.1 Performance Attribution**

What is the PnL of a portfolio in interval $[t-1, t]$?
(portfolio PnL)$_t = \mathbf{w}_t' \mathbf{r}_t$
$$ = \mathbf{w}_t' (\alpha + \mathbf{Bf}_t + \mathbf{\epsilon}_t) = \mathbf{w}_t' \alpha + \mathbf{w}_t' \mathbf{Bf}_t + \mathbf{w}_t' \mathbf{\epsilon}_t $$
The vector $\mathbf{w}_t \in \mathbb{R}^N$ represents the portfolio holdings at time $t-1$. The term $\mathbf{w}_t' \alpha$ is the characteristics of factor $j$ of each stock, weighted by the portfolio holdings. Keep in mind that the characteristics and the weights can both be negative. The term $\mathbf{w}_t' \mathbf{Bf}_t$ is the factor PnL in time interval $t$, while the term $\mathbf{w}_t' \mathbf{\epsilon}_t$ is the idiosyncratic PnL. Summing up over a time interval $[0, \dots, T]$, the PnL of a strategy is
$$ \text{PnL} = (\text{Factor PnL}) + (\text{Idiosyncratic PnL}) $$
We can also distribute the sum differently:
$$ \text{PnL} = \sum_t (\text{Factor PnL})_t + \sum_t (\text{Idiosyncratic PnL})_t $$
$$ = \sum_t \mathbf{w}_t' \mathbf{Bf}_t + \sum_t \mathbf{w}_t' (\alpha_t + \mathbf{\epsilon}_t) $$
$$ = \sum_t (\text{Factor } j \text{ PnL})_t + \sum_t (\text{Stock } i \text{ Idiosyncratic PnL})_t $$
And then, of course, one can partition factors and stocks in groups, to highlight, for example, the performance arising from style factors, from industry factors, or from a specific group of stocks.

**4.5.2 Risk Management: Forecast and Decomposition**

If we have a covariance matrix (not specifically from a factor model), the variance of a portfolio $\mathbf{w}$ is easy to compute:
$\text{var}(\mathbf{w}'\mathbf{r}) = \text{cov}(\mathbf{w}'\mathbf{r}, \mathbf{w}'\mathbf{r}) = \mathbf{w}' \Omega_r \mathbf{w}$.
We can apply the formula to a covariance matrix associated with a factor model
$$ \text{var}(\mathbf{w}'\mathbf{r}) = \mathbf{w}' (\mathbf{B} \Omega_f \mathbf{B}' + \Omega_\epsilon) \mathbf{w} $$
$$ = \mathbf{w}' \mathbf{B} \Omega_f \mathbf{B}' \mathbf{w} + \mathbf{w}' \Omega_\epsilon \mathbf{w} $$
The formula has two applications. The first one is an estimate of a portfolio’s ex-ante volatility at any point in time. This is an important piece of information for risk management, portfolio construction, and alpha research. Risk based on factor models is a common application in the decomposition of variance in factor and idiosyncratic components. Like in the attribution case, the formula is a jumping-off point. For example, a commonly quoted statistic for, a strategy is the percentage of idiosyncratic variance to total variance (also called variance ratio). The percentage of idiosyncratic variance and factor variance is the sum of two. The factor variance can be decomposed further by making factor partitions. The most detailed one has each factor being a singleton, but very common choices are [style group]/[industry group]/[country group]/[idiosyncratic group]. This information is used to manage strategies. Every partition, either of factors or of assets, induces a covariance matrix $\Omega_p = B_p \Omega_{fp} B_p'$ where $\Omega_{fp}$ is the covariance between partition group $p$ and $f$. For example, say that a portfolio has factor exposure $\mathbf{b}_p$, and we partition factors in groups $g_1, \dots, g_P$, with group $g_i$ containing a subset of factors $S_i$. Define $B_{g_i}$ as a selector matrix that selects the rows of $B$ that are in set $S_i$. Define $\Omega_{g_i}$ as the covariance matrix of the rows of PnL:
$$ \Omega = \begin{pmatrix} B_{g_1}' \Omega_f B_{g_1} & \dots & B_{g_1}' \Omega_f B_{g_P} \\ \vdots & \ddots & \vdots \\ B_{g_P}' \Omega_f B_{g_1} & \dots & B_{g_P}' \Omega_f B_{g_P} \end{pmatrix} $$
Then the total factor variance is $\mathbf{w}' \mathbf{B} \Omega_f \mathbf{B}' \mathbf{w} = \sum_{i,j=1}^P \mathbf{w}' B_{g_i}' \Omega_f B_{g_j} \mathbf{w}$.
The $g$-th group variance is $\mathbf{w}' B_{g_i}' \Omega_f B_{g_i} \mathbf{w}$.
Fraction of total variance for group $g$ is
$$ \pi_g = \frac{(\text{variance of group } i \text{ PnL}) + (\text{sum of } i \ne j \text{ covariance contributions})}{(\text{portfolio variance})} $$
$$ = \frac{\text{cov}(\mathbf{w}' B_{g_i} \mathbf{f}_{g_i}, \mathbf{w}'\mathbf{r})}{\text{var}(\mathbf{w}'\mathbf{r})} $$
$$ = \frac{(\text{beta of } i\text{-th factor group's PnL to total PnL})}{\text{var}(\mathbf{w}'\mathbf{r})} $$
So that $\sum_g \pi_g = 1$. The percentage of variance of a group $g_i$ (again, this includes single factors and single assets—perhaps the most commonly used partition) is simple the beta of returns of the group to the overall portfolio.
Marginal contribution to risk (MCR) of a group $S(i)$ is defined as
$$ m_i = \frac{\partial \text{portfolio } \sigma \text{ risk when we buy } \$1M \text{ of set } S(i)}{\partial \$1M} $$
$$ = \frac{\beta_{S(i), \text{port}} \times \sqrt{\text{var}(S(i))}}{1} = \frac{1}{\sigma_{\text{port}}} \sum_{j \in S(i)} \Omega_{ij} $$
$$ = \frac{\sigma_{S(i)}}{\sigma_{\text{port}}} (\text{correlation of } S(i) \text{ factor group PnL to total PnL}) $$
$$ = \frac{\text{vol}(S(i) \text{ PnL})}{\text{vol}(\text{PnL})} $$
Sharpe Ratio sensitivity. It is also useful to compute the sensitivity of the Sharpe Ratio to changes in volatility of a group. The total portfolio Sharpe Ratio sensitivity with respect to volatility increase of group $g$ is given by
$$ \frac{\partial E_t[\text{vol}(\text{PnL})]}{\partial \text{vol}(g \text{ PnL})} = \frac{E_t[\text{vol}(\text{PnL})]}{\text{vol}(\text{PnL})} \frac{\partial \text{vol}(\text{PnL})}{\partial \text{vol}(g \text{ PnL})} $$
$$ \text{vol}(\text{PnL}) \frac{\partial E_t[\text{PnL}]}{\partial \text{vol}(g \text{ PnL})} - E_t[\text{PnL}] \frac{\partial \text{vol}(\text{PnL})}{\partial \text{vol}(g \text{ PnL})} = \frac{m_g \text{SR}_{\text{port}} \times \text{vol}(g \text{ PnL})}{\text{vol}(\text{PnL})} $$
$$ = \frac{\text{SR}_{\text{port}} - \text{SR}_{g}}{\text{SR}_{\text{port}}} \frac{m_g}{\text{vol}(\text{PnL})} $$
The contribution to total Sharpe Ratio is positive if the Sharpe Ratio of a group exceeds the portfolio Sharpe Ratio, which is the marginal contribution to risk times the total Sharpe Ratio.

(Right Sidebar from Page 148)
does not depend on rotations. However, the single-factor risk variance is affected by rotations. Rather than being a drawback, this is a feature. We can use this flexibility to attribute risk to factors that are more meaningful (e.g., more intuitive) than others.

**FAQ 4.5: Why not use the empirical covariance matrix?**
Before treating factor model estimation, we address a preliminary question. Given a time series of returns $\mathbf{r}_t$ with population covariance matrix $\Omega_r$, its simplest estimator is the empirical covariance:
$$ \hat{\Omega}_r = \frac{1}{T} \sum_{t=1}^T \mathbf{r}_t \mathbf{r}_t' $$
or, if we denote $\tilde{\mathbf{R}} \in \mathbb{R}^{N \times T}$ the matrix of returns where $\tilde{\mathbf{R}}_{it} = r_{it}$, we can write $\hat{\Omega}_r = \frac{1}{T} \tilde{\mathbf{R}} \tilde{\mathbf{R}}'$. It is well known that if the returns are drawn from a normal multivariate distribution, $\hat{\Omega}_r$ is asymptotically consistent, and a Central Limit Theorem is available (Anderson, 1963). Why not use this as our estimate for the covariance matrix? The reason is that, even for $T \gg N$, the estimation error for volatility can be large, and portfolio optimization purposes, the covariance matrix has to be positive definite.
$$ \mathbf{w}_{LS}' \mathbf{1}_N = 0, \quad \mathbf{w}_{LS}' \tilde{\mathbf{R}} = \mathbf{0}, \quad \mathbf{w}_{LS} \ne \mathbf{0} $$
be a basis for the null space of $\tilde{\mathbf{R}}'$ (i.e., $\mathbf{w} \in \mathbb{R}^N$ s.t. $\mathbf{w}' \tilde{\mathbf{R}} = \mathbf{0}$). We can interpret these vectors as portfolios. The volatility of portfolio $\mathbf{w}_{LS}$ is
$$ \mathbf{w}_{LS}' \hat{\Omega}_r \mathbf{w}_{LS} = \frac{1}{T} \mathbf{w}_{LS}' \tilde{\mathbf{R}} \tilde{\mathbf{R}}' \mathbf{w}_{LS} = 0 $$
Six, a majority of independent portfolios has zero volatility. The situation is even worse in portfolio optimization. The solution of the mean-variance portfolio
$$ \max_{\mathbf{w}} \mathbf{w}' \alpha - \frac{1}{2\lambda} \mathbf{w}' \hat{\Omega}_r \mathbf{w} $$
is $\mathbf{w} \sim \mathcal{N}(0, \lambda^{-1} \hat{\Omega}_r^{-1})$. In this case, $\hat{\Omega}_r$ is in the null space of $\Pi_r$. The portfolio is ill-defined. Choosing an alpha close to the null space yields an arbitrarily large portfolio, and an arbitrarily large Sharpe Ratio.

**FAQ 4.4: Do model rotations affect risk decomposition?**
When we rotate a factor model, we transform the factor loadings and factor covariance matrix as $\tilde{\mathbf{B}} = \mathbf{B}C^{-1}$ and $\tilde{\Omega}_f = C \Omega_f C'$. In the rotated model, the factor exposure of portfolio $\mathbf{w}$ are
$$ \tilde{\mathbf{b}} = \tilde{\mathbf{B}}' \mathbf{w} = (C^{-1})' \mathbf{B}' \mathbf{w} = (C^{-1})' \mathbf{b} $$
and the factor risk is
$$ \tilde{\mathbf{b}}' \tilde{\Omega}_f \tilde{\mathbf{b}} = \mathbf{b}' C^{-1} C \Omega_f C' (C^{-1})' \mathbf{b} = \mathbf{b}' \Omega_f \mathbf{b} $$
The total factor variance is unchanged. The total (and single-asset) idiosyncratic variance is unchanged too, as it

---

**4.5.3 Portfolio Management**

Factor models are used in portfolio management in several ways. The first one is efficient ex ante risk management: volatility is the common language spoken by risk managers and portfolio managers, and is oftentimes generated by a factor model. The second one is the inverse of the covariance matrix, also known as precision matrix. This matrix plays a central role in portfolio optimization. As discussed in Section 4.1, a positive definite covariance matrix is a must. Factor models make this possible. A portfolio’s expected asset returns are the sum of two terms: $\alpha_i + B_{i \cdot} E[\mathbf{f}_t]$. These two terms give rise to two qualitatively different classes of expected returns. This makes sense, intuitively, since the factor-based returns come with some variability and risk, while $\alpha$ itself is systematic and comes with no risk. How to manage these sources of returns is the concern of portfolio management. Lastly, a factor model is agile: when applied to a portfolio, it produces factor exposures, risk and performance decompositions, as discussed above, explicitly. This makes the job of the portfolio managers easier, since it enables them to define action plans to monitor the strategy (during the trade), and understand (after the trade) their strategies.

**4.5.4 Alpha Research**

As volatility is the lingua franca spoken by risk managers and portfolio managers, so alpha is what a signal researcher and a portfolio manager both understand. At the cost of extreme generalization, one could say that the signal researcher cares about the risk model because it helps them identify and portfolio construction methods, so costs and tries to combine all these concerns into a profitable strategy. In reality, there is no “alpha” worth trading contained in the term $Bf$. Use the language loosely for the time being, with the goal of tightening it in coming chapters. Furthermore, common factors are not the same, although their roles are similar. Alpha research is improved by factor models in two ways. First, $Bf$ is important, and for a certain class of investors it is the only thing that matters.[...] Second, for a factor-based approach. Help separate the two sources of expected returns for a portfolio. One source is associated with having factor exposures. These returns come with the associated risk of variable factor returns. The second source is the “true alpha” of an asset, i.e., having exposure to the alpha vector.

---

**4.6 Factor Models Types**

The model we use from here on is Equation (4.1). We have taken the model for granted. But where do the data and parameters of the model come from? In the case of factor models, the answer is especially important, because the meaning attached to the various symbols matters. Practitioners use three broad approaches to identify all the parameters in the equation:

1.  Characteristic model: This is the most common approach. The input data to the model are the time series $r_t$ and $B_t$. Factor and idiosyncratic returns are estimated from these data. We define $B_{it}$ as a matrix of asset characteristics at time $t$. For example, $B_{it}$ could be the market capitalization of stock $i$ at time $t-1$. The intuition is that these characteristics are partially responsible for the stock return. I cover this in Chapter 5.
2.  Statistical model: In this model, the only premise is $r_t$ and $B_t, f_t$ and $K$ are all unobserved. We estimate these quantities from $r_t$. I cover this in Chapter 8.
3.  Macroeconomic model: In this model, the inputs are $r_t$, and $f_t$. $B_t$ and $K$ are estimated. $f_t$ usually represents a vector of macroeconomic time series.

The relevant methodological issues the modeler must address are:
1.  What are the best loss functions to evaluate a model?
2.  Once we have estimates (or promise data) about factor and idiosyncratic returns, how do we estimate the covariance matrices from cross-sectional estimates?
3.  What is the best approach within each framework?

---

**4.7 Appendix**

**4.7.1 Linear Regression**

Linear models are by far the most widespread class of models in statistics. There are entire books that treat the subject from the usual angle of the linear model. Here, we could spend pages that are much more useful if spent on their own. We could have on planet Earth may have completely different interpretations of them. In order to have some common ground, we will describe some less well-known aspects which need to be stated explicitly. Our setting is as follows. We are given a pair $(X, Y)$, where $X \in \mathbb{R}^p$ is a random vector of predictors and $Y \in \mathbb{R}$ is a random variable. We assume a general dependency, knowing the value of a realization $x$ of $X$ tells us something about the values of $Y$ and this makes the problem inherently interesting. Say that we want to provide a forecast $g(x)$ which is close to $Y$. One way to such forecast is to try to minimize the mean squared error of the forecast. The mean squared error, or loss, of the choice of the loss is the quadratic loss. It is non-negative; it is symmetric; it is differentiable; and it penalizes more for large errors. The problem we face is
(4.8)
$$ \min_g E[(Y - g(X))^2] $$
One basic result in statistics[15] and in control theory is that, if $E[Y^2] < \infty$, the function that minimizes this expectation is the conditional expectation of $Y$ given $X$. We use the notation $E[Y|X]$.
It follows that
$$ E[Y|X] = E[Y - g(X) + g(X)|X] = E[Y-g(X)|X] + E[g(X)|X] = 0 $$
Then we use the following chain:
$$ E[(Y-g(X))^2] = E[E[(Y-g(X))^2|X]] $$
$$ = E[E[(Y-E[Y|X] + E[Y|X] - g(X))^2|X]] $$
$$ = E[E[(Y-E[Y|X])^2|X] + E[(E[Y|X]-g(X))^2|X] + 2E[(Y-E[Y|X])(E[Y|X]-g(X))|X]] $$
$$ = E[(Y-E[Y|X])^2] + E[(E[Y|X]-g(X))^2] $$
$$ \ge E[(Y-E[Y|X])^2] $$
The equality holds only if $g(X) = E[Y|X]$. The term $E[Y^2]$ is finite, because
$E[Y^2] < 2E[Y^2] + 2E[g(X)^2] < \infty$.
$E[Y^2] < 2E[Y^2] + 2E[E[Y|X]^2] < \infty$.
(Jensen)
In applications we work with samples $(x_i, y_i)$ and we choose a functional form for $g = g(X, \theta)$, where $\theta$ is a finite- or infinite-dimensional vector of parameters. We then minimize the empirical squared loss
$$ n^{-1} \sum_{i=1}^n (y_i - g(x_i, \theta))^2 $$
The simplest form of $g$ is linear: $g(X, \theta) = X'\beta$. In matrix form, Equation (4.8) becomes
$$ \min_\beta (Y - X\beta)'(Y - X\beta) $$
where $Y \in \mathbb{R}^n, X \in \mathbb{R}^{n \times p}$. The integers $n$ and $m$ denote the number of observations and the number of features, respectively. We want to estimate the parameters $\beta$, leading to estimates for $X\beta$. We then minimize the empirical loss
$$ (Y - X\beta)'(Y - X\beta) $$
which is equal to the unweighted sum of squared errors (Ordinary Least Squares, OLS).
$$ \sum_{i=1}^n (y_i - x_i'\beta)^2 $$
A different route arrives at the same problem. It is to posit that the true model is $Y = X\beta + \epsilon$, where $\epsilon \sim N(0, \sigma^2 I_n)$. If we set the loss to be $-\log P(Y|X, \beta)$ and since we know the distribution of $\epsilon$, we can associate to $Y$ a choice of $\beta$ a likelihood $P(Y|X, \beta)$. If we choose the parameters to maximize the likelihood, we end up solving the same problem as Equation (4.8). The choice of maximizing the likelihood is called the Maximum Likelihood Principle (MLE).
Finally, there is a geometrical interpretation for the regression problem. You can interpret the set
$$ S := \{X\beta, \beta \in \mathbb{R}^m\} $$
as a subspace of $\mathbb{R}^n$. The columns of $X$ are a (generally non-orthonormal) basis of the subspace. We are looking for the point $X\hat{\beta}$ in the subspace $S$ that is closest to $Y$. This is the definition of orthogonal projection of $Y$ on $S$. The problem is a linear operator. The minimum distance $Y - X\hat{\beta}$ is attained at
$$ \hat{\beta} = (X'X)^{-1}X'Y $$
and the estimates $Y$ are $E[Y|X]$:
(4.9)
$$ \hat{Y} = X\hat{\beta} $$
$$ = X(X'X)^{-1}X'Y $$
The matrix
$$ H = X(X'X)^{-1}X' $$
is called the hat matrix or projection matrix. The estimated residuals are
$$ \hat{\epsilon} = (I-H)Y $$
Intuitively, the optimal estimates should not change if we change the basis of the subspace. To see this, choose a new basis $XQ$, where $Q \in \mathbb{R}^{m \times m}$ is non-singular. The new transformed set of predictors spans the same subspace as $X$. Then
(4.10)
$$ \hat{Y} = XQ((XQ)'XQ)^{-1}(XQ)'Y $$
$$ = XQ(Q'X'XQ)^{-1}Q'X'Y $$
$$ = XQQ^{-1}(X'X)^{-1}(Q')^{-1}Q'X'Y $$
$$ = X(X'X)^{-1}X'Y $$
hence $\hat{Y}$ is independent of base representation.
Another property of the estimate $\hat{Y}$ is that, if we iterate the estimation process on the estimate $\hat{Y}$, we obtain again $\hat{Y}$. This also has a geometric interpretation. Once a point has been projected on a hyperplane, the projection of the projection is unchanged. In algebraic terms,
$$ H \hat{Y} = H^2 Y = HY $$
Here is another facet of linear regression tying geometric and algebraic interpretations of linear regression. Decompose $X$ using the SVD $X = U \Lambda V'$. $U$ is an orthonormal basis for the column subspace of $X$. Then
$$ \hat{Y} = U \Lambda V' (V \Lambda U' U \Lambda V')^{-1} V \Lambda U' Y $$
$$ = U U' Y $$
So $\hat{Y}$ is projected on the column space of $U$.
Replace Equation (4.9) in the beta estimation formula (4.10) to obtain
$$ \hat{\beta} = (X'X)^{-1}X' (X\beta + \epsilon) $$
$$ = \beta + (X'X)^{-1}X'\epsilon $$
The estimate of beta is unbiased, because
$$ E[(X'X)^{-1}X'\epsilon] = 0 $$
, and the covariance matrix of $\hat{\beta}$ is
(4.11)
$$ \text{var}(\hat{\beta}) = \sigma^2 (X'X)^{-1} $$
Similarly,
$$ \text{var}(\hat{Y}) = \sigma^2 X(X'X)^{-1}X' = \sigma^2 H $$
We can write these formulas using the SVD.
(4.12)
$$ \text{var}(\hat{\beta}) = \sigma^2 V \Lambda^{-2} V' $$
(4.13)
$$ \text{var}(\hat{Y}) = \sigma^2 U U' $$
The variance of the estimates $\text{var}(\hat{\beta})$ becomes larger as the columns of $X$ become more collinear. In our interpretation of the matrix $X$, this occurs when we include factors that overlap heavily with pre-existing ones.
The formulas that extend directly to the case of heteroskedastic noise. In this case we assume that $\epsilon \sim N(0, \Omega_\epsilon)$, where $\Omega_\epsilon$ is a positive-definite matrix. The estimate for $\beta$ can be derived directly from the previous formulas, by “whitening” the data, i.e., by left-multiplying $Y$ and $X$ by $\Omega_\epsilon^{-1/2}$.
$$ \Omega_\epsilon^{-1/2} Y = \Omega_\epsilon^{-1/2} X \beta + \Omega_\epsilon^{-1/2} \epsilon $$
The noise $\Omega_\epsilon^{-1/2} \epsilon$ is distributed according to a standard normal (exercise), so that the previous formulas hold. And we apply the OLS results to obtain the Weighted Least Squares (WLS) formulas:
(4.14)
$$ \hat{\beta} = (X' \Omega_\epsilon^{-1} X)^{-1} X' \Omega_\epsilon^{-1} Y $$
(4.15)
$$ \text{var}(\hat{\beta}) = (X' \Omega_\epsilon^{-1} X)^{-1} $$

---

(4.16)
$$ \mathbf{y} = X(X'\Omega_\epsilon^{-1}X)^{-1}X'\Omega_\epsilon^{-1}\mathbf{y} $$

**Exercise 4.2:**
If a matrix $X \in \mathbb{R}^{n \times m}$ has near collinear columns, then there is a unit-norm vector $\mathbf{u}$ such that $\|X\mathbf{u}\|^2 < \delta$, for some small positive $\delta$.
1.  Show that $X'X \mathbf{u} \approx \mathbf{0}$.
2.  Let $\lambda_N$ be the eigenvalue of $X'X$. Show that $\min_\mathbf{u} \lambda_N \le \delta$.
From this, show that
$$ \sum_i \text{var}(\hat{\beta}_i)^2 \ge \max_i \lambda_i^{-2} \ge 1/\delta^2 = \|X\mathbf{u}\|^{-2} $$

**4.7.2 Linear Regression Decomposition**

Split Equation (4.8) into two parts:
(4.17)
$$ \mathbf{y} = [X_1 \quad X_2] \begin{bmatrix} \beta_1 \\ \beta_2 \end{bmatrix} + \epsilon $$
where we have partitioned the predictors $X$ into two blocks. Equation (4.17) can be rewritten using block inversion for $X'X = \begin{bmatrix} X_1'X_1 & X_1'X_2 \\ X_2'X_1 & X_2'X_2 \end{bmatrix}$, and the formulas for the block inverse which involve the Schur complement of $X_1'X_1$ in $X'X$. The estimate $\hat{\beta}_2$ can be estimated by a two-stage regression. First, regress the columns of $X_2$ on those of $X_1$: $\tilde{X}_2 = X_2 - X_1(X_1'X_1)^{-1}X_1'X_2$.
The matrix $\tilde{X}_2$ contains the components of the column vectors of $X_2$ that are orthogonal to the columns of $X_1$. We say that $\tilde{X}_2$ is the projection on the orthogonal complement of the subspace spanned by $X_1$. The subspace spanned by $(X_1, \tilde{X}_2)$ is the same as the subspace spanned by $(X_1, X_2)$ (if you do not see it, prove it). Therefore the estimates $\hat{\mathbf{y}}$ and $\hat{\beta} = [\hat{\beta}_1', \hat{\beta}_2']'$ are unchanged. Second, regress $\mathbf{y}$ on $\tilde{X}_2$:
$$ \mathbf{y} = \tilde{X}_2 \tilde{\beta}_2 + \eta $$
It can be proven (see, e.g., Hansen (2007), Ch. 2) or prove it yourself as an exercise, that the least-squares coefficient of this regression is the same as $\hat{\beta}_2$.

**4.7.3 The Frisch-Waugh-Lovell Theorem**

Let us continue along the line of reasoning of the previous section, where we characterize groups of predictors. In Equation (4.17) we did above, we saw that the estimate of $\beta_2$ is unchanged if we replace $X_2$ by $\tilde{X}_2$, the component orthogonal to the columns of $X_1$, and used the resulting matrix $\tilde{X}_2$.
However, this transformation enables us to perform regressions in consecutive stages, where each stage solves a stand-alone linear estimation problem. This insight is formalized in the following theorem.

**Theorem 4.1 (Frisch-Waugh-Lovell):**
Denote the reference model
(4.18)
$$ \mathbf{y} = X_1 \beta_1 + X_2 \beta_2 + \epsilon $$
whose estimated parameters are $\hat{\beta}_1, \hat{\beta}_2$.
Estimate the system in stages. The first-stage model is
(4.19) $Y = X_1 \gamma_1 + \eta_1$
from which we get estimates $\hat{\gamma}_1, \hat{\eta}_1$.
The second stage model uses $\hat{\eta}_1$ from the first stage.
(4.20) $\hat{\eta}_1 = X_2 \gamma_2 + \eta_2$
from which we get estimate $\hat{\gamma}_2, \hat{\eta}_2$. The following identities hold:
$$ \hat{\gamma}_1 = \hat{\beta}_1 $$
$$ \hat{\gamma}_2 = \hat{\beta}_2 $$
$$ \hat{\eta}_2 = \hat{\epsilon} $$
Proof:
We use the hat matrix of $X_1$:
$$ H_1 = X_1(X_1'X_1)^{-1}X_1' $$
The operator is a projection, i.e., $H_1^2 = H_1$ and
$$ (I_n - H_1) X_1 = \mathbf{0} $$
First, we characterize the solutions for $\hat{\beta}_1, \hat{\beta}_2$. We use the property that
$$ X_1'(I_n - H_1) X_2 = X_1'(I_n - H_1) X_2 - X_1'(X_1'X_1)^{-1}X_1'X_1 X_2 = \mathbf{0} $$
$$ \mathbf{y} = [X_1 \quad X_2] \begin{bmatrix} \beta_1 \\ \beta_2 \end{bmatrix} + \epsilon $$
$$ \begin{bmatrix} \hat{\beta}_1 \\ \hat{\beta}_2 \end{bmatrix} = \begin{bmatrix} (X_1'X_1)^{-1} & -(X_1'X_1)^{-1}X_1'X_2(X_2'M_1X_2)^{-1} \\ -(X_2'M_1X_2)^{-1}X_2'X_1(X_1'X_1)^{-1} & (X_2'M_1X_2)^{-1} \end{bmatrix} \begin{bmatrix} X_1' \\ X_2' \end{bmatrix} \mathbf{y} $$
$$ \hat{\beta}_1 = (X_1'X_1)^{-1}X_1'\mathbf{y} - (X_1'X_1)^{-1}X_1'X_2 \hat{\beta}_2 $$
$$ \hat{\beta}_2 = (X_2'M_1X_2)^{-1}X_2'M_1\mathbf{y} $$
Now, let us write the outputs $\hat{\gamma}_1, \hat{\eta}_1$ of the first stage
$$ \hat{\eta}_1 = (I_n - H_1)\mathbf{y} $$
$$ \hat{\gamma}_2 = (X_2'(I_n - H_1)X_2)^{-1}X_2'(I_n - H_1)\mathbf{y} $$
Those are used to generate $\hat{\gamma}_2, \hat{\eta}_2$. We show that they are identical to $\hat{\beta}_1, \hat{\beta}_2$.
$$ \hat{\gamma}_1 = (X_1'X_1)^{-1}X_1'\mathbf{y} $$
$$ \hat{\beta}_1 = (X_1'X_1)^{-1}X_1'(\mathbf{y} - X_2 \hat{\beta}_2) $$
$$ \hat{\eta}_2 = (I_n - H_2)(I_n - H_1)\mathbf{y} = (I_n - H_1 - H_2 + H_2H_1)\mathbf{y} $$
$$ = \hat{\beta}_2 $$
The equality of $\hat{\eta}_2$ and $\hat{\epsilon}$ follows from Equations (4.19)-(4.20).
We close the section with two remarks.
1.  In Section 4.7.2 we showed that Equation (4.20) yields the same estimate as the regression on the total returns, i.e., that the coefficient estimate $\hat{\beta}_2$ is the same as $\hat{\gamma}_2$. We also saw that, after removing the independent variable, we have the option of regressing directly on the total return. However, the estimated residuals $\hat{\eta}_1$ and $\hat{\eta}_2$ will be different.
2.  The formulas above hold for the case of identical idiosyncratic volatilities. For the general case, the formula for $\hat{X}_2$ becomes
    $$ \tilde{X}_2 = (I_n - X_1(X_1'\Omega_\epsilon^{-1}X_1)^{-1}X_1'\Omega_\epsilon^{-1})X_2 $$
    Proving this is left as an exercise (hint: pre-multiply by $\Omega_\epsilon^{-1/2}$ above, use the results above, and transform back).

**Procedure 4.1: Stagewise linear regression**
1.  Estimate the model
    (4.21) $y = X_1 \beta_1 + X_2 \beta_2 + \epsilon$
    to obtain estimates $\hat{\beta}_1$ and $\hat{\beta}_2$.
2.  Regress the columns of $X_2$ on $X_1$ and take the residuals of each regression. Define $\tilde{X}_2$ as a matrix whose $j$-th column is the residual vector of $X_{2j}$ on $X_1$.
3.  Estimate the model $y = \tilde{X}_2 \tilde{\beta}_2 + \tilde{\epsilon}$ to obtain estimates $\tilde{\beta}_2$ and $\tilde{\epsilon}$.

**4.7.4 The Singular Value Decomposition**

The Singular Value Decomposition (SVD) is a fundamental factorization in numerical linear algebra. It powers many numerical computations, as Golub and Van Loan (2012) beautifully explain. In addition, it is extremely insightful in theoretical analysis. Much theoretical research. Since it is not always covered in linear algebra courses, this Appendix provides a concise review of the SVD and its main geometric intuitions, see Trefethen and Bau (1997) and Johnson (2007). Strang (2019) and the aforementioned classic book by Golub and Van Loan.
We start by recalling a basic fact of algebra. We are given a square matrix $A$ that is symmetric and positive semidefinite ($A \in \mathbb{R}^{n \times n}$, $A=A'$, $x'Ax \ge 0$ for all $x \in \mathbb{R}^n$). Then, the $n$ eigenvalues and eigenvector of $A$, $(\lambda_i, v_i)$, where $Av_i = \lambda_i v_i$, are unit-norm vectors. Then, the eigenvalues are real, positive, and the eigenvectors are orthonormal, i.e., $v_i'v_j = \delta_{ij}$. What can be said about general rectangular matrices $A \in \mathbb{R}^{m \times n}$? It is possible to generalize the notion of eigenvalues and eigenvectors to this case. The SVD states that there exist two orthonormal bases $\{u_i\}_{i=1}^m \subset \mathbb{R}^m$ and $\{v_j\}_{j=1}^n \subset \mathbb{R}^n$ that span the column space and the row space of $A$, respectively. The vectors $u_i$ are the left singular vectors, the vectors $v_j$ are the right singular vectors. Let $r = \text{rank}(A)$. The image subspace of $A$ has dimension $r$ if there are $r$ independent vectors $u_i$. The kernel subspace has dimension $n-r$ if there are $n-r$ independent vectors $v_j$, such that $Av_j = 0$. We partition $V = [V_1 \quad V_2]$, where $V_1 \in \mathbb{R}^{n \times r}$ and $V_2 \in \mathbb{R}^{n \times (n-r)}$.
(4.22)
$$ A v_i = s_i u_i \quad 1 \le i \le r $$
$$ A v_i = 0 \quad r < i \le m $$
We can write these equations in matrix form:
$$ A [v_1 \quad \dots \quad v_m] = [u_1 \quad \dots \quad u_r \quad 0 \quad \dots \quad 0] \begin{pmatrix} s_1 & & & & \\ & \ddots & & & \\ & & s_r & & \\ & & & 0 & \\ & & & & \ddots \end{pmatrix} $$
Here, in addition to the vectors $u_1, \dots, u_m$, we have completed this orthonormal basis with $u_{r+1}, \dots, u_m$, so that it spans $\mathbb{R}^m$. In compact form, Equation (4.22) can be written as $AV = U\Sigma$, where $\Sigma \in \mathbb{R}^{m \times n}$ is a diagonal matrix, with $s_i \ge 0$ on its main diagonal. Finally, we rewrite the equation after right-multiplying by $V^T$ as
(4.23)
$$ A = U \Sigma V^T $$
We show the decomposition visually in Figure 4.5.

[Image: Figure 4.5: A Singular Value Decomposition, $A = U \Sigma V^T$. Shows matrices U, Sigma, V^T.]

We prove Equations (4.22) by noting that $A^T A$ is a positive semidefinite matrix of rank $r$, so that there are $r$ pairs $(v_i, s_i^2)$ satisfying $(A^T A)v_i = s_i^2 v_i$. Define $u_i := s_i^{-1} A v_i$. These satisfy Equation (4.22). We prove the $u_i$ are orthonormal.
(4.24)
$$ u_i' u_j = s_i^{-1} v_i' A^T A v_j s_j^{-1} = s_i^{-1} v_i' s_j^2 v_j s_j^{-1} = \frac{s_j}{s_i} v_i' v_j = \delta_{ij} $$
Because $v_1, \dots, v_n$ are orthonormal. Now we complete the basis in $\mathbb{R}^m$ by adding orthonormal vectors $u_{r+1}, \dots, u_m$. Then $U$ and $V$ are orthonormal matrices, and $\Sigma$ is a diagonal matrix. This makes a connection to the SVD. A few observations (among many) on the SVD:
1.  If all the singular values are distinct, the first $r$ columns of $U$ and $V$ are uniquely determined. However, they are not in the case of identical singular values.
2.  The SVD of a symmetric positive definite matrix $A$, and in particular for the covariance matrix, can easily be defined from the SVD.
    $$ A^T = (U \Sigma V^T)^T = V \Sigma^T U^T = V \Sigma U^T $$
    The condition $A=A^T$ implies that this definition meets the requirement of representation. For the specific case of the square root, one can show that $A^{1/2} A^{1/2} = A$.
    Equation (4.23) can be rewritten as:
    $$ A = \sum_{i=1}^r s_i u_i v_i^T $$
    The SVD decomposes a matrix into a sum of rank-one matrices.
3.  For all $k \le r$, $A_k = \sum_{i=1}^k s_i u_i v_i^T$.
4.  $A A^T u_i = s_i^2 u_i$ and $A^T A v_i = s_i^2 v_i$.
    In other terms, $A A^T$ and $A^T A$ have the same eigenvalues.
5.  The SVD decomposes the operations on an element in $\mathbb{R}^n$ into a rotation, a rescaling of the axes (turning a ball into an ellipsoid), followed by another rotation. The net result is that any operator $A$ maps a point on a ball into a point on a rotated ellipsoid. Figure 4.6 illustrates the steps of the SVD.

[Image: Figure 4.6: Singular Value Decomposition as a sequence of steps: rotation, scaling, rotation. Shows a circle transformed into ellipses through these steps.]

---

**4.8 Exercises**

**Exercise 4.3 (Portfolio Covariance):**
Generalize this result. Let $\mathbf{f}$ be a random vector taking values in $\mathbb{R}^m$ with covariance matrix $\Omega_f$. Let $A \in \mathbb{R}^{n \times m}$. Prove that the covariance matrix of the random vector $A\mathbf{f}$ is $A \Omega_f A^T$.
Say that a random vector $\mathbf{x}$ follows a multivariate normal distribution with covariance matrix $\Omega$. Let $U$ be the Singular Value Decomposition of $\Omega = U \Lambda^{1/2} \Lambda^{1/2} U^T$ and define
$$ \Omega^{1/2} U = \begin{pmatrix} \lambda_1^{1/2} & & & \\ & \lambda_2^{1/2} & & \\ & & \ddots & \\ & & & \lambda_m^{1/2} \end{pmatrix} U^T $$
Let $\mathbf{z}$ be a Gaussian distribution with unit covariance matrix. Prove that $E[\mathbf{z}\mathbf{z}^T] = I_m$. Then covariance is $\Omega$.

**Exercise 4.4:**
Provide a counterexample in which it is not possible to center the loadings with a rotation. (Hint: Use a one-factor model.)

**Exercise 4.5:**
Find conditions under which matrix $(X_1'X_1)$ is invertible.

**The Takeaways**

1.  Factor models express asset returns as a combination of factor contributions and idiosyncratic components. Their general form is
    $$ \mathbf{r}_t = \alpha + \mathbf{Bf}_t + \mathbf{\epsilon}_t $$
2.  Interpretations of Factor Models:
    *   Graphical Model: Illustrates dependencies between assets and factors using nodes and edges.
    *   Superposition of Effects: Asset returns are a sum of weighted factor contributions.
    *   Single-Asset Product: Expected return of an asset is the inner product of the factor loadings and factor returns.
3.  Alpha Components:
    *   Alpha Spanned: Portion of alpha explained by factors, indistinguishable from expected factor returns.
    *   Alpha Orthogonal: Portion of alpha unexplained by factors; offers diversification benefits and can enhance Sharpe Ratio.
4.  Transformations of Factor Models:
    *   Rotations: Change factor representations without altering model predictions (e.g., for interpretability).
    *   Projections: Reduce the number of factors while approximating the original model.
    *   Push-Outs: Expand the model by adding new factors to capture additional structure.
5.  Applications of Factor Models:
    *   Performance Attribution: Decompose portfolio returns into factor and idiosyncratic attributions.
    *   Risk Management: Forecast and decompose portfolio volatility into systematic and idiosyncratic risk.
    *   Portfolio Construction: Optimize expected returns, factor risk exposures and portfolios.
    *   Alpha Research: Identify sources of returns and separate skill from luck by analyzing alpha components.

**Notes**

1.  [1] Factor models go back to the birth of psychometrics at the turn of the 19th century. Seminal contributions to the subject are Johnson and Wichern (2007), Rencher and Christensen (2012). The use of factor models was first introduced by Sharpe (1964, 1963a) for the one-factor case, which was extended to multiple factors by Ross (1976b). Good introductions to factor models in finance are the survey papers by Connor and Korajczyk (2010), Fama et al. (1969) or the survey by Connor et al. (2010) and Connor and Korajczyk (2010), MacKinlay (1995).
2.  [2] We also use the terms residual and specific in place of “idiosyncratic”.
3.  [3] The use of the term “style” will be clear later, when we associate it with loading styles.
4.  [4] A dummy variable taking binary values (e.g., 0 or 1) or more generally values in a finite set. We will only use binary variables.
5.  [5] Graphical models are covered in monographs (Lauritzen, 1996), books on machine learning (Bishop, 2006; Murphy, 2012), and survey papers (Meilă et al., 2007).
6.  [6] Fair Market Value (FMV) is the amount invested in the security in the reference currency (numeraire).
7.  [7] For example, for U.S. equities, the maximum annualized idiosyncratic volatility is approximately 25%.
8.  [8] We have given up on the elegant eigenvalue of the sparse matrix $\Omega_\epsilon$.
9.  [9] Economic reason in terms of “increasing” economies as a function of the tradable assets. I believe there is not much to gain from this level of abstraction, so I keep the exposition and the inequalities in finite dimensions.
10. [10] See Appendix 4.7.4 for an introduction to the SVD and the concept of rank of a matrix, which we will use throughout the book.
11. [11] We use the notation $x \in [0, 1, \dots]$.
12. [12] A marketing term used for this investment style is smart beta.
13. [13] Important: when using commercial data, always check the data specification carefully. Make sure that the time index for the loadings is $t-1$ (by convention) and that the corresponding asset returns are for the period $[t-1, t]$.
14. [14] Not a joke: as of October 2012, the Vatican has 764 citizens; Amazon lists over 1,000 books in the “Probability and Statistics” section with “regression” in their title or subject, the vast majority of them covering linear models.
15. [15] Linear regression is an inexhaustible topic. Some useful references are, in order of increasing detail, Wasserman (2004), Hastie et al. (2008), Johnson and Wichern (2007), Harrell (2015), Gelman et al. (2013), Hansen (2019).
16. [16] For a detailed discussion of the MLE, see Robert (2007).
17. [17] The minimum is unique if the rank of $X$ is $m$, i.e., if all the columns of $X$ are linearly independent. In Chapter 5 we will encounter cases of rank-deficient matrices.

```

Okay, here is the Markdown compilation for Chapter 5.

```markdown
Everand

**Chapter 5**
**Evaluating Risk**

**The Questions**

1.  Given the absence of a single performance measure for benchmarking factor models, how should one proceed and select the best model for a specific use-case?
2.  What are the robust loss functions suitable for evaluating volatility predictions in factor models?
3.  What are the tests suitable for testing the performance of covariance matrices for portfolio optimization?
4.  What are the advantages and limitations of different approaches?
5.  What additional tests should we perform to ensure that models can be used in production environments?

There are dozens of papers and documents extolling the virtues of commercial models. Many alternative models. Several asset classes. All combinations of geographies. And, of course, many vendors. However, there are hardly any papers laying out theoretically motivated procedures that test risk properties of factor models that allow practitioners to choose among them. This is a void that I believe is worth plumbing. In the words of E. E. Cummings, “Listening is Love the Earth; nobody wants to help Mom do the dishes.” This is a chapter about doing dishes. It relies on two simple principles. First, the metrics that we use should be related as much as possible to real applications. We care about accuracy of volatility forecasts, and realized volatility of optimized portfolios. We also want to measure these quantities in a realistic setting. The second principle follows from the observation that there is not a single performance measure on which we benchmark factor models. It follows that it is possible that a single “best” model may not exist, because it could be that a single model outperforms all the others on all metrics. This should not be overly surprising. Our goal is not to find the best, but to concentrate our efforts on our use-case, or at least prioritize for it, and find the best model for the task.

The remainder of the chapter is organized around three families of metrics: those aimed at evaluating the covariance matrix, those aimed at evaluating the precision matrix, and those aimed at evaluating the model suitability for secondary tasks.

---

**5.1 Evaluating the Covariance Matrix**

**5.1.1 Robust Loss Functions for Volatility Estimation**

A major application of a factor model is volatility estimation. The quality of volatility predictions is one that has been at the core of research in the development of risk models. It is often framed as a problem of point prediction. At a certain time $t$ (i.e., the volatility prediction made available at time $t-1$ for time interval $[t-1, t]$), there is a measure of the quality of the volatility predictions is given by a loss function
$$ L_t = \frac{1}{N} \sum_{i=1}^N L(\hat{\sigma}_{it}^2, \sigma_{it}^2) $$
where $\hat{\sigma}_{it}$ is an empirical estimate of the observed volatility $\sigma_{it}$, the realized volatility returns of asset $i$ over period $t$. This loss function $L(x,y)$ is non-negative, and equal to zero if and only if $x=y$. In the metrics station above, we use a volatility proxy $r_{it}^2$ instead of the unknown true volatility $P_t$. Hansen and Lunde (2006a) introduce a concept of rank robustness for losses: if we have two alternative volatility forecasts $\hat{\sigma}_{it}^{(1)}$ and $\hat{\sigma}_{it}^{(2)}$, $\hat{\sigma}_{it}^{(1)}$ is better than the other using an unbiased volatility proxy if and only if one is better than the other using the true volatility. That is,
$$ L(\hat{\sigma}_{it}^{(1)}, \sigma_{it}^2) \le L(\hat{\sigma}_{it}^{(2)}, \sigma_{it}^2) \iff L(\hat{\sigma}_{it}^{(1)}, \hat{r}_{it}^2) \le L(\hat{\sigma}_{it}^{(2)}, \hat{r}_{it}^2) $$
Patton and Sheppard (2009); Patton (2011) completely characterize these loss functions and show that these two are robust:
$$ \text{QLIKE}(\sigma, \tau) := \frac{1}{T} \sum_{t=1}^T \left( \frac{r_t^2}{\hat{\sigma}_t^2} - \log\left(\frac{r_t^2}{\hat{\sigma}_t^2}\right) - 1 \right) $$
$$ \text{MSE}(\sigma, \tau) := \frac{1}{T} \sum_{t=1}^T \left( \frac{r_t^2}{\hat{\sigma}_t^2} - 1 \right)^2 $$
QLIKE is (save for constants) the negative of the log-likelihood of the normal distribution. These two loss functions are increasingly being used in place of the Bias statistic.[1] Their graphs are shown in Figure 5.1.

[Image: Figure 5.1: QLIKE and MSE comparison. Notice that QLIKE is skewed, with higher losses when the realized variance is smaller than the estimated variance. Plot shows QLIKE (red) and MSE (blue) loss functions vs r_t^2 / sigma_hat_t^2.]

**5.1.2 Application to Multivariate Returns**

The loss functions QLIKE and MSE apply to univariate returns, not to covariance matrices. Below are a few ways to adapt the univariate setting to a multivariate one.

*   **Production Strategies.**
    If strategies are already running, a straightforward and necessary test is to evaluate their simulated performance under different factor models. QLIKE and MSE are important and should be checked jointly with metrics that are important for the portfolio manager, like Sharpe Ratio or PnL. It is important that the covariance matrix is tailored to the production strategy. Ideally, a portfolio should be generated on the basis of the factor model itself. If a portfolio is generated using factor model A and then tested on model B, the test will be marred by this asymmetry.
*   **Average-Case Analysis.**
    An alternative approach is to estimate the expected loss, where the expectation is taken over a distribution of portfolios as well as of asset returns. For the distribution of returns, we use the empirical measure $P$ of historical returns; for the distribution of portfolios, we may choose a simple one, like uniform on a sphere (see Procedure 5.1). Then we estimate
    $$ E_{P,W} [L(W' \hat{\Omega} W, W' \Omega W)] $$
    There are a few drawbacks to this approach. First, there is a degree of arbitrariness in choosing a portfolio distribution. The actual distribution of portfolios is almost certainly not uniform; and it is not even warranted that the distribution of alphas is uniform. Second, it is computationally expensive. We are averaging in high dimensional spaces, with $W$ varying in size from $10^2$ to $10^4$ in typical models. Consequently, issues such as calculation errors and convergence criteria, become important. An approximation is to select a portfolio basis, say, $N$ portfolios $W_1, \dots, W_N$, and then apply an “average” case analysis to these $N$ portfolios. A special case of this approach is that of eigenportfolios (see Section 5.2.1), i.e., $U S U'$ where $U$ are the eigenportfolios (equal to the columns of $U$). This is more computationally tractable. One important drawback is that this average loss is not independent of the choice of the portfolio; in fact, it is quite sensitive to it. Even if we restrict our choice to an orthonormal basis, the performance of the measured portfolio still depends on the basis. Since the choice of an appropriate basis cannot be easily justified based on principles, the outcome is arbitrary.

    **Procedure 5.1: Random portfolios average variance testing**
    1.  Inputs: candidate covariance matrices $\hat{\Omega}_k$, and returns $r_t$ for $t=1, \dots, T$.
    2.  Set $L_{tot} = 0$.
    3.  Set $W \sim N(0, I_N)$, $W \leftarrow W/\|W\|$.
    4.  Choose $k$ uniformly at random in $1, \dots, K$.
    5.  $L_{tot} \leftarrow L_{tot} + L(r_t' W, W' \hat{\Omega}_k W, W' \Omega W)$
    6.  Set $N_{sim} \leftarrow N_{sim} + 1$.
    7.  If $L(r_t' W, W' \hat{\Omega}_k W, W' \Omega W) / L_{tot} \ge \epsilon_{tol}$
        go to Step 3.
    8.  Output: $L_{avg} = L_{tot} / N_{sim}$.
*   **Worst-Case Under/Over Prediction.**
    Yet another approach is to estimate the worst-case loss function:
    $$ \max_W E_P [L(r'W, W' \hat{\Omega} W, W' \Omega W)] $$
    $$ \text{s.t. } \|W\| \le 1 $$
    The problem with this approach is that the objective function (be it QLIKE or MSE) is not convex. When the number of assets is large, the problem is not computationally tractable.

    **Procedure 5.2: Worst-case variance testing**
    1.  Inputs: candidate covariance matrices $\hat{\Omega}_k$, and returns $r_t$ for $t=1, \dots, T$. Loss function $L$.
    2.  Set $L_{max} = 0, N_{iter} = 0$.
    3.  Set $W \sim N(0, I_N)$, $W \leftarrow W/\|W\|$.
    4.  Choose $k$ uniformly at random in $1, \dots, K$.
    5.  Set
        $$ W \leftarrow W - \eta_{iter} \nabla_W L(r_t' W, W' \hat{\Omega}_k^T W, W' \Omega W) $$
    6.  Set $N_{iter} \leftarrow N_{iter} + 1$.
    7.  If $L(r_t' W, W' \hat{\Omega}_k^T W, W' \Omega W) / L_{tot} \ge \epsilon_{tol}$
        go to Step 3.
    8.  Output: $L_{max} = \max_k L(r_t' W, W' \hat{\Omega}_k^T W, W' \Omega W)$.

    None of the above dominates the others. Whenever available, production strategies are always tested against alternative approaches. Average- and worst-case analyses are both computationally very demanding. Moreover, in the case of average-case analysis the result depends on the assumption on portfolio distribution.
*   **Leading Alpha, MVO Portfolios.**
    Another option is to construct portfolios based on the actual leading alphas of the securities. This scheme has the advantage to use the predictiveness of the strategy for “relevant” portfolios and is described in Procedure 5.3. After all, volatility prediction matters only if we have alpha in the first place. If we don’t, then we have other problems to be worried about.

    **Procedure 5.3: Realized alpha variance testing**
    1.  Inputs: candidate covariance matrices $\hat{\Omega}_k$, and returns $r_t$ for $t=1, \dots, T$. Loss function $L$.
    2.  Set $L_{tot} = 0$.
    3.  For each $t=0, \dots, T-\tau$, let
        $$ \alpha_t := \frac{1}{\tau} \sum_{s=t+1}^{t+\tau} r_s $$
        $$ W_t := \hat{\Omega}_{k,t}^{-1} \alpha_t $$
    4.  $L_{tot} := L_{tot} + L(r_{t+\tau+1}' W_t, W_t' \hat{\Omega}_{k, t+\tau+1}^T W_t)$
    5.  Output:
        $$ L := L_{tot} / (T-\tau+1) $$
    An advantage of this approach is that it can easily be augmented. For example, we could test the performance on portfolios with added noise:
    $$ W := \hat{\Omega}_{k,t}^{-1} (\alpha_t + \eta_t), \quad \eta_t \sim N(0, \sigma_\eta^2 I_N) $$
*   **Distribution Likelihood.**
    An alternative that does not depend on the portfolio choice is to use the log-likelihood for the zero-mean multivariate normal distribution, applied to the returns of the estimation universe. Modulo constant terms, the negative log-likelihood, $L$, is proportional to:
    (5.2)
    $$ \text{QDIST} = \sum_t (\mathbf{r}_t' \hat{\Omega}_{k,t}^{-1} \mathbf{r}_t + \log |\hat{\Omega}_{k,t}|) + N \log(2\pi) $$
    **Exercise 5.1**
    In their survey paper, Patton and Sheppard (2009) propose a multivariate test for $\Omega_k$ using a proxy estimate for the true covariance matrix $\hat{\mathbf{H}}_t$. The loss function they propose is
    $$ L = \sum_t \text{trace} \left( (\hat{\Omega}_{k,t}^{-1} - \hat{\mathbf{H}}_t^{-1}) \hat{\mathbf{H}}_t (\hat{\Omega}_{k,t}^{-1} - \hat{\mathbf{H}}_t^{-1}) \hat{\mathbf{H}}_t \right) - T \log |\hat{\Omega}_{k,t}^{-1} \hat{\mathbf{H}}_t| $$
    Show that, when $\hat{\mathbf{H}}_t = r_t r_t'$, $L$ is equivalent to QDIST, i.e.,
    $L = a \times \text{QDIST} + b$
    for some positive constant $a$.

---

**5.2 Evaluating the Precision Matrix**

**5.2.1 Minimum Variance Portfolios**

As we have seen repeatedly throughout the book, the quality of a factor model is related to the accuracy of its precision matrix. We propose two tests. The first one is based on a well-known portfolio construction method. We consider a very simple example: construct a portfolio $\mathbf{w}$ of minimum variance and with unit net market value $\sum_i w_i = 1$. This is the ex-ante minimum variance portfolio; the realized variance will differ. The intuition is that a “better” covariance matrix will result in a realized variance. We make this intuition rigorous, and generalize to the case where the portfolio has a given expected return or arbitrary factor risk. Let $\hat{\Omega}_k \in \mathbb{R}^{N \times N}$ be a candidate covariance matrix and $\Omega_t$ be the true covariance matrix. Let $\hat{\mathbf{w}}_k = \hat{\Omega}_k^{-1} \mathbf{1}_N$, and solve the risk-minimization problem
$$ \min_{\mathbf{w}} \mathbf{w}' \hat{\Omega}_k \mathbf{w} $$
$$ \text{s.t. } \mathbf{1}_N' \mathbf{w} = 1 $$
and let $\mathbf{w}_k(\hat{\Omega}_k)$ be its solution. We compare the realized variance of the portfolio $\text{var}(\mathbf{w}_k(\hat{\Omega}_k), \Omega_t)$. Then, the realized volatility of portfolio $\mathbf{w}_k(\hat{\Omega}_k)$ is greater than that of $\mathbf{w}_k(\Omega_t)$, and the two are identical if and only if $\hat{\Omega}_k = \Omega_t$. This is Theorem 5.1 in the Appendix (Section 5.4). A way to apply this result is as follows: fix $\hat{\Omega}_k = \hat{\Omega}_A$, and define $\mathbf{w}_A = \mathbf{w}_k(\hat{\Omega}_A)$. Then compare $\text{var}(\mathbf{w}_A, \Omega_t)$ with $\text{var}(\mathbf{w}_B, \Omega_t)$. This comparison of realized variance of minimum variance portfolios is by far the realized Sharpe Ratio for a certain strategy.

We can use all the portfolio-dependent schemes introduced for volatility tests to evaluate the precision matrix. The realized variance acts as a loss function.

**5.2.2 Mahalanobis Distance**

There is another test that is portfolio-independent and that involves the precision matrix only. The Mahalanobis distance is defined for a multivariate zero-mean random vector $\mathbf{r}$ and an associated covariance matrix $\Omega_r$ as
$$ d(\mathbf{r}, \Omega_r) = \sqrt{\mathbf{r}' \Omega_r^{-1} \mathbf{r}} $$
. For Gaussian returns and the true covariance matrix, $d_t^2$ is distributed according to a chi-squared distribution with $N$ degrees of freedom.[2] One test is then
$$ \text{MALV} := \frac{1}{T} \sum_{t=1}^T d(\mathbf{r}_t, \hat{\Omega}_{k,t})^2 = \frac{1}{T} \sum_{t=1}^T \mathbf{r}_t' \hat{\Omega}_{k,t}^{-1} \mathbf{r}_t $$
$$ \text{MALV} := \text{var} (P_1, \dots, P_T) $$
The lower the value of MALV($\hat{\Omega}_k$), the better the performance of the precision matrix. If the variance is very large (say, if $d_t^2 / N \gg 1$), the value of the test is not very useful for evaluating precision, preferring volatility. We don’t primarily care about the constant in this test, because a volatility test should address that issue. A different way to interpret the result is the following: if returns are Gaussian, then they are distributed as $N(0, \hat{\Omega}_k)$ with $\hat{\Omega}_k$ constant. The Mahalanobis distance is $N$ times the mean of $d_t^2$. Its mean is $N$ and standard deviation $\sqrt{2N}$. For large $N$, $d_t^2 \approx N$. If $\hat{\Omega}_k$ is constant (i.e., $\hat{\Omega}_{k,t} = \hat{\Omega}_k$), this means MALV as follows:
$$ \hat{\mu} = \frac{1}{T} \sum_{t=1}^T \mathbf{r}_t $$
$$ \hat{\Sigma} = \frac{1}{T} \sum_{t=1}^T (\mathbf{r}_t - \hat{\mu})(\mathbf{r}_t - \hat{\mu})' - \hat{\nu} $$
$$ \approx \frac{1}{T} \sum_{t=1}^T (\mathbf{r}_t' \hat{\Omega}_k^{-1} \mathbf{r}_t - N)^2 - \hat{\nu} $$
$$ \approx \frac{1}{T} \sum_{t=1}^T (\mathbf{r}_t' \hat{\Omega}_k^{-1} \mathbf{r}_t - N)^2 $$
The approximate equality results from the fact that we have replaced $\hat{\Omega}_k$ with its expected value. We see here an instance of
$$ \Omega_{k,t}^{-1/2} \mathbf{r}_t \sim N(0, I_N) - \hat{\mu}_k^T \hat{\Omega}_k^{-1} \hat{\mu}_k $$
its zero by multiplying the left and right by standard multivariate Gaussian random vectors. In Section 10.3, we will see that this matrix difference is also responsible for bounding the Sharpe Ratio efficiency.

---

**5.3 Ancillary Tests**

In addition to performance measures on the ex-ante covariance matrix $\hat{\Omega}_k$ and its inverse, we want to verify that the model performs well at tasks that are indirectly related to portfolio construction and hedging. We consider two specifically. The first one is model turnover. Changes over time in the data we have at hand affect the transaction costs of our strategies. There are three major drivers of such changes. The first is the time-varying nature of expected returns, i.e., alpha. However, the second and third drivers are factor exposures and factor volatilities. We need to verify that these changes are not too large. The second is due to changes in the market impact function itself. There are exceptional periods in which trading activity changes rapidly, and so does the cost of trading. However, in general, this is the most stable component in portfolio construction and we assume it is accurately known. The last driver of change is the factor return, which is the output of the following subsection.

**5.3.1 Model Turnover**

Turnover is an intrinsic property of a model. It is the property of a production trading strategy. However, it may make sense to have a given estimate of turnover. For example, in an ideal setting in which there are no transaction costs, we may want to target a constant factor exposure level, for factor $k$. In this setting, it is optimal to trade Factor-Mimicking Portfolios (FMPs). The FMP is the portfolio that provides the best approximation to the true factor returns of the model. They are defined in Section 7.1.1. The weights of these portfolios are the column vectors of the matrix
$$ \mathbf{P}_t := \Omega_{\epsilon,t}^{-1} \mathbf{B}_t (\mathbf{B}_t' \Omega_{\epsilon,t}^{-1} \mathbf{B}_t)^{-1} $$
$$ \mathbf{w}_t := \mathbf{P}_t \mathbf{b} $$
Portfolio turnover is driven by the changes in $\mathbf{P}_t$. We then define a simple measure of quadratic turnover as the time series average
$$ \text{turnover}_T := \frac{1}{T} \sum_{t=1}^T \| \mathbf{P}_t - \mathbf{P}_{t-1} \|_F^2 $$
where $\| \cdot \|_F$ is the Frobenius norm of a matrix. This definition has the advantage of being simple and intuitive. It is positive definite, at the cost of losing generality. If we have an indication of the target exposures $\mathbf{b}_t$ of our strategy, and we have a trading cost function $TC(\cdot, \cdot)$, then a more accurate measure of turnover would be
$$ \text{turnover}_{TC} := \frac{1}{T} \sum_{t=1}^T TC(\mathbf{P}_t - \mathbf{P}_{t-1}, \mathbf{b}_t) $$

**5.3.2 Testing Betas**

A practical application of risk models is to produce predicted betas of investor portfolios versus some benchmark. A simple instance is predicting the beta of a long-only portfolio of highly liquid stocks versus the S&P500. This beta is an FMP. An even less obvious example is that of beta to a thematic portfolio. For example, a bank has generated a thematic portfolio that describes an industrial or consumption trend that is expected to occur at that point in time. We want to measure the beta of this portfolio to this thematic portfolio. In all of these cases, we want to make sure that the predicted beta matches the ex-post beta, in the sense that it exhibits low discrepancy to the realized beta. Therefore, as part of the evaluation of the risk model, we want to include tests on betas. For simplicity, consider the case of a single-instrument portfolio (FMP, or thematic portfolio). The vector of predicted betas of each asset to this reference portfolio is
$$ \hat{\beta}_t(\mathbf{w}) = \frac{\mathbf{w}' \hat{\Omega}_{k,t} \mathbf{w}_{ref}}{\mathbf{w}_{ref}' \hat{\Omega}_{k,t} \mathbf{w}_{ref}} $$
The exponentially weighted empirical mean $\hat{\Omega}_{k,t}$, and realized beta vector is given by
$$ \hat{\Omega}_{k,t} = \frac{1 - e^{-T/\tau}}{1 - e^{-1/\tau}} \sum_{s=0}^{T-1} e^{-s/\tau} \mathbf{r}_{t-s} \mathbf{r}_{t-s}' $$
$$ \hat{\beta}_t(\mathbf{w}) := \frac{\mathbf{w}' \hat{\Omega}_{k,t} \mathbf{w}}{\mathbf{w}' \hat{\Omega}_{k,t} \mathbf{w}} $$
We measure the beta accuracy as
$$ \text{BETAERR}(\mathbf{w}) = \sum_t \| \hat{\beta}_t(\mathbf{w}) - \beta_t \|^2 $$
and employ BETAERR as an ancillary measure of accuracy.

---

**5.3.3 Coefficient of Determination?**

A very popular way to summarize the performance of a factor model is to measure the average coefficient of determination (or $R^2$) of the weighted cross-sectional regression. It is defined as 1 minus the ratio of the sum-of-squared residual sum of squares and the total sum of squares:
$$ R^2 = 1 - \frac{\sum_{t=1}^T \mathbf{e}_t' \Omega_{\epsilon,t}^{-1/2} \Omega_{\epsilon,t}^{-1/2} \mathbf{e}_t}{\sum_{t=1}^T (\mathbf{r}_t - \bar{\mathbf{r}}_t)' \Omega_{\epsilon,t}^{-1/2} \Omega_{\epsilon,t}^{-1/2} (\mathbf{r}_t - \bar{\mathbf{r}}_t)} = 1 - \frac{\sum_{t=1}^T \mathbf{e}_t' \Omega_{\epsilon,t}^{-1} \mathbf{e}_t}{\sum_{t=1}^T (\mathbf{r}_t - \bar{\mathbf{r}}_t)' \Omega_{\epsilon,t}^{-1} (\mathbf{r}_t - \bar{\mathbf{r}}_t)} $$
Since the idiosyncratic covariance matrix $\Omega_{\epsilon,t}$ is not known in advance, a proxy is used in its place, as described in Chapter 4 and 7. The estimated factor returns $\hat{\mathbf{f}}_t$ are the coefficients of the cross-sectional regression in period $t$. A high coefficient of determination is interpreted as a positive attribute of the model since, in the case of factor models, most of the variability of returns is due to common factors. First, there is a “look-ahead” estimate of $\Omega_{\epsilon,t}$. We cannot possibly estimate the performance of the model on a holdout sample because the estimated coefficients, the factor returns, must be estimated in every period. This makes the statistic sensitive to data snooping. Second, even if they keep constant over time, the quality of the model (the number of factors) and the choice of the successive manipulations and adjustments to the loading matrices $\mathbf{B}_t$. The naive $R^2$ is always improved by adding factors (even with random loadings) to an existing model, although the fact that more refined metrics, like AIC and BIC, provide more tools to use. It is not possible to answer this question in general. Another solution to the use of $R^2$ is to compare the performance of the model at hand. To illustrate the problem, consider an artificial example. Asset returns follow a simple static factor model $r_t = B f_t + \epsilon_t$, with $B \in \mathbb{R}^{N \times K}$. The estimated factor returns are $\hat{f}_t = (B'B)^{-1} B' r_t$. We build a new factor model, where the estimated factor returns $\tilde{f}_t$ are a sequence of random vectors defined as follows:
$$ \tilde{f}_{1,t} = 0 \quad \dots \quad 0 $$
$$ \tilde{f}_{2,t} = 0 \quad \dots \quad 0 $$
$$ C_t = \begin{pmatrix} \tilde{f}_{1,t} & 0 & \dots & 0 \\ 0 & \tilde{f}_{2,t} & \dots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \dots & \tilde{f}_{K,t} \end{pmatrix} $$
where $C_k^T C_k = C_k C_k^T = I_N$.
After some rote calculations, we find that the estimated factor returns from this model are
$$ \hat{\mathbf{f}}_t = (\mathbf{B}_t' \mathbf{B}_t)^{-1} \mathbf{B}_t' \mathbf{r}_t = C_t \mathbf{f}_t $$
The coefficient of determination is unchanged.
$$ R^2(\tilde{\mathbf{B}}_t) = 1 - \frac{\sum_{t=1}^T \| \mathbf{r}_t - (\mathbf{L}_t \mathbf{C}_t \mathbf{B}_t \mathbf{C}_t^{-1}) \mathbf{B}_t' \mathbf{r}_t \|^2}{\sum_{t=1}^T \| \mathbf{r}_t \|^2} $$
$$ = 1 - \frac{\sum_{t=1}^T \| (I_N - \mathbf{L}_t \mathbf{B}_t \mathbf{B}_t') \mathbf{r}_t \|^2}{\sum_{t=1}^T \| \mathbf{r}_t \|^2} $$
$$ = R^2(\mathbf{B}) $$
However, the estimated factor covariance matrix of the rotated model is
$$ [\hat{\Omega}_f]_{k,j} = \frac{1}{T} \sum_{t=1}^T \hat{f}_{k,t} \hat{f}_{j,t} $$
$$ \rightarrow \begin{cases} [\Omega_f]_{k,j} & \text{if } i=j \\ 0 & \text{if } i \ne j \end{cases} $$
When $N \gg K$, the average of $r_{it}^2$ is $\approx \sigma_{i\epsilon}^2$, i.e., it is identical to the variance of the original non-rotated model. When $N \approx K$, the sum approaches 0 because of the independence of $f_{k,t}$ and $f_{j,t}$, ($i \ne j$); and $E[f_{k,t} f_{j,t}] = E[f_{k,t}] E[f_{j,t}] = 0$.
The limitations of $R^2$ have led to the effect of decorrelating the estimated factor returns. To see how, we have here the effect of decorrelating the estimated factor returns. In summary we have two models, one is the true model, the other is a rotated model with reestimations in every period. The two models are indistinguishable in terms of $R^2$. The estimated factor returns are very different. The two models are also identical. However, the second model has a very different—and incorrect—covariance matrix. Expert modelers are aware of the shortcomings of $R^2$ for factor modeling, and resort to heuristics to confirm the correctness of the cross-sectional regression. One such heuristic is that the factor returns of a model which achieve a high $R^2$ should have significance criterion, i.e., the regression coefficient corresponding to a factor has an absolute t-score greater than two. Another natural check is on the realized Sharpe Ratios of each factor return. These tests confirm that $R^2$ is inadequate for factor model selection.[5] The recommendation is to rely on the tests we presented earlier in this chapter for risk model performance, and on Chapter 8 for testing risk-adjusted performance.

---

**5.4 Appendix**

**5.4.1 Proof for Minimum Variance Portfolios**

**Theorem 5.1:**
(Engle and Colacito, 2006) Let $\hat{\Omega}_k \in \mathbb{R}^{N \times N}$ be a candidate covariance matrix and $\Omega_t$ be the true covariance matrix. Let $\hat{\mathbf{w}}_k = \hat{\Omega}_k^{-1} \mathbf{1}_N$, and solve the risk minimization problem
$$ \min_{\mathbf{w}} \mathbf{w}' \hat{\Omega}_k \mathbf{w} $$
$$ \text{s.t. } \mathbf{1}_N' \mathbf{w} = 1 $$
and let $\mathbf{w}_k(\hat{\Omega}_k)$ be its solution. Then the realized variance of the portfolio $\text{var}(\mathbf{w}_k(\hat{\Omega}_k), \Omega_t)$ is greater than that of $\mathbf{w}_k(\Omega_t)$, and the two are identical if and only if $\hat{\Omega}_k = \Omega_t$.

Proof:
The solution of Problem (5.1) is
$$ \mathbf{w}(\hat{\Omega}_k) = (\mathbf{1}_N' \hat{\Omega}_k^{-1} \mathbf{1}_N)^{-1} \hat{\Omega}_k^{-1} \mathbf{1}_N $$
The ratio between realized variance of the portfolios constructed on $\hat{\Omega}_k$ and on $\Omega_t$ is
$$ \frac{\text{var}(\mathbf{w}(\hat{\Omega}_k), \Omega_t)}{\text{var}(\mathbf{w}(\Omega_t), \Omega_t)} = \frac{\mathbf{1}_N' \hat{\Omega}_k^{-1} \Omega_t \hat{\Omega}_k^{-1} \mathbf{1}_N}{(\mathbf{1}_N' \hat{\Omega}_k^{-1} \mathbf{1}_N)^2} \frac{(\mathbf{1}_N' \Omega_t^{-1} \mathbf{1}_N)}{\mathbf{1}_N' \Omega_t^{-1} \Omega_t \Omega_t^{-1} \mathbf{1}_N} $$
One can readily verify that if $\hat{\Omega}_k = \Omega_t$, the ratio is one. Let $\Omega_t^{1/2}$ be the SVD of $\Omega_t = U S U'$. Let $\mathbf{H} = \Omega_t^{-1/2} \hat{\Omega}_k \Omega_t^{-1/2}$.
Then we rewrite the variance ratio as
$$ \frac{\text{var}(\mathbf{w}(\hat{\Omega}_k), \Omega_t)}{\text{var}(\mathbf{w}(\Omega_t), \Omega_t)} = \frac{\mathbf{x}' \mathbf{H}^{-1} \mathbf{x}}{(\mathbf{x}' \mathbf{H}^{-1} \mathbf{x})^2} \frac{(\mathbf{x}' \mathbf{x})}{1} $$
Consider now the SVD of $\mathbf{H} = V D V'$ and define $\mathbf{y} = V' \mathbf{x}$. We have
$$ \frac{\text{var}(\mathbf{w}(\hat{\Omega}_k), \Omega_t)}{\text{var}(\mathbf{w}(\Omega_t), \Omega_t)} = \frac{(\sum_i y_i^2/d_i)}{(\sum_i y_i^2/d_i)^2} (\sum_i y_i^2) $$
The term on the RHS can be interpreted as $E[1/U]$, where $U$ is a random variable taking value $d_i$ in state $i$ with probability $p_i = y_i^2 / \sum_j y_j^2$. By Jensen’s inequality, $E[1/U] \ge 1/E[U]$, and the result follows.

**The Takeaways**

1.  When evaluating a factor model, we are concerned with three dimensions of performance:
    *   Accuracy of the covariance matrix, since the portfolio’s volatility prediction accuracy depends on it.
    *   Accuracy of the precision matrix, since it is used in mean-variance portfolio optimization.
    *   Ancillary performance metrics like turnover and beta prediction, since they are important in trading applications.
2.  Two principled metrics for volatility estimation are QLIKE and MSE.
3.  They can be extended to the multivariate case, allowing for comparison of models across production strategies (best-case, worst-case, etc.) focusing on realistic portfolio scenarios.
4.  For precision matrix accuracy, we use Minimum Variance Portfolios: construct portfolios satisfying a linear constraint. A lower realized variance indicates a better model.
5.  Another metric is the Mahalanobis distance test. It’s portfolio-independent.
6.  Ancillary metrics are as follows:
    *   Turnover: Considers the frequency of model updates and potential transaction costs, with measures such as FMP turnover.
    *   Beta Accuracy: Compares predicted versus realized betas for portfolios (e.g., thematic, factor-mimicking) to ensure thematic, factor-mimicking to ensure consistency.
7.  We caution against the use of $R^2$ for factor model evaluation as it can be manipulated and may not reflect true predictive performance.

**Notes**

1.  [1] The Bias statistic is defined as $T^{-1} \sum_{t=1}^T (\hat{\sigma}_{it}^2 - r_{it}^2)$. See Connor et al. (2010).
2.  [2] A note of caution regarding the computation of QDIST in Equation (5.2): a numerically stable way to compute $\log |\mathbf{A}|$ is to compute the SVD of the argument and exploit the fact that
    $$ |\mathbf{A}| = |U S V^T| = |S| $$
    , so
    $$ \log |\mathbf{A}| = \log |S| = \sum_i \log s_i $$
3.  [3] To prove this, note that the vector $\mathbf{z}$ can be generated by $\mathbf{r} = \Omega^{1/2} \mathbf{z}$, where $\mathbf{z} \sim N(0, I_N)$. Therefore,
    $$ \mathbf{r}' \Omega^{-1} \mathbf{r} \sim \mathbf{z}' \Omega^{-1/2} \Omega \Omega^{-1/2} \mathbf{z} = \mathbf{z}'\mathbf{z} \sim \chi_N^2 $$
4.  [4] I should note that some researchers do model time variation of execution costs by including trading volume. But these approaches are out of the scope of this book.
5.  [5] We ignore corrections of $R^2$ for the “degrees of freedom” and alternative measures of quality of fit, like Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) (e.g., Hastie et al. (2008)), since these corrections pertain to in-sample fit.
6.  [6] For a more critical perspective on $R^2$ used as a metric for time-series model, see Lewellen et al. (2010).

```

Okay, here is the Markdown compilation for Chapter 6.
     Everand

**Chapter 6**
**Fundamental Factor Models**

**The Questions**

1.  What are the steps involved in the estimation of a fundamental factor model?
2.  How do we handle heteroskedastic returns?
3.  Can we estimate a model when we have “redundant” characteristics of the securities in the loadings matrix?
4.  What should we be careful about when estimating the factor covariance matrix?
5.  Can we make the model more responsive to sudden changes in volatility?
6.  How do we estimate off-diagonal terms in the idiosyncratic covariance matrix?
7.  How do we link different factor models into a coherent one?
8.  How do we model currencies in the model, and how do we change the reference currency?

Fundamental (or characteristic-based) factor models estimate Equation (4.1) using as inputs $\mathbf{R}_t$ and $\mathbf{B}_t$. The outputs of the models are estimates of factor and idiosyncratic returns $\hat{\mathbf{f}}_t, \hat{\mathbf{\epsilon}}_t$, as well as their covariance matrices $\hat{\Omega}_f, \hat{\Omega}_\epsilon$. Fundamental factor models are perhaps the most popular ones among practitioners. Reasons for their popularity are:

*   Good Performance. Commercial models are the outcome of a long process of refinement. The first models date back to the mid-1970s. Consequently, some important factors have been identified.
*   Interpretability. Firm characteristics provide a summary description of individual assets, and exposures based on these characteristics give a measure of systematic risk.
*   Connections to Academic Research. In the asset pricing literature, multifactor models originate with the Arbitrage Pricing Theory of Ross (1976). In fact, the reference model used by academic researchers to explain pricing anomalies is the three-factor model by Fama and French (1993).
*   Alpha Research. Fundamental models are the workhorse of alpha research, because they allow the portfolio manager to incorporate almost any data source, to analyze very large datasets, to interpret the results of their analysis, and to link the outcome to a portfolio construction system.

---

**6.1 The Inputs and the Process**

There are two major steps needed to identify a factor model. Some of them require involved quantitative methods; others are more art than science. Before we even begin to describe the steps, we should focus on the inputs.

**6.1.1 The Inputs**

Fundamental model inputs are:
1.  A set of returns per asset/date, i.e., the $\mathbf{R}_t$ part.
2.  A set of raw characteristics per asset/date/characteristic identifier. Asset characteristics are generally denoted by $\mathbf{B}_t$.

Asset returns are usually computed over intervals of equal duration. These intervals determine the periodicity of the model. Daily returns may be based on close-to-close prices. Intraday returns may be based on the last transaction price at intervals that divide the trading day. The interval can range from 30 minutes to sub-second intervals. It should make sense to use returns over the shortest interval, but this is not the case. The answer to the question “what is the final price at a time period?” is not easy or unique. Ultimately, models of returns should help the portfolio manager develop a profitable real-life strategy. If prices are such that we cannot trade on them, or if transaction costs at the trading horizon are too high, then the model will not be useful, no matter how well it fits the data on paper. Consider the closing price. Where does it come from? In many stock exchanges, at the end of the day the limit-order book (LOB) is replaced by a closing auction (CA). Without delving into the details of a CA, it suffices to know that a CA is a very different beast from a LOB. If the model is based on daily returns, and the final price is the closing auction price, it is meaningful, in the sense that it is exploitable by a portfolio manager, at a non-negligible size. Now, compare this scenario to one in which we are interested in modeling a small-cap stock that trades very little. In the extreme case, such a stock would not trade at all for long stretches of time. If it is a member of the estimation universe, then the model will use its zero returns at any volume. In addition, if we model intraday returns, then we must exercise additional care. What does it mean that the price at the end of a 5-minute interval was $6.35 per share? Maybe the stock did not even transact in that interval, and the price was stale. Or maybe it transacted once, but only a handful of shares changed hands. The transaction price was $6.35$. Maybe there were many transactions, but the transaction happened at the ask, but the transaction just before happened at the bid. Or should we use the mid-price between the bid and the ask? Could our strategy actually trade at either of these prices in real life? These are just some of the many questions that arise when dealing with high-frequency return data. Daily returns, but not only for many asset classes, determining good daily closing prices is a very challenging, important and thankless task. The details are

(Right Sidebar from Page 212)
two asset- and data-vendor-specific to be covered in detail; moreover, this is an area where biases accumulate. The first impurity is that any material to their business. A fix is needed. The second one is that the data are noisy. The third one is that the problem is how to solve this already in Section 2.1.4. The fourth one is that the model what price is appropriate (bid, ask, mid); whether to explicitly model the noise in price observations; whether time-of-day non-stationarity matters; whether to model transaction costs explicitly; whether to model market impact. The fifth one is that returns are usually non-stationary. The sixth one is that to avoid looking-ahead bias, we need to use returns that are available at time $t-1$ and model in a period $t$. Liquidity. For our purposes, we could be pressed by trading volume in a period. Usually, average daily trading volume is available. Liquidity is related to price discovery. The price of a very liquid stock is less prone to manipulation, and it is more likely to reflect the true value of the asset. There are choices a modeler makes. Several choices of model inputs are related. Unless you want to model market microstructure explicitly, and want to rely on closing period prices, then a shorter period will imply that your model universe will be smaller.

Raw characteristics data. This is the “art”, or better, the “dark art” part of the modeling task. “Raw data” can mean almost anything. A possible classification of raw data is structured versus unstructured. The former includes numerical data and categorical data that can be converted to a numerical factor or an estimation period. Categorical data take only a finite set of values, which do not necessarily have an ordering relationship. Examples are the country and sector of a stock. A slightly less common example is the credit rating of a company, which does admit an ordering. The latter includes textual data, such as news or social media, and tabular form. Examples are the earnings transcripts of a company, or its regulatory filings (Forms 10-K or 10-Q), or its web search, or a web scraping of a firm with information about its products, or the consumer credit card transactions of a firm; a list could go on and on. Some of these data are more useful than others for modeling purposes, some are just a ruse of the vendor, or of the modeler. For asset return modeling purposes, we extract from these vast troves of alternative data some representative statistics that can be interpreted as structured data. For example, from transaction data, we can extract flows (dollars transacted in a stock); from textual data, we can extract sentiment (positive, negative, or neutral change at the company level); or we can extract measures of geographical dispersion. Some of these operations can be automated; some may require the use of machine learning tasks like classification and clustering. One important feature of all these operations, though, is that they should result in data that are comparable across assets and that admit a natural interpretation of security returns as returns in excess of a rate received in the absence of investing. In the United States, this requires the highest amount of human intelligence. A great number of papers have been published on characteristic data. Maybe in the future we will be able to feed such disparate sources of information into a black box and directly produce portfolio return recommendations. In that event, I’ll gladly write a second edition to this book.

---

**6.1.2 The Process**

The estimation steps of a characteristic model are:
1.  Data ingestion. This step encompasses receiving datasets from vendors, checking their integrity, and performing essential data checks. These include:
    *   Ensure that data are of the correct type and not corrupt. This happens with positive probability.
    *   Ensure that the set of securities is not substantially different from the previous period.
    *   Ensure that the fraction of missing data per asset and characteristic is not substantially different.
    *   Identify and report data outliers.
2.  Estimation universe selection. I introduced issues related to this set earlier in this chapter. The main criteria are:
    *   Tradability. The assets must be sufficiently liquid, because FMPs include them all.
    *   Data quality. This is closely related to the liquidity of the assets, but for a different reason. We need securities for which price discovery is good, i.e., assets that have a high informational value, since we are using their prices for return calculations and model estimation.
    *   Relevance to investments. The estimation universe should be overlapping to some extent with the investment universe of the strategy. This is a judgment call. There is not to my knowledge a rigorous treatment of this problem.
3.  Winsorization. Identify outliers in returns of the estimation universe and winsorize them.
4.  Loadings generation. Generate characteristics $\mathbf{B}_t$ by transforming and combining raw data.
5.  Cross-sectional regression. For each $t=0, \dots, T$, perform a cross-sectional regression of asset returns $\mathbf{R}_t$ against the loadings $\mathbf{B}_t$. The outputs of this step are the estimates $\hat{\mathbf{f}}_t$ and $\hat{\mathbf{\epsilon}}_t$. Furthermore, from these, using the time series from the previous steps estimate:
    *   the factor covariance matrix $\hat{\Omega}_{f,t}$
    *   the idiosyncratic covariance matrix $\hat{\Omega}_{\epsilon,t}$
    *   the risk-adjusted performance of factor returns.

The next three sections address specific aspects of model inputs, regression, and covariance estimation. We then consider estimation in Section 6.5. The next section presents an advanced topic on linking multiple factor models coherently, and also considers portfolio assets denominated in multiple currencies. Finally, we offer a preliminary description of identifying the factor characteristics.

---

**6.2 Cross-Sectional Regression**

The first step is cross-sectional regression.
(6.1)
$$ \mathbf{r}_t = \mathbf{B}_t \mathbf{f}_t + \mathbf{\epsilon}_t, \quad t \in N $$
where the parameters to be estimated are $\mathbf{f}_t$ and $\mathbf{\epsilon}_t$. This is a case of random design: the tuple $(\mathbf{R}_t, \mathbf{B}_t, \mathbf{f}_t, \mathbf{\epsilon}_t)$ can be viewed as independent samples drawn from a common distribution. We observe $(\mathbf{R}_t, \mathbf{B}_t)$.
Several regression approaches are possible. One may minimize the square loss function $\| \mathbf{R}_t - \mathbf{B}_t \mathbf{f}_t \|^2$. The assumptions behind this step are:
1.  The matrix $\mathbf{B}_t \in \mathbb{R}^{N \times K}$ has full rank. A necessary but not sufficient condition for this is that $m \le N$.
2.  Residual returns $\mathbf{\epsilon}_t$ have zero mean, are homoskedastic (i.e., $\text{Var}(\epsilon_{it}) = \sigma_\epsilon^2$), and are uncorrelated, and independent of each other.
3.  Factor returns residual returns are independent of each other.
4.  Factor and residual returns are “well-behaved”, in the sense of having at least finite fourth moments.
These assumptions can be relaxed in various ways. The matrix $\mathbf{B}_t$ is often rank-deficient. Later in this section we will introduce ways to deal with rank-deficient matrices. In order to have a unique solution. Homoskedasticity is also not a necessary assumption. If residuals have different variances for different assets, we can weight the observations by the inverse of their variance. Heteroskedasticity is a fact of life. In all of these cases, we use weighted least squares, so that the single term does not dominate the sum of losses, and unduly affect the parameters’ estimation.
We estimate Model (6.1) by minimizing the sum of a loss function $L: \mathbb{R}^N \times \mathbb{R}^N \to \mathbb{R}^+$:
$$ \min_{\mathbf{f}_t} L(\mathbf{R}_t, \mathbf{B}_t \mathbf{f}_t) $$
In this section, we choose to minimize the weighted sum of the squared residuals. We know a diagonal, positive matrix $\mathbf{W}$ whose diagonal terms can be interpreted as weights assigned to observation (i.e., asset) $j$. We then find $\mathbf{f}_t$ that minimizes
(6.2)
$$ L(\mathbf{R}_t, \mathbf{B}_t \mathbf{f}_t) = (\mathbf{R}_t - \mathbf{B}_t \mathbf{f}_t)^T \mathbf{W} (\mathbf{R}_t - \mathbf{B}_t \mathbf{f}_t) $$
There are good reasons for this choice. If we assume that Model (6.1) is the true model, then least squares gives us the lowest-variance unbiased estimate among all the linear models (Pearson, 2022). The lack of bias matters for performance attribution and alpha identification. Even a small bias in factor return estimation (and, consequently, in residual returns) would accumulate over the course of a year. The low variance of the estimate matters for risk estimation. The additional benefit of weighted least squares regression is that its estimates have a natural interpretation in terms of Factor-Mimicking Portfolios (FMPs). We will cover these in detail later. For now, it should suffice to say that FMPs are investable portfolios whose returns track as well as possible the true (but unobserved) factor returns. Our estimation procedure is to use this set as a starting point, and to run through diagnostics to identify its possible shortcomings. To do so, we make the assumption that the model is $\mathbf{R}_t = \mathbf{B}_t \mathbf{f}_t + \mathbf{\epsilon}_t$, with $\mathbf{\epsilon}_t \sim N(0, \Omega_\epsilon)$. We are addressing the problem of estimating $\mathbf{f}_t$ by minimizing both sides of (6.2). Now assume that the idiosyncratic covariance matrix is diagonal, $\Omega_\epsilon = \text{diag}(\sigma_{\epsilon,1}^2, \dots, \sigma_{\epsilon,N}^2)$. We use the Ordinary Least Squares (OLS) loss function (i.e., $\mathbf{W} = \mathbf{I}_N$ in (6.2)), which is equivalent to the loss function in Equation (6.1) with a weight matrix $\mathbf{W} = \Omega_\epsilon^{-1}$.
Factor loadings are assumed to be constant over time. This simplifies the formulas below, but can be relaxed by simply regressing the returns on the time-varying loadings.
Given $\mathbf{B}_t, \Omega_\epsilon$, the Gaussian likelihood is given by
$$ L = \prod_{t=1}^T (2\pi)^{-N/2} |\Omega_\epsilon|^{-1/2} \exp \left( -\frac{1}{2} (\mathbf{R}_t - \mathbf{B}_t \mathbf{f}_t)^T \Omega_\epsilon^{-1} (\mathbf{R}_t - \mathbf{B}_t \mathbf{f}_t) \right) $$
If we denote the matrix of returns $\mathbf{R} \in \mathbb{R}^{N \times T}$ and $\mathbf{F} \in \mathbb{R}^{K \times T}$, the log-likelihood is equivalent to $-\frac{NT}{2} \log(2\pi) - \frac{T}{2} \log |\Omega_\epsilon| - \frac{1}{2} \sum_{t=1}^T (\mathbf{R}_t - \mathbf{B}_t \mathbf{f}_t)^T \Omega_\epsilon^{-1} (\mathbf{R}_t - \mathbf{B}_t \mathbf{f}_t)$. We write the optimization problem as
$$ \min_{\mathbf{F}} \frac{1}{2} \| \Omega_\epsilon^{-1/2} (\mathbf{R} - \mathbf{B}\mathbf{F}) \|_F^2 $$
$$ \text{s.t. } \mathbf{F} \in \mathbb{R}^{K \times T} $$
We consider first the case of a single period. In this case $\mathbf{R}$ and $\mathbf{F}$ are column vectors. The solution is formally given by
$$ \hat{\mathbf{f}}_t = (\mathbf{B}_t^T \Omega_\epsilon^{-1} \mathbf{B}_t)^{-1} \mathbf{B}_t^T \Omega_\epsilon^{-1} \mathbf{R}_t $$
In the case of multiple periods, the problem is the sum of the single-period problems.
$$ \mathbf{R} - \mathbf{B}\mathbf{F} = \sum_{t=1}^T (\mathbf{R}_t - \mathbf{B}_t \mathbf{f}_t)^T \Omega_\epsilon^{-1} (\mathbf{R}_t - \mathbf{B}_t \mathbf{f}_t) $$
Each term can be minimized independently. Hence, we have
(6.3)
$$ \hat{\mathbf{f}}_t = (\mathbf{B}_t^T \Omega_\epsilon^{-1} \mathbf{B}_t)^{-1} \mathbf{B}_t^T \Omega_\epsilon^{-1} \mathbf{R}_t $$
As a direct extension of the previous formula in matrix form, the problem of minimizing $\| \mathbf{A} - \mathbf{B}\mathbf{X} \|_F^2$ has a closed-form solution:
(6.4)
$$ \arg \min_{\mathbf{X}} \| \mathbf{A} - \mathbf{B}\mathbf{X} \|_F^2 = (\mathbf{B}^T \mathbf{B})^{-1} \mathbf{B}^T \mathbf{A} $$

**Insight 6.1: Which idiosyncratic covariance matrix?**
In the cross-sectional regression procedure, we have taken as an input the covariance matrix $\Omega_\epsilon$. However, this matrix is an output of the factor estimation procedure. How to resolve this circularity? One possibility is to use the identity matrix as a proxy for the true idiosyncratic covariance matrix. This proxy won’t be the best possible covariance matrix, but it is better than the identity matrix, which corresponds to OLS. The first, and simplest one, is to take advantage of a previous estimation of the covariance matrix, say from BARRA or Axioma. A second approach is to perform a two-stage process. In the first stage, we use the identity matrix as a proxy in the cross-sectional regression, and estimate the idiosyncratic covariance matrix, as explained in Section 6.4. In the second stage, we use this estimate in the weighted estimation process, starting with the cross-sectional regression, and ending with a final idiosyncratic covariance matrix. Finally, there is a variant on this second approach. We can use the identity matrix in the first stage, and average returns only for a number of periods. In the following example, we have 20 years of history, we could perform the two-stage process in the first year only. For every day after the first year, we can use as proxy the final estimate of the idiosyncratic covariance matrix estimated for the previous day.

**6.2.1 Rank-Deficient Loadings Matrices**

In some cases the loadings matrix is rank-deficient: even if there are $K$ factors, the number of independent columns is $m < K$. As concrete (and very common) examples, consider the following:
1.  There is a factor with loadings for each asset equal to 1. This is sometimes called a “country,” “region,” or “universe” factor, since all assets are identically affected by changes in this factor. The interpretation is that this factor is a “market” factor. In this case, the regression matrix $\mathbf{B}_t$ has at least one linear dependency: the sum of the last $m$ columns is equal to the first column, which can be interpreted as non-negative weights summing to one, for simplicity, assume that the first factor is the country, and the next $m-1$ are industries. Then the vector
    $$ \mathbf{v} = (1, -1, \dots, -1)^T $$
    is such that $\mathbf{Bv} = \mathbf{0}$. The matrix is rank-deficient.
2.  In most multi-country models there are industry as well as country factors. Say that $N_{ind}$ and $N_{cty}$ are industry loadings, followed by $N_{cty}$ country loadings. Then the vector
    $$ \mathbf{v} = (1, 1, \dots, 1, -1, -1, \dots, -1)^T $$
    where the first $N_{ind}$ ones are ones and the remaining $N_{cty}$ are negative ones, also satisfies $\mathbf{Bv} = \mathbf{0}$.
We generalize this to the case where there are $m-p$ independent vectors $\mathbf{v}_k$ such that $\mathbf{Bv}_k = \mathbf{0}$. Because of this, $(\mathbf{B}^T \Omega_\epsilon^{-1} \mathbf{B})$ is not invertible and it is not possible to estimate $\mathbf{f}$ using Equation (6.3). There are at least three ways to address such an issue:
1.  The first is to remove the redundancy. For example, remove the country factor and/or $p$ industry or country factors from the regression. The drawback is that the original loadings matrix is easier to interpret. We would like to know a portfolio exposure to the country and to all industries. The second drawback is that, if the industries’ exposures are positive, which is often true, it implies that the industries’ exposures are small. And, of course, all industries are useful. Just ask the portfolio manager whose main covered industry was removed from the model.
2.  The second is to add a small quadratic penalty term to Equation (6.2). The term is $(\mathbf{f}^T \mathbf{D} \mathbf{f})$, where $\mathbf{D}$ is a diagonal matrix of positive constants. The factor estimates are no longer unbiased (or the linear model), so a careful analysis would be needed before using this method. In the limit $\delta \to 0$, the solution to the regression problem is the ridge regression
    $$ \hat{\mathbf{f}} = (\mathbf{B}^T \Omega_\epsilon^{-1} \mathbf{B} + \delta \mathbf{I}_K)^{-1} \mathbf{B}^T \Omega_\epsilon^{-1} \mathbf{R} $$
    , where $^+$ denotes the Moore-Penrose pseudo-inverse operator. Finally, we can add $m-p$ side constraints of the form $\mathbf{C}^T \mathbf{f} = \mathbf{c}$. An example is that the sum of industry factor returns is zero. Our regression problem then finds some person complexity to the estimation process, but maintains or even enhances the interpretability of factor returns. For example, we may require that the market-weighted sum of industry factor returns be zero. This would mean that $\mathbf{w}_{mkt}^T \mathbf{B}_{ind} \mathbf{f}_{ind} = 0$, where $\mathbf{B}_{ind}$ is the submatrix of industry factor returns, and $\mathbf{w}_{mkt}$ is a weight vector of asset market caps per asset. The constraint says “the sum across assets of market-weighted industry returns must be zero.” If $\mathbf{w}$ are chosen to be the weight of a benchmark portfolio, this may read as “the benchmark portfolio must have no industry returns.”

---

**6.3 Estimating the Factor Covariance Matrix**

We have a random vector of factor returns $\hat{\mathbf{f}}_t$ from which we want to estimate $\Omega_f$. We assume that the $\hat{\mathbf{f}}_t$ has zero fourth moments, but unlike in Section 2.2.4, we cannot assume $\hat{\Omega}_f = \mathbf{I}_K$. By construction, we do not expect the matrix to be spiked. The number of samples over which we estimate the covariance matrix can be larger than the number of factors. For example, we could estimate a model with 10 factors and 300 days of estimation. The assumption that its estimate is $\hat{\Omega}_f = \frac{1}{T} \sum_{t=1}^T \hat{\mathbf{f}}_t \hat{\mathbf{f}}_t^T$.
Let
$$ \hat{\Omega}_f = \frac{1}{T} \sum_{t=1}^T \hat{\mathbf{f}}_t \hat{\mathbf{f}}_t^T $$
By the Law of Large Numbers, $\hat{\Omega}_f \to \Omega_f$ almost surely. Both eigenvalues and eigenvectors converge to the true population values. See the Appendix, Section 7.6.2. Factor volatilities converge to the true (aka denoted population) volatilities, and the principal components of the factor covariance matrix converge to their population counterparts, so long as the volatilities of factors are all sufficiently separated. This seems to settle the issue of covariance estimation: just take the empirical covariance matrix. There are several problems, though:
*   Oftentimes, the number of factors is not much smaller than the number of observations. In this case, shrinking may improve the quality of the estimate.
*   We will see that factor return estimates are influenced by the estimation process. This is another argument in favor of shrinkage.
*   Factor returns are non-stationary, sometimes dramatically so at the onset of a crisis. We need to take this into account.
*   Factor returns are serially autocorrelated. This is not correct.

**6.3.1 Factor Covariance Matrix Shrinkage**

The first issue is that the factor return estimates $\hat{\mathbf{f}}_t$ are just that: estimates. They are the outcome of WLS linear regression estimates, Equation (6.3). The covariance matrix of the estimates $\hat{\mathbf{f}}_t = (\mathbf{B}_t^T \Omega_{\epsilon,t}^{-1} \mathbf{B}_t)^{-1} \mathbf{B}_t^T \Omega_{\epsilon,t}^{-1} \mathbf{r}_t$. This implies that the covariance matrix of the estimates $\hat{\mathbf{f}}_t$ is biased.
(6.5)
$$ \text{var}(\hat{\mathbf{f}}_t) = \Omega_f + (\mathbf{B}_t^T \Omega_{\epsilon,t}^{-1} \mathbf{B}_t)^{-1} $$
Insight 6.2: FMP, interpretation of factor covariance shrinkage
An alternative lens to interpret Equation (6.5) is via factor-mimicking portfolios. The return of FMP $\mathbf{w}_k$ is $\mathbf{w}_k^T \mathbf{r}_t = \mathbf{e}_k^T (\mathbf{B}_t^T \Omega_{\epsilon,t}^{-1} \mathbf{B}_t)^{-1} \mathbf{B}_t^T \Omega_{\epsilon,t}^{-1} \mathbf{r}_t = \hat{f}_{k,t}$. The estimated covariance of the returns of FMP is $\text{cov}(\hat{\mathbf{f}}_k, \hat{\mathbf{f}}_j) = (\mathbf{B}_t^T \Omega_{\epsilon,t}^{-1} \mathbf{B}_t)_{k,j}^{-1}$. This suggests that we should shrink the empirical covariance matrix in order to obtain an unbiased estimate.
(6.6)
$$ \hat{\Omega}_f^u = \hat{\Omega}_f - (\mathbf{B}_t^T \Omega_{\epsilon,t}^{-1} \mathbf{B}_t)^{-1} $$
How big is the correction? In the simpler but instructive case where $\mathbf{B}_t^T \Omega_{\epsilon,t}^{-1} \mathbf{B}_t = \mathbf{I}_K$, i.e., the estimated factor returns $\hat{\mathbf{f}}_t = \mathbf{B}_t^T \mathbf{r}_t$,
$$ \text{var}(\hat{\mathbf{f}}_t) = T^{-1} \sum_{t=1}^T \hat{\mathbf{f}}_t \hat{\mathbf{f}}_t^T = \Omega_f + \mathbf{I}_K $$
, and therefore
(6.7)
$$ \hat{\Omega}_f^u = \hat{\Omega}_f - \mathbf{I}_K $$
In applications the number of observations ranges from 250 to 1000 days and the number of factors ranges from 10 to 50. The number of assets is in the order of 5000 and 30 years of daily returns. Therefore we are not always in the regime $N \ll T$ and the asymptotics of Section 7.6.2 do not apply, neither the results for spiked covariance matrices. A popular shrinkage applied to the covariance matrix is Ledoit-Wolf shrinkage (Ledoit and Wolf, 2003a,b, 2004). It has the advantage of being simple, robust, and having good performance. The shrunken covariance matrix is
$$ \Omega_{f,shrink}(\rho) = (1-\rho) \hat{\Omega}_f + \rho \frac{\text{trace}(\hat{\Omega}_f)}{m} \mathbf{I}_m $$
which we combine with Equation (6.7):
$$ \Omega_{f,shrink}(\rho) = (1-\rho)[\text{var}(\hat{\mathbf{f}}_t) - (\mathbf{B}_t^T \Omega_{\epsilon,t}^{-1} \mathbf{B}_t)^{-1}] $$
$$ + \rho \frac{\text{trace}(\text{var}(\hat{\mathbf{f}}_t) - (\mathbf{B}_t^T \Omega_{\epsilon,t}^{-1} \mathbf{B}_t)^{-1})}{m} \mathbf{I}_m $$
where $\rho \in (0,1)$ is a tunable parameter.

---

**6.3.2 Dynamic: Conditional Correlation**

An alternative approach to estimating the empirical covariance matrix in Equation (6.5) is to model the factor volatilities and correlations separately. Normally, we decompose the population covariance matrix into the product of a correlation matrix $\mathbf{C}$ and a diagonal matrix $\mathbf{V}$ containing the factor volatilities:
$$ \Omega_f = \mathbf{V} \mathbf{C} \mathbf{V} $$
Bollerslev (1990) modeled the time-varying correlation and the correlation matrix as constant. Practitioners estimate the empirical correlation matrix and the volatility vector using exponentially weighted averages with different half-lives:
$$ \text{diag}(\mathbf{V}_t) = T_V^{-1} \sum_{s=0}^{T_V-1} K_V e^{-s/T_V} \hat{\mathbf{f}}_{t-s} \odot \hat{\mathbf{f}}_{t-s} $$
$$ \mathbf{C}_t = K_C^{-1} \sum_{s=0}^{T_C-1} K_C e^{-s/T_C} \hat{\mathbf{f}}_{t-s}^* (\hat{\mathbf{f}}_{t-s}^*)^T $$
where $T_V < T_C$ are half-lives for factor correlations and factor variances, respectively, and $K_V, K_C$ are normalizing constants. In many equity models estimated using daily returns, the half-lives are set between three months (for variances) to one or two years.

**6.3.3 Short-Term Volatility Updating**

Estimated factor returns often exhibit large, unanticipated volatilities. Anecdotally, their volatility does not vary smoothly but discontinuously, with regimes of high volatility followed by a quick transition to low-volatility regimes. This poses two challenges. First, the standard EWMA model for volatilities in Equation (6.8) will react too slowly to the sudden increases in volatility. The carryover effect of this is that the investors will severely underestimate systematic risk at the time when they need accurate estimates the most. Second, the estimates react too slowly to subsequent volatility declines. By the nature of the weights, previous volatilities decay too slowly than warranted, resulting in an overestimation of risk. Several approaches have been proposed to address this issue. We mention one that performs well and is simple: Short-Term Volatility Updating (STVU). First, we model the multivariate factor returns so that they are modulated by a latent state variable $z_t$:
(6.8)
$$ \hat{\mathbf{f}}_t = z_t^{1/2} \mathbf{C}_t^{1/2} \mathbf{\eta}_t $$
$$ \mathbf{\eta}_t \sim N(0, \mathbf{I}_m) $$
$$ z_{t+1} = \phi z_t + \sigma_z \epsilon_t $$
In the degenerate case where $\sigma_z=0$, i.e., $z_t$ is all 1, the model reduces to one where the factor covariance matrix is $\Omega_f = C_t$.
Define $e_t := \log |\mathbf{u}_t|^2 - \log \|\mathbf{\eta}_t\|^2$.
This is a linear state-space model. Define
$$ \kappa = E(\log \|\mathbf{\eta}_t\|^2) $$
$$ \epsilon_t := \log |\mathbf{u}_t|^2 - \kappa $$
$$ x_t := \log z_t $$
$$ y_t := \log |\mathbf{u}_t|^2 - \kappa $$
The state-space equation is
$$ x_{t+1} = \phi x_t + \sigma_z \epsilon_t $$
and the estimate of the state takes the form,[7]
$$ \hat{x}_{t+1|t} = (1-e^{-1/T_V}) \sum_{s=0}^{T_V-1} e^{-s/T_V} (\log |\mathbf{u}_{t-s}|^2 - \kappa) $$
From the first equation in Model (6.8), the factor covariance matrix is then adjusted by multiplying by $e^{\hat{x}_{t+1|t}}$. At the time when they need accurate estimates the most.
Some implementations use the linear approximation of this formula and the approximate equality
$$ \kappa = \log(m) + E(\log \|\mathbf{\eta}_t\|^2/m) \approx \log m $$
since $E(\log \|\mathbf{\eta}_t\|^2/m) \approx 0$ as $m \to \infty$.
(6.9)
$$ e^{\hat{x}_{t+1|t}/2} \approx \exp \left( (1-e^{-1/T_V}) \sum_{s=0}^{T_V-1} e^{-s/T_V} \frac{|\mathbf{u}_{t-s}|^2 - m}{m} \right) $$
The interpretation of the formula is clearer in the special case of uncorrelated factor returns. In this case, $m=1$. If we view the random variable $u_t$ as $N$ iid samples of a random variable, the term $|\mathbf{u}_t|^2/m$ gives us an estimate of its standard deviation, and if this estimate exceeds one, then our original estimate for the standard deviation of the $f_t$ needs to be scaled upward. That is what the model does. The half-life is typically chosen to be ten days for daily risk models, in order to incorporate the rapid onset of a shock.

**6.3.4 Correcting for Autocorrelation in Factor Returns**

Daily factor and asset returns usually exhibit mild, but non-zero, short-term autocorrelation. When the factor covariance matrix is estimated on shorter time intervals, the autocorrelation may be more pronounced. In these cases, correcting for autocorrelation may improve the model performance, at a cost. We build on previous work by Scholes and Williams (1977) and assume that the observed returns follow an autoregressive process of order $L_{max}$ that is a function of underlying uncorrelated returns. The coefficients in the AR($L_{max}$) equation are random, but sum to 1. Let the lagged covariance matrix $C_j$ be defined as
$$ [C_j]_{k,l} := \text{cov}(\hat{f}_{k,t}, \hat{f}_{l, t-j}) $$
Then the autocorrelation consistent estimator is given by
$$ \hat{\Omega}_f^c = C_0 + \sum_{j=1}^{L_{max}} (C_j + C_j^T) $$
An alternative approach, which is asymptotically consistent in the limit $T \to \infty$, is Newey and West’s estimator (Newey and West, 1987).

---

**6.4 Estimating the Idiosyncratic Covariance Matrix**

Next, we need to estimate the covariance matrix $\Omega_\epsilon$, based on the period estimated idiosyncratic returns $\hat{\mathbf{\epsilon}}_t$.

**6.4.1 Exponential Weighting**

As in the case of factor volatility, we use exponential weighting for idiosyncratic volatility estimation. Let $\hat{\sigma}_{\epsilon, it}^2 = E[\hat{\epsilon}_{it}^2]$ be the mean of estimated idiosyncratic returns for asset $i$ at time $t$. The weighting matrix is a diagonal positive-definite matrix $\mathbf{W}_t$. A common choice for the diagonal terms is $\mathbf{W}_{t,t} = \kappa \exp(-t/\tau)$.
; the positive constant $\kappa$ is such that the diagonal terms sum to $T$. The EWMA empirical idiosyncratic covariance matrix is then $\hat{\Omega}_\epsilon = \text{EWE}_t^T$.

**6.4.2 Visual Inspection**

This matrix should be diagonal, or at least sparse. The sample covariance matrix based on estimated idiosyncratic returns does not satisfy these requirements. The sample covariance matrix $\hat{\Omega}_\epsilon = \frac{1}{T} \sum_{t=1}^T \hat{\mathbf{\epsilon}}_t \hat{\mathbf{\epsilon}}_t^T$ is not sparse (unless $N \ll T$). One possibility could be all the off-diagonal terms to zero, thus effectively amounts to a radical shrinkage of the idiosyncratic correlations. This step, however, is not warranted. As a sanity check, we recommend performing a visual inspection of the idiosyncratic covariance matrix. Oftentimes, there are strong patterns that can be interpreted as factors. For example, there are blocks of stocks that are highly correlated (e.g., some Chinese securities are listed in both Mainland China and in Hong Kong (H shares)). These securities have highly correlated but not identical returns, and the correlations will show up in the idiosyncratic covariance matrix. In such a case, rather than assuming that $\hat{\Omega}_\epsilon$ is sparse, it is more appropriate to add a “local factor” to the model.

**6.4.3 Short-Term Idio Update**

Idiosyncratic returns, like factor returns, are subject to sudden changes in volatility that are not captured well by exponential weighting with long half-lives $T$.
A very responsive daily return model has $T \approx 126$ trading days, and the shocks may occur over 10 trading days. As a remedy, we reuse the STVU mechanism of Section 6.3.3. We estimate the idiosyncratic volatilities using the same formula, although the technique is applicable to other asset classes. Stocks are likely to receive large shocks in proximity of earnings, either because new information is released before or on earnings date, or because such information becomes fully priced in the following days. We use a two-tier horizon during which earnings information is received. Define the function as
$$ s_{i,t} = \begin{cases} 1 - |t-T_{earn,i}|/\tau_{earn} & \text{if } |t-T_{earn,i}| \le \tau_{earn} \\ 0 & \text{otherwise} \end{cases} $$
$s_{i,t}$ ranges from zero to one, when $t$ is within $T_{earn}$ number of days from the earnings date $T_{earn,i}$ (see Model 6.8), but restricting ourselves to positive values. We then modify the correction term in the STVU mechanism. Instead of the simple fact that the correlation matrix is approximately diagonal. We restrict our attention to the linear approximation; the corrective term is
$$ \hat{\sigma}_{\epsilon,it}^{2,c} = \hat{\sigma}_{\epsilon,it}^2 \exp \left( \sum_{k=0}^{K_0-1} w_k \frac{\sum_{j \in S_k} \alpha_{i,j} (\hat{\epsilon}_{i, t-j}^2 - \hat{\sigma}_{\epsilon, i, t-j}^2)}{\sum_{j \in S_k} \alpha_{i,j} \hat{\sigma}_{\epsilon, i, t-j}^2} \right) $$
and applies only to the assets affected by earnings.
$$ \hat{\sigma}_{\epsilon,it}^{2,c} \leftarrow [1 - \alpha_{i,t} (1-e^{-1/\tau})] \hat{\sigma}_{\epsilon,it}^2 $$

**6.4.4 Off-Diagonal Clustering**

Finally, we need to identify those assets whose idiosyncratic returns are highly correlated. Two instances are important. The first one is the case of different securities that refer to the same underlying asset. For example, some stocks are listed on different share classes, for example, Berkshire Hathaway trades under BRK.A and BRK.B, with different fractional values. The liquidity of the two securities may be different. The second one is when the correlation between securities in a factor model still depends on the nature of the trading strategy employing the model itself. If the strategy intends to exploit the temporary small mispricing between two assets, then we should include both assets. If instead we only intend to invest in the company based on fundamental information, then we should only include a security representative of the underlying asset, typically the one with the highest liquidity. The second one is when the correlation between stocks whose comovements are not described by factors. In order to be identifiable, factors must be pervasive. A factor influencing only a handful of assets is not a factor, and cannot be identified in a large cross-section of assets. The dependency among these stocks is still available in the correlation between their idiosyncratic returns. We can estimate these correlations. We can transform the correlation elements by applying a simple sparsifying operator.
The optimal threshold is $h_c = \rho_c \sqrt{K \log K / T}$ (Cai et al., 2011), for some positive constant $K$. In practice, however, it is more instructive to explore the clusters emerging for different values of the threshold $\lambda$. For some value of $\lambda$, the clusters are (a) stable, in the sense that they do not change much for perturbed values of $\lambda$, and (b) interpretable. They are composed of “similar” stocks, such as stocks in the same sector, or stocks with similar size and sometimes style factor loadings as well.[8] It is important to check that, for every level of the threshold, the correlation matrix is symmetric positive-definite (and well-conditioned). For example, we use the residual returns from a commercial factor model (Axioma US4 Short Horizon, 2015-06-08). We compute the equal-weighted correlations for consecutive constituents of the Russell 3000 index, and threshold their absolute values at 0.15. Figure 6.1 shows the resulting clusters. The number of stocks is small: less than 3% out of a total of nearly 3,000 stocks. The plot is quite sparse. The plot also includes Las Vegas Sands, Peabody Energy and Alpha Natural Resources, and a mining cluster composed of HL, NEM, CDE, PCLD.

[Image: Figure 6.1: Clusters for idiosyncratic matrix.]

**TABLE 6.1**
Ticker and company names of cluster components in Figure 6.1

| Ticker Name | Ticker Name |
| :---------- | :---------- |
| AAPL APPLE INC | GOOG ALPHABET INC CL C |
| ...         | ...         |

**6.4.5 Idiosyncratic Covariance Matrix Shrinkage**

Analogous to the factor covariance shrinkage of Section 6.3.1, we recommend shrinking the idiosyncratic variances toward the identity matrix.
$$ \Omega_{\epsilon,shrink}(\rho) = (1-\rho) \hat{\Omega}_\epsilon + \rho \frac{\text{trace}(\hat{\Omega}_\epsilon)}{m} \mathbf{I}_m $$
For a diagonal idiosyncratic covariance matrix, this is analogous to shrinking the idiosyncratic variances toward the empirical average of the variances.

---

**6.5 Winsorization of Returns**

The issue of outlier detection, if not central, is at least very important both for risk modeling and alpha research. There are many examples of outliers in return data, each one of them responsible for ruining the career of a finance researcher. Before proposing some remedial measures to improve the research process and save a few careers, let us discuss where they come from, and the impact that they may have. The sources are several and diverse. First, the data provider may have made a mistake. Secondly, the data are genuinely very large. This is the case of liquidity-driven volatility. Third, good researchers spend a large proportion of their time evaluating and comparing data and questioning providers on the data collection methodology and their applicability. The sources of error are many. In the worst case, prices are not comparable across assets or across time. In the best case, prices are not comparable across assets. In the best case, prices are not comparable across assets. In the best case, the ultimate source of the returns may be a broker located in a farming village in New Zealand, and even more unlikely instances. Bad providers are the perfect breeding ground for outliers. Second, authentic outliers do exist. Instances are:
*   There are rare stray transactions for a liquid stock.[9]
*   Very illiquid stocks exhibit higher volatility, and occasionally large returns.
*   Stocks in the process of being delisted, or entering/exiting bankruptcy, usually trading over-the-counter (OTC) also exhibit very large returns.
*   The most pervasive large jumps reflecting new information in the market, say in earnings and forward guidance, announcement of market entry by a competitor, merger announcements and news of merger break, accidents or hiring new and unforeseen liabilities, and macroeconomic drivers having a large impact on the security’s price.
Of these instances, the first one is related to improving price data collection, i.e., by not only taking the last bid price of a 5-minute interval, but also considering the entire price trace. The second and third can be avoided by choosing the estimation and investment universe carefully. Microcap stocks that are very illiquid should be excluded; the last class of outliers, however large they may be, should not be excluded from the analysis. Instead, the model should be made robust to them. Make the output of the analysis much less reliable. If winsorizing a large absolute return, we affect the estimated factor returns from the cross-sectional regression. A factor return is the return of its mimicking portfolio, and by winsorizing returns in the cross-sectional regression, we effectively cap the portfolio return from that period. The total portfolio return is inevitably capped based on historical returns. This affects the evaluation of the factor returns, as well as of the idiosyncratic returns. Two easy qualitative recommendations that follow from all of this are:
1.  Whatever winsorization method you use, make sure to report all the instances of winsorized data in backtest or in production, and examine them one by one.
2.  Make sure that your investment universe comprises only liquid, tradable assets.
For the winsorization process, use a robust outlier detection strategy. There is no ideal and completely justified method. A method that works well enough is to compute at the security level, the robust z-score of return:
$$ d_{it} = \frac{|\log(1+r_{it}) - \text{median}_s \log(1+r_{is})|}{\text{median}_s |\log(1+r_{is}) - \text{median}_k \log(1+r_{ik})|} $$
and to winsorize returns exceeding a threshold $d_{max}$. The threshold depends on asset class, region, and other attributes, and is set by trial-and-error between 5 and 10.

---

**6.6 Advanced Model Topics**

**6.6.1 Linking Models**

In some applications, you will have an investment universe consisting of securities belonging to different regions. For large hedge funds, for example, most of their assets are in North America, Europe, and Asia. Linking models allows the investment of securities belonging to different asset classes. An example is U.S. equity and corporate credit, but the possibilities are endless. Since the mathematical treatment that will follow is somewhat dry and arduous, it is perhaps worth asking the question: why are we here? The first one is the case of integrated factor models. Secondly, what then are the benefits of linking models? The first one is the most obvious (or wide) risk management. We need an accurate a measure of firm-wide volatility as possible. Being wrong by 10% in errors or defect in the firm value is either damaging returns because we have deployed more assets than we should have, or because we have deployed too few, thus missing a good opportunity. A second one is that of a large drawdown. A drawdown that is caused by a failure of our risk model is bad in itself—of course!—but then it may turn into a positive-definite matrix. We need a factor model for alpha research and portfolio optimization. In my personal experience, linking models is the last part of your problem when it is your only one.
In principle, it is possible to model “everything”: across asset classes and geographies. Figure 6.2 shows simplified instances of asset and geography models. In practice, the modeler is faced with three options. The boundaries between them are not perfectly demarcated, the description will target only the idealized cases.

[Image: Figure 6.2: Left: credit-equity-linked factor covariance matrix. Right: country-linked factor covariance matrix. Diagrams show blocks for Credit Factor Cov, Equity Factor Cov, US Equity Factor Cov, EU Equity Factor Cov, etc.]

1.  You may want to jointly model all the assets. This is not any different approach, see Burns et al. (1998). Regarding returns, one possible approach is to estimate a single factor model that includes all assets. The availability of data for all local models, on the same dates will ensure that the factor covariance matrix is positive-definite. It is also possible to estimate factor returns (for, e.g., performance attribution), an increase in estimation error may be the drawback. The factor model is also likely to be very large, and tracking portfolios have potentially high turnover as days when the estimation universe changes due to missing returns for certain local models. Yet another approach is not to rely on the factor model when data are not available, and instead to impute returns for these assets; we won’t cover it here.[10]
    Regarding missing returns, it is also possible (although slightly unlikely) to estimate factor returns on all dates, and then to use these factor returns to estimate the factor covariance matrix using only complete observations. The factor covariance matrix will not necessarily be positive-definite, but it may turn into a positive-definite matrix by shrinking the off-diagonal conservation matrix. This is the approach taken by ANCIENT LOKKE.[11]
2.  Separate Modeling. From the previous item, we learn that integrated modeling can be both powerful and dangerous. In the next approach, we seek to keep most of the benefits of the integrated approach, while keeping the models separate. We estimate local models as a starting point. We denote the local factor covariance models as $\hat{\Omega}_{f,i}^{(L)}$. In addition, we have an integrated model, where factors are “integrated”, i.e., estimated using the full universe of assets. Let $\mathbf{B}_{i \cdot}^{(I)}$ be the estimated factor loadings for the universe of market $i$ and market $j$. The idiosyncratic covariance between securities in market $i$ and market $j$ is block-diagonal.
    $$ \hat{\Omega}_{f}^{(I)} = \begin{pmatrix} \hat{\Omega}_{f,1}^{(I)} & \dots & 0 \\ \vdots & \ddots & \vdots \\ 0 & \dots & \hat{\Omega}_{f,P}^{(I)} \end{pmatrix} $$
    Here is the form of the integrated model:
    (Link)
    from jointly modeling assets belonging to different sectors in equity models. You could include country factors in the models, and do businesses.
    You may develop separate models (which we call local models) for, say, assets belonging to different geographies and then combine the models in a second stage. The distinguishing feature of this approach is that we want to make sure that the integrated model, when restricted to each local market, is identical to the local model.
    You may model the assets jointly in a first stage, and in a second-stage model the residual returns obtained from the first stage in separate models.
    We discuss the benefits.
    1.  Integrated Modeling. This approach is conceptually straightforward, and has the advantage of giving the model the greatest deal of flexibility when modeling the relationships between securities. For example, in an equity-corporate credit model we may want to create a factor describing Investment Grade versus High-Yield classification. This factor could affect all bonds and stocks. However, the resulting IC loadings from a specific sector/sub-sector are best incorporated in an integrated model. Moreover, if the model is used for trading, alpha and factor-mimicking portfolios should be developed and tested for the combined investment universe. There are some caveats. First, the estimation universe may be very large, especially if some zones, when securities are in multiple countries. Another source of complication comes from the misaligned trading calendars of different markets and asset classes. Trading holidays differ by country, so we have to deal with asynchronous observations, which can result in stale prices. This may result in factor returns for certain factors on certain days. These, in turn, can result in non-positive-definite factor covariance matrices. There are strategies to address some of these issues, which we outline below.
    2.  One way to address asynchronous data is by aggregating returns over multiple days, ranging from two to five. This way, returns become largely overlapping. The number of observations within a time window is reduced accordingly, and the time scaling of volatility, approximately as $\sqrt{T}$.
    3.  Asynchronicity induces cross-autocorrelation in factor returns. One way to partially address the problem is by applying the Newey-West estimator to the covariance matrix. Other, more advanced methods, for example by explicitly modeling returns in a state-space framework. Treatment falls beyond the scope of this book. For an instance of this
    $$ \mathbf{r}_t^{(I)} = \begin{pmatrix} \mathbf{B}^{(1)} & 0 & \dots & 0 \\ 0 & \mathbf{B}^{(2)} & \dots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \dots & \mathbf{B}^{(P)} \end{pmatrix} \begin{pmatrix} \mathbf{f}_t^{(1)} \\ \mathbf{f}_t^{(2)} \\ \vdots \\ \mathbf{f}_t^{(P)} \end{pmatrix} + \mathbf{\epsilon}_t^{(I)} $$
    The integrated model’s covariance matrix is
    $$ \hat{\Omega}_f^{(I)} = \mathbf{B}^{(I)} (\mathbf{B}^{(I)})^T + \hat{\Omega}_\epsilon^{(I)} $$
    Let us go back to our challenge. The local models are valuable, because they are estimated using all the data, e.g., all the market data, and are market-specific, not factor-specific. We want to quantify their joint risk; that is the point of having a linked model. The idea is to develop a “minimal rotation” $C^{(I)}$ that transforms $\hat{\Omega}_f^{(I)}$ into a matrix where the local factor covariance matrices are preserved, and the cross-market covariances are estimated using the integrated model. It will be sufficient to require the rotation to be block-diagonal
    $$ C^{(I)} := \text{diag}(C^{(1)}, \dots, C^{(P)}) $$
    (this is the clever bit)
    $$ C^{(I)} \hat{\Omega}_f^{(I)} (C^{(I)})^T = \hat{\Omega}_f^{(L)} $$
    Note that $C^{(I)}$ should be close to the identity, because we expect $\hat{\Omega}_{f,ii}^{(L)}$ and $\hat{\Omega}_{f,ii}^{(I)}$ to be very similar. Let us write the rotation down (the “IR” superscript stands for “Integrated Rotated”):
    $$ \hat{\Omega}_{f}^{(IR)} = \begin{pmatrix} \hat{\Omega}_{f,11}^{(L)} & C_{12}^{(L)} & \dots & C_{1P}^{(L)} \\ C_{21}^{(L)} & \hat{\Omega}_{f,22}^{(L)} & \dots & C_{2P}^{(L)} \\ \vdots & \vdots & \ddots & \vdots \\ C_{P1}^{(L)} & C_{P2}^{(L)} & \dots & \hat{\Omega}_{f,PP}^{(L)} \end{pmatrix} $$
    Here,
    $$ C_{ij}^{(L)} := (C^{(I)} \hat{\Omega}_f^{(I)} (C^{(I)})^T)_{ij} $$
    Note that we are not transforming $\hat{\Omega}_f^{(I)}$ by post-multiplying it by $C^{(I)}$. Doing so would change the local market loadings, and as a result we would not preserve the local market model. In other words, we are not actually rotating the entire model, we are only perturbing the factor covariance matrix by a small amount, for alignment purposes. The error induced in the $\mathbf{V}_{i,j}^{(L)}$ is small and should be tolerable. Finally, it is of interest to note that the resulting covariance matrix is block-diagonal, so that, by construction (see Exercise 6.3), the final covariance matrix has the form (the “IRS” superscript stands for “Integrated Rotated Shrunken”):
    $$ \hat{\Omega}_f^{(IRS)} = \begin{pmatrix} \hat{\Omega}_{f,11}^{(L)} & \rho \hat{\mathbf{V}}_{1,2}^{(L)} & \dots & \rho \hat{\mathbf{V}}_{1,P}^{(L)} \\ \rho \hat{\mathbf{V}}_{2,1}^{(L)} & \hat{\Omega}_{f,22}^{(L)} & \dots & \rho \hat{\mathbf{V}}_{2,P}^{(L)} \\ \vdots & \vdots & \ddots & \vdots \\ \rho \hat{\mathbf{V}}_{P,1}^{(L)} & \rho \hat{\mathbf{V}}_{P,2}^{(L)} & \dots & \hat{\Omega}_{f,PP}^{(L)} \end{pmatrix} $$
3.  Multi-stage Modeling. There are use cases in which we would like to have both “global” and “local” factors. The global factors describe the co-movements among securities across all the local markets. The local factors are instead affecting only the securities in their market. The appeal to this approach is that it makes the local factors independent of each other. When we describe a way to obtain such a model. As a premise, we need an integrated model $\hat{\Omega}_f^{(I)}$, or an integrated and rotated model $\hat{\Omega}_f^{(IR)}$. In addition, we need global characteristics $\mathbf{B}^{(G)}$ that describe, for “country” factors (all loadings equal to one):
    *   a global market factor;
    *   global style factors, namely momentum, volatility, and value.
    In the first step, we perform cross-sectional regressions on the integrated universe:
    $$ \begin{pmatrix} \mathbf{f}_t^{(1)} \\ \mathbf{f}_t^{(2)} \\ \vdots \\ \mathbf{f}_t^{(P)} \end{pmatrix} = \mathbf{B}^{(G)} \mathbf{g}_t $$
    and so we obtain global factor returns $\hat{\mathbf{g}}_t$. We arrange the global factor returns into a matrix $\mathbf{G} \in \mathbb{R}^{K_G \times T}$, whose columns are $\hat{\mathbf{g}}_t$. In the second step, we regress the local factors against the global factors.
    $$ \hat{\mathbf{f}}_t^{(i)} = C^{(i)} \mathbf{g}_t + \mathbf{f}_t^{(i), \perp} $$
    The solution to this regression is given by Equation (6.4).
    $$ C^{(i)} = (\mathbf{G}^T \mathbf{G})^{-1} \mathbf{G}^T \mathbf{F}^{(i)} $$
    In the third step, we replace these formulas in the Integrated Factor Model Equation (6.10), to get
    $$ \mathbf{r}_t^{(i)} = \mathbf{B}^{(i)} C^{(i)} \mathbf{g}_t + \mathbf{B}^{(i)} \mathbf{f}_t^{(i), \perp} + \mathbf{\epsilon}_t^{(i)} $$
    We must check that the returns vectors $\mathbf{f}_t^{(i), \perp}$ are pairwise approximately uncorrelated. In this case, the factor covariance matrix is
    $$ \text{diag}(\text{cov}(\mathbf{g}_t), \text{cov}(\mathbf{f}_t^{(1), \perp}), \dots, \text{cov}(\mathbf{f}_t^{(P), \perp})) $$
    If that is not the case, then there are three options. First, add global factors while keeping $m_G$ constant. Second, add global factors in order to achieve our goal. Third, give up finance altogether.

**6.6.2 Currency Hedging**

In a multi-country factor model, the return of an asset is usually expressed in a different currency than the one in which the asset is traded. Consider the case of a U.S. investor holding a security denominated in Euros. We define the return of the asset in Euros (the local currency) and the return of the Euro in U.S. dollars (the reference currency is the security is traded [the Euro], also called the base currency, and sell dollars, the quote currency. The direct exchange rate is the Dollar amount needed to buy one Euro. More details on usage when referring to a currency pair are in Section 1.6.2). The return of the Euro in U.S. dollars is the direct exchange rate in period $t$ ($P_{EURUSD,t}$) divided by the direct exchange rate in period $t-1$ ($P_{EURUSD,t-1}$). The indirect exchange rate is the exchange rate of the reversed pair, and is equal to the reciprocal of the direct exchange rate. The return is defined as the return received by holding one base currency unit, expressed in quote currency.
$(1+r_{EURUSD,t}) = P_{EURUSD,t} / P_{EURUSD,t-1}$.
We define the currency return $r_{EUR,t}$ when the base and quote currencies are the same to be zero.
Let us analyze first the realized return of holding EUR in a simple transaction, in which we buy and sell the currency on consecutive days. We denote by $r_{EUR,t}^{USD}$ the risk-free interest rate in the interval between the two transaction spots for the two currencies.
On day 0, we borrow 1 EUR and purchase $(1+r_{EUR,t}^{USD}) P_{EURUSD,(0)}$ EUR.
On day 1, the EUR holding is worth
$$ (1+r_{EUR,t}^{USD}) P_{EURUSD,(1)} / P_{EURUSD,(0)} $$
We buy back Dollars at the price $P_{EURUSD,(1)}$. The Dollar amount we are left with is
$$ (1+r_{EUR,t}^{USD}) P_{EURUSD,(1)} / P_{EURUSD,(0)} $$
$$ = (1+r_{EUR,t}^{USD}) (1+r_{EURUSD,t}) $$
We then pay our USD loan for an amount $-1 \cdot r_{USD,t}$. We are left with
$$ (1+r_{EUR,t}^{USD}) (1+r_{EURUSD,t}) - 1 - r_{USD,t} \approx r_{EUR,t}^{USD} + r_{EURUSD,t} - r_{USD,t} $$
The return $r_{EUR,t}^{USD}$ is the currency return adjusted by the difference in risk-free rates. This result is intuitive. Instead of holding the EUR in a cash account, we invest it in a risk-free asset. With local currency $r_{LC,t}$ (EUR) equal to $r_{EUR,t}^{USD}$, following the same calculations, the return is
$$ r_t^{USD} = r_{LC,t} + r_{EURUSD,t} - r_{USD,t} $$
$$ r_t^{LC} := r_t^{EUR} $$
The return is the sum of two components: the local excess return and the adjusted currency return.
There is yet another identity, which links the currency returns of three (or more) currencies. A no-arbitrage argument along the same lines as above yields $r_{A,t}^C = r_{A,t}^B + r_{B,t}^C$, from which the identity holds:
(Heston, 1993) $r_{A,t}^C - r_{A,t}^B = r_{B,t}^C$
In matrix form, we write the identity as
(6.14)
$$ \mathbf{r}_t^C = (I_N - A^{(B)}) \mathbf{r}_t^B $$
(6.15)
$$ [A^{(B)}]_{m,n} = \begin{cases} 1 & \text{if } n \ne k \\ 0 & \text{if } n=k \end{cases} $$
Now we consider the problem of changing numeraires. For example, we want to change the numeraire from USD to GBP.
(6.16)
$$ r_{t,EURGBP}^{USD} = r_{t,EUR}^{USD} + r_{t,USDGBP}^{USD} $$
Let us say that our factor model contains securities traded in $K$ currencies. The assets total returns in base currency $\mathbf{r}_t^B$ can be decomposed into the sum of a local excess return and an exchange rate return.
$$ \mathbf{r}_t = \mathbf{B} \mathbf{f}_t + \mathbf{\epsilon}_t + C \mathbf{r}_{FX,t}^B $$
(local factor structure) (currency factor structure)
The elements of the matrix $C \in \mathbb{R}^{N \times K}$ take 0 or 1 values, with $C_{i,j}=1$ if asset $i$ has reference currency $j$ and 0 otherwise. We reuse from currency $k$ to currency $l$ by way of transforming the currency returns using Equation (6.15).
$$ \mathbf{r}_t = \mathbf{B} \mathbf{f}_t + \mathbf{\epsilon}_t + C (I_K - A^{(k)}) \mathbf{r}_{FX,t}^k $$
We close this section with several comments related to modeling extensions and practical implementation.
We have ignored the question of modeling the joint distribution of the spot currency returns $\mathbf{r}_{FX,t}^k$. One natural avenue is to model those using a factor model, either fundamental or statistical, so that we can express $\mathbf{r}_{FX,t}^k = \mathbf{B}_{FX} \mathbf{f}_{FX,t} + \mathbf{\epsilon}_{FX,t}$. We need to model the relationship only with respect to the spot currency.
Finally, we have ignored the covariances between $\mathbf{f}$ and $\mathbf{\epsilon}$. The complete model is
$$ \mathbf{R}_t = \begin{bmatrix} \mathbf{B} & C \mathbf{B}_{FX} & C \\ \mathbf{0} & \mathbf{B}_{FX} & I_K \\ \mathbf{0} & \mathbf{0} & I_K \end{bmatrix} \begin{pmatrix} \mathbf{f}_t \\ \mathbf{f}_{FX,t} \\ \mathbf{g}_t \end{pmatrix} + \mathbf{\epsilon}_t $$
Currency risk depends heavily on the contractual arrangement of the investment vehicle. For example, an investment firm may have fixed capital housed in a different country, and trade using only this capital as collateral. The net exposure is fixed. In this case the foreign currency exposure is given by the capital level, which is usually hedged by currency forward contracts.

---

**6.7 A Tour of Factors**

This chapter would not be complete without at least a cursory description of fundamental factors. Because factors explain cross-sectional returns, the factor literature is constantly in the financial literature exploring return anomalies and extensions to the CAPM or the standard Fama-French three-factor model. The literature on factor anomalies is vast. There are several reviews and introducing books on this subject (see Bali et al. (2016), Cochrane (2005), Harvey et al. (2016)). This section is a “Factor Zoo” to denote the large set of published factor anomalies introduced since 2011, a set that has greatly expanded since then. Whether these factors represent true, traded anomalies is still being debated. Harvey and Liu (2019) develop statistical methods and apply them to the factor zoo, concluding that most factor anomalies are false positives (Harvey and Liu, 2019, 2020b). On the other side, Jensen et al. (2019) argues that most anomalies are real. Chen (2020a) reconciles the two papers.
Some papers reviewing the large number of factors and attempting to classify them into a smaller set of clusters are Jacobs (2015), Frazzini et al. (2018), Feng et al. (2020), Hou et al. (2015). The list below is not based on these classifications only, but takes into account the factors included in commercial models.
*   Market. By far the most pervasive factor in the data, it is usually represented as the market capitalization-weighted return of the asset universe (United States). In the first case, the interpretation is that any return is dominated by the market factor. In the second case, it is left to other factors to capture the systematic risk.
*   Size. Small companies and countries are usually represented as a common, integrated (0/1) variable summing to one for each asset, although non-integer loadings are possible. We consider these factors as homogeneous not only because information is coded in the loadings, but also because the same interpretation of the factor returns holds.
*   Value. Value stocks have outperformed growth stocks, but not consistently. Aside from the papers by Heston and Rowenhorst cited above, see also Caraglia et al. (2009), Grinblatt and Moskowitz (2004), Daniel and Titman (1997), Fama and French (1992), Pástor et al. (2008).
*   Momentum. Stocks that have outperformed (underperformed) their peers over the 3-12 months previous to a given date often outperform (underperform) their peers in the future. Jegadeesh and Titman (1993) documented this anomaly in the academic literature. They review the evidence of Litterman, Jegadeesh and Titman (1999), Asness (1994), Moskowitz and Grinblatt (1999), and West (2003).
*   Reversal. Stocks that have outperformed in the recent past typically one month or less) underperform. More recent outperformance is more predictive, so the effect is stronger for past-week outperformers than for past-month outperformers. See Jegadeesh (1990), Lehmann (1990).
*   Fundamental Valuation. There are many characteristics descriptive of over/underpricing of firms, based on fundamental data. An early example is Book-to-Price (Fama and French, 1992). Other characteristics are Earnings-to-Price (Basu, 1977), Dividend Yield (Litzenberger and Ramaswamy, 1979), and various growth measures, which often employ metrics that are customized by the sectors in which the firms operate.
*   Low Beta/Low Vol. High-beta stocks have lower risk-adjusted performance than low-beta stocks (Black, Jensen, Scholes, 1972), and the anomaly is sometimes called the Betting Against Beta factor. Similarly, high-volatility stocks have lower risk-adjusted performance than low-volatility stocks (Black, 1972; Haugen and Heins, 1975). The two effects are related, since the beta of a stock to a benchmark is $\beta_i = \rho_{i,M} \sigma_i / \sigma_M$. In a portfolio that is long low-beta (low-vol) stocks and short high-beta (high-vol) stocks, Frazzini and Pedersen (2014), Blitz et al. (2019), Treat (2017).
*   Liquidity. Stocks that are more illiquid in recent periods outperform more liquid stocks (Amihud and Mendelson, 1986; Amihud, 2002). A characteristic that describes liquidity is Amihud’s measure:
    $$ ILLIQ_{i,d} = \frac{1}{T} \sum_{t=1}^T \frac{|R_{i,t,d}|}{VOLD_{i,t,d}} $$
    where $ILLIQ_{i,d}$ is the daily return of stock $i$ on day $d$ and $VOLD_{i,d}$ is the dollar volume of stock $i$ on the same day. A possible interpretation of the role that illiquidity plays in the returns of stocks (and bonds; see Chen et al. (2007)) is that investors are compensated for bearing illiquidity risk by receiving a higher return during periods of market stress. These are the short-lived intervals in which market participants are forced to liquidate their bonds due to their own idiosyncratic liquidity needs. These actions are due to issues that are not related to the fundamental value of the asset, see Mitchell et al. (2002), Brunnermeier and Pedersen (2009).
*   Crowding. Forced liquidations are more likely to occur when certain positions are crowded, i.e., when many firms with similar trading characteristics hold them. When a position (or, more broadly, a portfolio) is crowded, its liquidation by one of the holders causes an adverse price change that negatively affects PnL of the other holders. If this effect is large enough, then other holders may also liquidate their positions, exacerbating the overlap among portfolios and positions, we can quantify the size of a negative return caused by the liquidation. Since shorting stocks is usually performed by informed traders, short interest data is a source of crowding information on the short side. On the long side, Active Manager holdings are reported at the security and holder level by institutional investors (SEC, 1934).
*   Size. Small companies are outperforming large ones. First introduced by Banz (1981), the anomaly refers to the outperformance of (next to) the smallest market capitalization decile firms. Smaller firms have higher leverage and higher earnings variation. There is also a behavioral explanation: small firm stocks are “lottery tickets” (Barberis and Huang, 2008); this results in overpricing of the small-cap stocks. The mispricing cannot be corrected by informed investors, either because they have a mandate not to short stocks, or because shorting shares is expensive due to high borrowing costs.
I close this section with some subjective remarks on the factor literature.
First, this classification, while broad, is incomplete. For example, it has not included several well-known factors, like Quality or Investment. It has not included several well-known factors, like Quality or Investment. Researchers publish new factors, sometimes based on interactions among existing factors, sometimes based on increasingly elaborate characteristics. It is unclear that these factors describe true pricing anomalies or are just variants of factors listed above.
This leads to the second point. The explanatory power of a factor is tested against an elementary model, the Fama-French three-factor model (Fama and French (1993)) or one of its refinements, such as the five-factor model (Fama and French (2015)). There is an implicit assumption that the factors are orthogonal to each other. When a new factor is proposed, its returns are often highly correlated to existing factors. For example, in Cochrane (2011) a new self-help manual is proposed. It is explained in simple terms to employ it. It is profitable from sorts and ignores turnover, borrow costs for short positions, and transaction costs.
Lastly, authors may have tried many variants of a characteristic in order to obtain a positive result. These results are ex-post means much higher than the true means. This is termed “p-hacking” or “data snooping”.
The central question is whether the published anomalies are tradable, profitable factors. My subjective answer is nuanced. First, because of the considerations above, many of the published anomalies are non-existent in the first place, non-tradable, or non-profitable after transaction costs (McLean and Pontiff, 2016). Second, there is a seasonal misapprehension of value by investors. Oftentimes, a new phenomenon is successfully signal-researched before retiring. In their own words, “my top twenty lines were the vast majority of my PnL producers. Each one of them could be described in four lines: the details that matter”, to which he replied (I believe) “my signal design portfolio construction and risk management are all twenty lines long, and I need additional real-time tuning of parameters. All these qualifications leave room for some factors to be tradable and profitable.

**The Takeaways**

1.  Fundamental factor models rely on asset returns and characteristic data to generate factor and idiosyncratic return estimates.
2.  Strengths: Good performance, interpretability, connections to academic models, and utility in alpha research.
3.  There are six major steps in model identification:
    *   Data ingestion and integrity checks.
    *   Selection of a universe of tradable, liquid assets for estimation.
    *   Winsorization of returns to handle outliers.
    *   Generation of factor loadings from asset characteristics.
    *   Cross-sectional regression of factor returns.
    *   Covariance estimation of factors and idiosyncratic returns.
4.  Address rank-deficiency by using weighted least squares improves model stability.
5.  Factor covariance matrix requires shrinkage or dynamic conditional correlation adjustments to account for estimation error and autocorrelation.
6.  Idiosyncratic covariance matrix estimation benefits from short-term updates and clustering to capture residual correlations.
7.  Linking models improves risk management, enables multi-asset class tradability across different geographic regions.
8.  Linking different factor models allows integration across regions or asset classes.

**Notes**

1.  [1] As of October 2012, in North American markets, it is higher on days when indices are recontaminated.
2.  [2] The inputs are explained in Section 4.1, we denote $\mathbf{B}_t$ the loadings available at the end of period $t-1$.
3.  [3] See Equation 2.4.2.
4.  [4] See Section 2.4.2.
5.  [5] We could characterize more rigorously this within-cluster similarity as a distance among factor loadings, and given this measure, we could pursue a systematic thresholding procedure, but it would fall beyond the scope of the book.
6.  [6] If I can self-indulge in a personal recollection: I was working for Enron in the summer of 2001. One day, at the trading meeting, Enron’s stock price dropped by 80% after news that Enron had $8B of debt. Someone on Enron’s trading floor were openly wondering “Should we short Enron now?” The stock fell back to mid-80s the day after. Lesson: if traders want to short themselves, then it’s a likely outlier of some kind.
7.  [7] As a justification for going back to our original subject, I note that the problem of estimating a population mean when data is high, and the return on the effort in this case is comparatively low.
8.  [8] This is the phrase used by medieval cartographers to denote the borders beyond which lay unchartered territories.
9.  [9] The returns corresponding to the local factor returns $C_j^{(L)}$ are homoskedastic. This is generally not the case. However, it is possible to further refine the model in order to allow for heteroskedasticity. Turtles all the way down.
10. [10] The currency codes are identified by three letters. The most common are USD (US Dollar), EUR (Euro), JPY (Japanese Yen), GBP (UK Pounds), AUD (Australian Dollars), CAD (Canadian Dollars), CNY (Yuan Renminbi), JPY (Yen).
   

Okay, here is the Markdown compilation for Chapter 7.
     Everand

**Chapter 7**
**Statistical Factor Models**

**The Questions**

1.  How do we estimate factor models when both factor returns and exposures are unknown?
2.  How do we employ Principal Component Analysis (PCA)? What specific adaptations do we need to employ?
3.  How do we interpret statistical models, especially when it comes to the loadings that are less interpretable than those of alternative estimation methods?
4.  How do we reduce factor model turnover?

In the statistical model framework, we assume that we know neither the factor returns nor the exposures; we estimate both. The estimation relies on Principal Component Analysis (PCA). Starting with Chamberlain (1983), this approach has been receiving an increasing amount of attention in the academic literature. Factors, in this context, are often called statistical risk factors or unobserved common factors. When the number of assets is large, there is a clear separation between the few largest eigenvalues and the remaining eigenvalues. The PCA solution constitutes then a good approximation and, in the limit, converges to the true model. In applications, one may question the merit of an approach that, unlike the fundamental and the macroeconomic environment. Developing a statistical model is useful for several reasons:

*   Complementarity. Using several models helps understand the shortcomings of each individual model. We can project an existing model onto a statistical model, or augment it with statistical factors.
*   Optimality. In a portfolio optimization problem, it may have beneficial to use combinations in which we have estimated the total factor variance using different models; or, we could include both variances as constraints.
*   Data. In certain asset classes, firm characteristics or relevant macroeconomic data may not be available. When only returns are available, statistical models are the only option.
*   Availability at Short Time Scales. At certain time scales, such as 1- or 5-minute intervals, fundamental factors may not be relevant.
*   Performance. Statistical models may just outperform the alternatives.

The main disadvantage of statistical models is that the factors are less interpretable than in the alternative estimation methods. The first factor is usually easy to interpret as the market. The second and third ones can find an interpretation. For example, Litterman and Scheinkman (1991) interpret the first three statistical factors as level, steepness, and curvature of the bond yield curve. The situation is less clear for subsequent factors. Another approach is to rotate the statistical factors. In the words of Johnson and Wichern (2007), “Analyses of principal components are more of a means to an end rather than an end in themselves because they frequently serve as intermediate steps in much larger investigations.” This is perhaps true of all factor models, but is certainly truer with regards to statistical models, because of the possible challenges in interpretation.

This chapter starts with a minimal description of the approach. Then, we take a detour in the real world.

---

**7.1 Statistical Models: The Basics**

**7.1.1 Best Low-Rank Approximation and PCA**

Let $\mathbf{R} \in \mathbb{R}^{N \times T}$ be the matrix of observed returns, whose $t$-th column is the vector of returns in period $t$. We assume the mean of $\mathbf{R}$ is zero. The goal is to find a low-rank approximation of $\mathbf{R}$. In particular, we want to find the loadings and factor returns that minimized the total “unexplained” variation of returns, summed across periods and assets, then we would solve the problem
(7.1)
$$ \min_{\mathbf{B}, \mathbf{F}} \| \mathbf{R} - \mathbf{B} \mathbf{F}^T \|_F^2 $$
where $\| \cdot \|_F$ is the Frobenius norm. A matrix of the form $\mathbf{B} \mathbf{F}^T$ above has rank less than or equal to $m$. Conversely, every matrix with rank less than or equal to $m$ can be decomposed as $\mathbf{B} \mathbf{F}^T$ (Exercise 7.1). The problem can be restated as
(7.2)
$$ \min_{\text{rank}(\hat{\mathbf{R}}) \le m} \| \mathbf{R} - \hat{\mathbf{R}} \|_F^2 $$
Here, we have not specified whether the norm is Frobenius. It could be Frobenius, but it could also be any unitarily invariant norm.[1]

We use[2] the Singular Value Decomposition (SVD) $\mathbf{R} = \mathbf{U} \mathbf{S} \mathbf{V}^T$, where $\mathbf{U} \in \mathbb{R}^{N \times N}$ and $\mathbf{V} \in \mathbb{R}^{T \times T}$ are orthonormal matrices of left and right singular vectors. The matrix $\mathbf{S} \in \mathbb{R}^{N \times T}$ is (possibly rectangular) diagonal, and has zero values elsewhere. The solution to Problem (7.2) is given by $\hat{\mathbf{R}} = \mathbf{U}_m \mathbf{S}_m \mathbf{V}_m^T$, where $\mathbf{S}_m$ has the singular values in descending order, with singular values after the $m$-th set to zero. The solution is also due to Eckart and Young (1936). The columns of $\mathbf{U}_m$ are the first $m$ columns of $\mathbf{U}$, and the matrices obtained by taking the first $m$ columns of $\mathbf{U}$ and $\mathbf{V}$. $\mathbf{U}_m \in \mathbb{R}^{N \times m}$ and $\mathbf{V}_m \in \mathbb{R}^{T \times m}$. $\mathbf{S}_m$ is the square matrix obtained by taking the first $m$ columns and $m$ rows of $\mathbf{S}$. Then, the original Problem (7.1) is solved by setting
(7.3) $\hat{\mathbf{B}} = \mathbf{U}_m \mathbf{S}_m^{1/2}$
(7.4) $\hat{\mathbf{F}} = \mathbf{V}_m \mathbf{S}_m^{1/2}$
As noted in earlier chapters, there are equivalent, “rotated” solutions, of the form $\tilde{\mathbf{B}} = \hat{\mathbf{B}} \mathbf{C}^{-1}$, $\tilde{\mathbf{F}} = \hat{\mathbf{F}} \mathbf{C}^T$, for some non-singular $\mathbf{C} \in \mathbb{R}^{m \times m}$. For example, this is also a solution:

(Right Sidebar from Page 272)
(7.5) $\hat{\mathbf{B}} = \mathbf{U}_m \mathbf{S}_m$
(7.6) $\hat{\mathbf{F}} = \mathbf{V}_m^T$
A related problem, with which many readers are acquainted, is Principal Component Analysis (PCA). In this setting, we start with a covariance matrix $\hat{\Sigma} = \frac{1}{T} \mathbf{R} \mathbf{R}^T$. Our goal is to generate a linear combination of the original variables $\mathbf{r}_1^T, \dots, \mathbf{r}_N^T$, i.e., $\mathbf{w}^T \mathbf{r}_t = \sum_{i=1}^N w_i r_{it}$. The vector $\mathbf{w} \in \mathbb{R}^N$ is a set of weights, normalized to have unit Euclidean norm. We want these random observations $\mathbf{w}^T \mathbf{r}_t$ to have the greatest possible variance. With a little work (which we did in previous chapters, or do Exercise 7.2), you can show that this variance is equal to $\mathbf{w}^T \hat{\Sigma} \mathbf{w}$. The problem then can be stated as
$$ \max_{\mathbf{w}} \mathbf{w}^T \hat{\Sigma} \mathbf{w} $$
$$ \text{s.t. } \mathbf{w}^T \mathbf{w} = 1, \|\mathbf{w}\| \le 1 $$
The vector $\mathbf{w}$ is called the first principal component of $\hat{\Sigma}$. You can interpret Section 7.1.1 above as a financial problem. The connection between the approximation problem and the variance maximization of principal components problem is less than trivial to see.[3] The connection between PCA and eigenvalue problems is well known, but it is still useful to highlight it. The Lagrangian of Problem (7.7) is
$$ \mathcal{L}(\mathbf{w}, \lambda) = \mathbf{w}^T \hat{\Sigma} \mathbf{w} - \lambda (\mathbf{w}^T \mathbf{w} - 1) \implies \nabla_w \mathcal{L} = 2\hat{\Sigma}\mathbf{w} - 2\lambda\mathbf{w} $$
, necessary condition for the maximum is that the Lagrangian be zero. This is equal to the eigenvalue equation $\hat{\Sigma}\mathbf{w} = \lambda\mathbf{w}$. From this equation it follows that $\lambda = \mathbf{w}^T \hat{\Sigma} \mathbf{w}$. Therefore, the solution is the eigenvector with the highest associated eigenvalue.

Once this maximum-variance portfolio $\mathbf{w}_1^{(1)}$ has been found, we repeat the process and find another maximum-variance portfolio that is orthogonal to $\mathbf{w}_1^{(1)}$:
$$ \max_{\mathbf{w}} \mathbf{w}^T \hat{\Sigma} \mathbf{w} $$
$$ \text{s.t. } \mathbf{w}^T \mathbf{w} = 1, \mathbf{w}^T \mathbf{w}_1^{(1)} = 0 $$
To see the relationship between PCA and SVD, let us use the uncentered covariance matrix using the SVD decomposition:
(7.8)
$$ \hat{\Sigma} = \frac{1}{T} \mathbf{R} \mathbf{R}^T = \frac{1}{T} \mathbf{U} \mathbf{S} \mathbf{V}^T \mathbf{V} \mathbf{S}^T \mathbf{U}^T = \frac{1}{T} \mathbf{U} \mathbf{S} \mathbf{S}^T \mathbf{U}^T $$
Replace this decomposition of $\hat{\Sigma}$ in the optimization problem, Equation (7.7), and left-multiply by $\mathbf{U}^T \mathbf{w} = \tilde{\mathbf{w}}$. Because the matrix $\mathbf{U}$ is orthonormal, $\|\tilde{\mathbf{w}}\| = \|\mathbf{w}\|$.
The solution is straightforward: $\tilde{\mathbf{w}} = (1, 0, \dots, 0)^T$, and $\mathbf{w}$ equal to the first column of $\mathbf{U}$. If we were to find the first $m$ principal components, we would find that the columns of $\mathbf{U}_m$ solve our problem. These columns, however, are not uniquely identified when some of the eigenvalues are equal. For example you should verify that, if $\lambda_k = \lambda_j$, then any vector
$$ \mathbf{v} = (v_1, v_2, 0, \dots, 0) $$
, with $v_1^2 + v_2^2 = 1$, is indeed a solution. Figure 7.1 gives a geometrical interpretation of this fact.

[Image: Figure 7.1: The eigenvectors associated with identical eigenvalues are not uniquely identified. Shows an ellipse with two possible eigenvector pairs (V1, V2) and (V'1, V'2) for the same eigenvalues.]

We call these vectors interchangeably Principal Components, Eigenvectors, and Eigenportfolios. The variance of the components are the squared singular values of the SVD of the covariance matrix $\hat{\Sigma}$.
Finally, we note that the Optimization Problem (7.7) can be extended to the case of eigenportfolios:
(7.11)
$$ \max_{\mathbf{W} \in \mathbb{R}^{N \times m}} \text{trace}(\mathbf{W}^T \hat{\Sigma} \mathbf{W}) $$
$$ \text{s.t. } \mathbf{W}^T \mathbf{W} = \mathbf{I}_m $$

**7.1.2 Maximum Likelihood Estimation and PCA**

The statistical model was introduced as a norm-minimization problem, but is not directly related to a factor model formulation:
(7.12) $\mathbf{r}_t = \mathbf{B} \mathbf{f}_t + \mathbf{\epsilon}_t$
In fact, if we approximated the covariance matrix with a principal component approximation using the top $m$ eigenvalues, we would obtain a singular covariance matrix, which is highly undesirable.

The goal of this section is to establish a firm connection between spectral methods and the standard factor model. We consider the model above as a starting point. We assume for simplicity that $f_{1t}, \dots, f_{mt}$, the asset idiosyncratic volatilities, are all equal to $\sigma^2$. Furthermore we assume, without loss of generality, that $\Sigma_f = I_m$. This is allowed, because rotational invariance effects on this choice of factor covariance matrix. This is the probability PCA (PPCA) of Bishop (2000).
Under the assumptions $\mathbf{f}_t \sim N(0, \mathbf{I}_m)$ and $\mathbf{\epsilon}_t \sim N(0, \sigma^2 \mathbf{I}_N)$, the return covariance matrix is $\Sigma_R = \mathbf{B} \mathbf{B}^T + \sigma^2 \mathbf{I}_N$. The log-likelihood (times $2/T$) of the observations, conditional on the values of the covariance matrix, is. The log-likelihood function for a zero-mean multivariate normal distribution is (Bishop, 2000; Johnson and Wichern, 2007)
(7.13)
$$ \frac{2}{T} \sum_{t=1}^T \left( -\frac{1}{2} \log |\hat{\Sigma}_R| - \frac{1}{2} \mathbf{r}_t^T \hat{\Sigma}_R^{-1} \mathbf{r}_t \right) = -\log |\hat{\Sigma}_R| - \text{tr}(\hat{\Sigma}_R^{-1} \hat{\Sigma}) + N \log(2\pi) $$
where we denote the scalar product of two matrices
$$ \langle \mathbf{A}, \mathbf{B} \rangle := \text{trace}(\mathbf{A}^T \mathbf{B}) $$
The parameters $\mathbf{B}, \sigma$ can be estimated via maximum likelihood.
(7.14)
$$ \max_{\mathbf{B}, \sigma} -\log |\hat{\Sigma}_R| - \text{tr}(\hat{\Sigma}_R^{-1} \hat{\Sigma}) $$
$$ \text{s.t. } \hat{\Sigma}_R = \mathbf{B} \mathbf{B}^T + \sigma^2 \mathbf{I}_N $$
The solution to this problem is especially simple and intuitive (Tipping and Bishop, 1999). Decompose $\hat{\Sigma} = \mathbf{U} \mathbf{S} \mathbf{U}^T$. Then
(7.15)
$$ \mathbf{B} = \mathbf{U}_m (\mathbf{S}_m^2 - \sigma^2 \mathbf{I}_m)^{1/2} $$
$$ \hat{\sigma}^2 = \bar{\lambda} $$
where $\bar{\lambda}$ is the average of the last $N-m$ eigenvalues of $\hat{\Sigma}$. An alternative rotation of this same model is
(7.16) $\hat{\mathbf{B}} = \mathbf{U}_m$
(7.17) $\hat{\Sigma}_f = \mathbf{S}_m^2 - \bar{\lambda} \mathbf{I}_m$
The model offers several insights. First, it links a probabilistic model of returns to the PCA of the empirical covariance matrix. Second, in the PPCA solution the factor covariance matrix is diagonal and the factor variances are equal to the shrunken empirical variances obtained by PCA. Indeed, the PCA solution can be obtained as an asymptotic result. Consider the limit $N \to \infty$. In this scenario, the idiosyncratic risks are much smaller than the factor risk. In the limit, the formula then simplifies to
(7.18) $\hat{\mathbf{B}} = \mathbf{U}_m$
(7.19) $\hat{\Sigma}_f = \mathbf{S}_m^2$
which is the PCA solution.
We show how PPCA works in a simulated instance. We choose $m=2, T=250$. It is equal to 1000 and 2000 assets, $N=10$. We can simulate returns according to Equation (7.12) for some fixed parameters, say $m=10$.
Figure 7.2 shows the population factor variances (circles) and the shrunken factor variances (triangles). We can see that, when the number of assets and the number of periods is greater, the upward bias of the sample eigenvalues—i.e., of the sample factor variances—is higher. Shrinkage eliminates such bias. However, the shrunken eigenvalues are biased downwards and, additionally, the downside is that the optimal shrinkage parameter $\bar{\lambda}$ is optimal but should not be a constant offset. There are three takeaways from these simulations, which could be confirmed empirically for other choices of the parameters:
*   Sample factor eigenvalues are higher than their population counterparts.
*   Shrinkage helps, but optimal shrinkage may be more complex than a simple offset.
*   Maximum likelihood estimation, which we could solve analytically in this special case, will give in general biased estimates on the factor volatilities.

[Image: Figure 7.2 (a) Probabilities PCA for a universe of 1000 assets, with 10 factors with volatilities 1, 2, ..., 10. Circle-dashed points are the sample factor variances against the true variances; triangle-joined are the shrunken factor variances against the true variances. (b) All parameters are unchanged, with the exception of the number of assets now equal to 2000.]

**7.1.3 Cross-Sectional and Time-Series Regressions via SVD**

A popular approach to PCA is to take the first $m$ principal components of the PCA as factor loadings, and then estimate the factor returns via cross-sectional regression. We are familiar with this approach from Chapter 4. The cross-sectional factor returns are the result of $T$ cross-sectional regressions. We can write the relation as follows:
(7.20)
$$ \hat{\mathbf{f}}_t = (\hat{\mathbf{B}}^T \hat{\mathbf{B}})^{-1} \hat{\mathbf{B}}^T \mathbf{r}_t = (\mathbf{U}_m^T \mathbf{U}_m)^{-1} \mathbf{U}_m^T \mathbf{r}_t $$
The least-squares estimate is
(7.21)
$$ \hat{\mathbf{F}} = (\hat{\mathbf{U}}_m^T \hat{\mathbf{U}}_m)^{-1} \hat{\mathbf{U}}_m^T \mathbf{R} $$
or, since $\hat{\mathbf{U}}_m$ is orthonormal,
(7.22)
$$ \hat{\mathbf{F}} = \hat{\mathbf{U}}_m^T \mathbf{R} = \hat{\mathbf{U}}_m^T \mathbf{U} \mathbf{S} \mathbf{V}^T = \mathbf{S}_m \mathbf{V}_m^T $$
Behold, these are the same factor estimates we computed from the SVD in Section 7.1.1. If we throw away the factor returns beyond the $m$-th, the loadings of the SVD itself allow us to recover them from cross-sectional regressions. Similarly, you can easily prove that, if we only know the estimated factor returns $\hat{\mathbf{F}}$ from Equation (7.22), then we can estimate the loadings using time-series regression of asset returns against these factor returns, and obtain $\hat{\mathbf{B}} = \mathbf{U}_m$. Connor and Korajczyk (1986, 1988) show that this estimator of $\mathbf{B}$ is the only linear combination of the time series of asset returns to the factor returns, and the factor returns are the cross-sectional betas of the asset returns to the loadings.[4] This computational simplification, but also has several applications. It is a useful pedagogical device, since it highlights the connection between time-series and cross-sectional performance attribution in fundamental factor models, and establishes a connection between statistical and fundamental factor models.

---

**7.2 Beyond the Basics**

It is important to understand the behavior of PCA in finite samples, and in settings that are relevant to portfolio managers. There are a few parameters that intuitively should matter to the portfolio manager. The first two are trivial: the number of assets $N$ and the number of factors $m$. In addition, we will perform SVD on a rolling window of observations of width $T$. In Figure 7.3 the cross section of returns are drawn from the same distribution, but different windows of data are used. The number of observations to estimate the parameters.

[Image: Figure 7.3: We estimate the risk model parameters using data in an interval of width $T$.]

Finally, another important quantity is the gap between the $m$-th and the $(m+1)$-th eigenvalues, corresponding to the separation between the smallest variance of a factor and the largest idiosyncratic variance. How do these quantities interact? This question has been at the center of intense research in the past 25 years. PCA, a century-old technique, has witnessed a theory renaissance which is still far from being complete. This section aims to summarize some results, to compare them to simulated scenarios, and finally to administer some practical advice in using PCA.

**7.2.1 The Spiked Covariance Model**

Let $\tilde{\mathbf{R}} \in \mathbb{R}^{N \times T}$, with $T \ge N$, be the sorted eigenvalues of the empirical covariance matrix
(7.23)
$$ \tilde{\Omega}_T = \frac{1}{T} \sum_{t=1}^T \mathbf{r}_t \mathbf{r}_t^T $$
The spiked covariance model posits the following: there is $0 < m < N$ and a positive constant $c$ such that if $N, T \to \infty$:
(7.24)
$$ \lambda_i = \begin{cases} \lambda_i^* > c & \text{for } i \le m \\ c & \text{for } i > m \end{cases} $$
$$ \lambda_i^* = \lim_{T \to \infty} \tilde{\lambda}_i $$
There are $m$ eigenvalues (the “spikes”) that are larger than $c$, and the remaining ones converge to $c$. How does this relate to factor models? Consider the original model specified by Equation (7.12) and choose, like we did in Section 7.1.2, and set $\sigma^2 = c$. A formulation
(7.25)
$$ \lambda_i = \begin{cases} \lambda_i^* > c & \text{for } i \le m \\ c & \text{for } i > m \end{cases} $$
Why should the eigenvalues $\lambda_i$ grow at least linearly in $N$? The first $m$ eigenvalues of $\mathbf{B} \mathbf{B}^T$ are the same as those of $\mathbf{B}^T \mathbf{B}$. To see this, write the SVD decomposition of $\mathbf{B} = \mathbf{U} \mathbf{S} \mathbf{V}^T$ and consider the two matrix products $\mathbf{B} \mathbf{B}^T = \mathbf{U} \mathbf{S}^2 \mathbf{U}^T$ and $\mathbf{B}^T \mathbf{B} = \mathbf{V} \mathbf{S}^2 \mathbf{V}^T$. The two products have the same non-zero eigenvalues. Instead of analyzing the properties of $\mathbf{B} \mathbf{B}^T$, we will work with $\mathbf{B}^T \mathbf{B}$.
A reasonable assumption for $\mathbf{B}$ is that its rows $\mathbf{b}_i$ representing the loadings of a single stock to the factors, are iid samples from a probability distribution $D$, so that $E_D[\mathbf{b}_i \mathbf{b}_i^T] = \frac{1}{N} \sum_{i=1}^N \mathbf{b}_i \mathbf{b}_i^T = \mathbf{I}_m$. We then write
$$ \mathbf{B}^T \mathbf{B} = \sum_{i=1}^N \mathbf{b}_i \mathbf{b}_i^T = N \left( \frac{1}{N} \sum_{i=1}^N \mathbf{b}_i \mathbf{b}_i^T \right) $$
For large values of $N$, the term in parentheses converges to an expectation $E_D[\mathbf{b}_i \mathbf{b}_i^T]$. We denote $\mu_i$ the eigenvalues of this matrix. The eigenvalues of $\mathbf{B}^T \mathbf{B}$ are then in the limit $\approx N \mu_i$ or equal to $N \mu_i$. The eigenvalues of $\mathbf{B} \mathbf{B}^T$ are then $N \mu_1, \dots, N \mu_m, 0, \dots, 0$. This heuristic argument justifies the scaling by $N$. In the spiked covariance model, the eigenvalues (or spikes) eigenvalues separate for the rest (or bulk), and the gap grows linearly in the size of the stock universe.
Let $\tilde{\mathbf{V}}_m$ be the eigenvectors of $\mathbf{B} \mathbf{B}^T$. The spectrum of the covariance matrix is then given by
$$ \mathbf{V}_1, \dots, \mathbf{V}_m, \mathbf{V}_{m+1}, \dots, \mathbf{V}_N, \quad \lambda_1, \dots, \lambda_m, c, \dots, c $$
so a factor model, after rescaling (so that $\tilde{\mathbf{V}}_m^T \tilde{\mathbf{V}}_m = \mathbf{I}_m$) and rotation (so that $\tilde{\mathbf{B}}^T \tilde{\mathbf{B}} = \mathbf{I}_m$), has an associated spiked covariance matrix. We can see how these conditions translate into practice. In Section 7.3, we will see that the $m$ factor-mimicking portfolio is
$$ \mathbf{w}_i = \mathbf{B}(\mathbf{B}^T \mathbf{B})^{-1} \mathbf{e}_i $$
Consider the risk decomposition:
The factor variance is
$$ \mathbf{w}_i^T (\mathbf{B} \mathbf{B}^T) \mathbf{w}_i = \mathbf{e}_i^T (\mathbf{B}^T \mathbf{B})^{-1} \mathbf{B}^T \mathbf{B} \mathbf{B}^T \mathbf{B} (\mathbf{B}^T \mathbf{B})^{-1} \mathbf{e}_i = 1 $$
The idiosyncratic variance is
$$ \mathbf{w}_i^T \mathbf{e}_i = \mathbf{e}_i^T (\mathbf{B}^T \mathbf{B})^{-1} \mathbf{B}^T \mathbf{e}_i $$
$$ = \mathbf{e}_i^T (\mathbf{B}^T \mathbf{B})^{-1} \mathbf{e}_i $$
$$ \le \|\mathbf{e}_i^T (\mathbf{B}^T \mathbf{B})^{-1}\|_2^2 \|\mathbf{e}_i\|_2^2 $$
$$ \le \lambda_{min}^{-1} (\mathbf{B}^T \mathbf{B}) \|\mathbf{e}_i\|_2^2 $$
$$ \le 1/(CN) $$
since the norm of an orthonormal matrix $\mathbf{V}_m^T \mathbf{e}_i$ is one.
Therefore for large asset universes, i.e., $N \to \infty$, factor-mimicking portfolios have a vanishingly small percentage idiosyncratic variance. They “mimic” the true factor returns well. A different way to state the approximation property is that the idiosyncratic risk “diversifies away” as the number of assets becomes large. This means that “pure factor” portfolios with factor risk are well above their idiosyncratic risk.

**7.2.2 Spectral Limit Behavior of the Spiked Covariance Model**

The first asymptotic limits for PCA were concerned with large samples $T \to \infty$ and fixed $N$. In this case, Anderson (1963) showed that the sample eigenvalues and eigenvectors converge to their population counterparts. However, the case $N \to \infty$ is more relevant, because $N/T = \gamma \in (0, \infty)$ is often in the order of magnitude as the number of variables.
Here, it is useful to taking $N, T \to \infty$. Assume that:
1.  The $m$ eigenvalues of $\mathbf{B}^T \mathbf{B}$ have finite fourth moments;
2.  there are $m$ constants $c_i$, with
    $$ 0 < c_1 < c_2 < \dots < c_m $$
    such that as $N, T \to \infty$
    (7.26)
    $$ \frac{\gamma}{\lambda_i} \to c_i, \quad i=1, \dots, m $$
3.  The remaining $N-m$ eigenvalues are equal to one.
Then the following holds (Shen et al., 2016; Johnstone and Paul, 2018):
1.  When $\lambda_i > 1+\sqrt{\gamma}$,
    Let $\tilde{\lambda}_i$ be the $i$-th sample eigenvalue. Then
    (7.27)
    $$ \tilde{\lambda}_i \to \mu_i := \lambda_i \left(1 + \frac{\gamma}{\lambda_i-1}\right) \quad \text{a.s.} $$
    Because $\mu_i > \lambda_i$ (Equation 7.27), the limit, as $T \to \infty$, this is the same as
    (7.28)
    $$ \tilde{\lambda}_i \to \lambda_i \left(1 + \frac{\gamma}{\lambda_i-1}\right), \quad i=1, \dots, m $$
    The empirical eigenvalues are asymptotically unbiased for large values of $\lambda_i$.
    Let $\tilde{\mathbf{U}}_i$ denote the population (true) eigenvector and $\mathbf{U}_i$ the sample eigenvectors. Then, almost surely,
    (7.29)
    $$ |\langle \tilde{\mathbf{U}}_i, \mathbf{U}_i \rangle| \to \frac{1}{\sqrt{1+\frac{\gamma \lambda_i}{(\lambda_i-1)^2}}}, \quad i \le m $$
2.  When $\lambda_i \le 1+\sqrt{\gamma}$,
    $$ \tilde{\lambda}_i \to (1+\sqrt{\gamma})^2 \quad \text{in probability} $$
    $$ |\langle \tilde{\mathbf{U}}_i, \mathbf{U}_i \rangle| \to 0 \quad \text{a.s.} $$
Even if this strong result only holds asymptotically, it offers a few insights that can be verified experimentally. In addition, there are similar results that extend to the multiple spiked eigenvalue case, albeit with more assumptions. First, let us stress the insights:
1.  Under the spiked model assumptions, the spiked empirical eigenvalues are asymptotically upwardly biased. The bias is higher if $\lambda_i$ is closer to the ground eigenvalue; it becomes smaller when $\lambda_i$ gets bigger. This makes intuitive sense. When $\lambda_i$ is close to one, then the probability that the largest empirical eigenvalue is a “noise” ground eigenvalue becomes non-negligible. This brings us to the next insight.
2.  There is a critical threshold at $1+\sqrt{\gamma}$. For eigenvalues larger than $1+\sqrt{\gamma}$, it is possible to separate the largest eigenvalue from the spectrum. Indeed, the largest sample eigenvalue is further beyond $(1+\sqrt{\gamma})^2$. The separation is clearer still when $\lambda_i$ is large. The larger the first eigenvalue, the better the eigenvector’s collinearity.
Below the threshold, the largest eigenvalue, even if it is larger than $1$, cannot easily be identified from the data. The associated eigenvector is not consistently estimated.
In practice, for many applications, the number of assets in a model is in the interval $[10^3, 10^4]$, and the number of observations ranges between 250 and 1000, so that $\sqrt{\gamma}$ ranges between 1 and 2. This is a useful starting point to reason about thresholding eigenvalues, and their associated eigenvector.

**7.2.3 Optimal Shrinkage of Eigenvalues**

We know that the empirical eigenvalues are biased. This means that, should we evaluate portfolios in the subspace spanned by the spike eigenvectors, the predicted variance of the portfolios will be biased upward by $\tilde{\lambda}_i^2 / \lambda_i^2$. Let $\mathbf{w}$ be a unit-norm vector, and the portfolio be $\mathbf{w}^T \mathbf{U}_m$. Then the true variance is $\mathbf{w}^T \mathbf{S}_m^2 \mathbf{w} = \sum_{i=1}^m w_i^2 \lambda_i^2$, and the predicted variance is $\sum_{i=1}^m w_i^2 \tilde{\lambda}_i^2$. The problem is to estimate $\lambda_i^2$. From Equation (7.27), we could invert $\tilde{\lambda}_i = \lambda_i (1 + \gamma/(\lambda_i-1))$ and solve for $\lambda_i$. This is a quadratic equation, and we could insert $\tilde{\lambda}_i$ for $\lambda_i$ on the RHS. From Equation (7.27),
(7.30)
$$ \ell(\lambda) = \lambda_i - \gamma \frac{\lambda_i}{\lambda_i-1} \ge 1+\sqrt{\gamma} $$
For large values of $\lambda_i$, this is an offset of the empirical eigenvalues, like the one we saw in PCA, Equation (7.17). When we apply this to a diagonal $\mathbf{S}_m^2$ and $\mathbf{B} = \mathbf{U}_m \mathbf{S}_m^{1/2}$, we use the matrix $\mathbf{S}_m^2 - \bar{\lambda} \mathbf{I}_m$ (which is not diagonal). However, this is not necessarily the best choice. The shrinkage of eigenvalues has a long history. Donoho et al. (2018) characterize the optimal shrinking of eigenvalues for a large number of functions. Based on what we learned in Section 7.2.2, we only use a few of the largest eigenvalues. The optimal shrinkage formula (Equation (7.30)) is optimal for large values of $\lambda_i$. For small eigenvalues close to $1+\sqrt{\gamma}$, we shrink them proportionally more than the small values. The Ledoit-Wolf (2004) shrinkage method, which is a very popular method among practitioners: the Ledoit-Wolf shrinkage method starts with finding a matrix of the form
(7.31)
$$ \hat{\Sigma}_R = \rho_1 \hat{\Sigma} + \rho_2 \mathbf{I}_N $$
and identifying $\rho_1$ and $\rho_2$ so that $\hat{\Sigma}_R$ minimizes the distance reduced by the Frobenius norm from $\Sigma_R$.
(7.32)
$$ \min_{\rho_1, \rho_2} \| \Sigma_R - \rho_1 \hat{\Sigma} - \rho_2 \mathbf{I}_N \|_F^2 $$
The space of $m \times m$ matrices is a Hilbert space with scalar product $\langle \mathbf{A}, \mathbf{B} \rangle = \text{trace}(\mathbf{A}^T \mathbf{B})$.
The problem (7.32) is then just a special case of the well-known problem of minimum distance of a subspace to a point in a Hilbert space (Luenberger, 1969, Sec 3.8). They assume iid returns, finite fourth moments, and an asymptotic regime in which $N$ is constant and $T \to \infty$. They find that the optimal solution is of the form
(7.33)
$$ \hat{\Sigma}_R = (1-b^2) \hat{\Sigma} + b^2 \frac{\text{tr}(\hat{\Sigma})}{N} \mathbf{I}_N $$
This solution has many interpretations, aside from the geometric one that follows from the solution to Optimization Problem (7.32). While these interpretations may be of independent interest, I will devote some time to justify why this specific shrinkage is not necessarily optimal in our context. The main issue is that the Frobenius-norm-induced shrinkage will necessarily tend to identify the structure of the model, as shown in the previous chapter (Fan et al., 2008). Secondly, because the regime is $N$ fixed, $T$ diverging is not relevant to applications in which $N > T$ or $N \approx T$. Thirdly, because the constant that multiplies $\mathbf{I}_N$ is the average of the eigenvalues, it may be overly conservative. Lastly, because the eigenvalues of the largest matrix of the form $\lambda_i \mathbf{I}_N - \gamma (\lambda_i-1)^{-1}$ for the leading eigenvalues, this shrinkage model does not match the optimal asymptotic shrinkage of the spiked covariance model.

**7.2.4 EigenShrink: Eigenvalue versus Theory**

We now compare these theoretical results to simulations. We use the same setup as used for the PCA results in Figure 7.2, i.e., $m=10$ factors with standard deviations ranging between 1 and 10, uniformly spaced, and idiosyncratic standard deviations; 250 periods, and either 1000 or 2000 assets. In addition to the case of normal returns, I also consider the case of heavy-tailed returns. Specifically, both factor returns and idiosyncratic returns are t-distributed with five degrees of freedom. This choice is meant to simulate returns that have finite fourth moments, which is a reasonable assumption for daily asset returns.
We simulate 50 instances of each factor model. For each model, we compute the first 20 empirical top eigenvalues, and we shrink them using Equation (7.30) for $\ell(\lambda)$. The simulation (Figure 7.4) shows that the shrinkage function $\ell$ works well for normal returns, but not for heavy-tailed returns. In the latter case, it appears that a shrinkage proportional to the eigenvalue is a common factor. This is a different shrinkage than the ones of Equations (7.30) and (7.31), which are consistent in a constant offsetting term. Combining the empirical observations from simulated data, and theoretical results, it seems at least reasonable to consider a linear shrinkage
$$ \ell(\lambda) = K_1 \lambda - K_2 $$
$$ K_2 \ge \lambda_{min} $$
$$ K_1 \in (0,1] $$
when identifying $\lambda$.

[Image: Figure 7.4 (a) 1000 assets, normally distributed returns; (b) 1000 assets, t-distributed returns; (c) 2000 assets, normally distributed returns; (d) 2000 assets, t-distributed returns. The x-axis denotes the population eigenvalues. The y-axis denotes the shrunken empirical eigenvalues. The dashed line is the line y=x.]

**7.2.5 Choosing the Number of Factors**

In the example above, we assumed that the number of factors was known in advance. This is not the case with applications. An important component of the model definition procedure is the determination of the number of factors.[5] There are some criteria motivated by theoretical models, and others that are the outcome of experiments and trial-and-error by generations of practitioners. The theoretical models provide a lower bound on the number of factors, and we should preserve this number with a high confidence level. But, finding the right factors matters more than finding their exact number. By “right”, we mean the factor loadings with the “best performance”, and by performance, we mean one of many metrics introduced in Chapter 5. Because there are many metrics, and because the choice of the number of factors is a one-size-fits-all criterion. Second consideration, telling the exact number of factors is practice is either very easy or hopelessly hard. Under the assumptions of pervasive factors, we won’t need complex criteria. However, there is a wide gap between the situation eigenvalues and the true eigenvalues of returns. We need to use the eigenvalues that are not too noisy, gradually, and a hard rule is unlikely to choose the must threshold. A final consideration, which is both grounded in theory and in practice, is that one should err on the side of selecting more factors, rather than fewer. The cost of including an extra factor is that the model will choose some spurious noise that will increase true risk, which can result in a reduction in the Sharpe Ratio. The cost of choosing too many factors is a slight decrease in the Sharpe Ratio.
After these qualifications, let us review the most common methods.
*   **Threshold-Based Methods.** For matrices with ground eigenvalues equal to 1, the results of Section 7.2.2 suggest that we should select factor eigenvalues that exceed the threshold $1+\sqrt{\gamma}$, i.e.
    (7.34)
    $$ m = \max \{k | \tilde{\lambda}_k \ge 1+\sqrt{\gamma} \} $$
    An older method is the scree plot. This is the best-known method. In constructing the scree plot, we plot the eigenvalues against their rank. The largest eigenvalues dominate and decrease rapidly. To a value where the eigenvalues are small and decrease gradually, usually almost linearly. The method consists of choosing the last eigenvalue preceding this group. A variant of this method plots the logarithm of the eigenvalue:
    (7.35)
    $$ m = \underset{2 \le k \le K_{max}}{\arg \max} (\tilde{\lambda}_{k-1} - \tilde{\lambda}_k) $$
    (7.36)
    $$ m = \underset{2 \le k \le K_{max}}{\arg \max} (\log \tilde{\lambda}_{k-1} - \log \tilde{\lambda}_k) $$
    where $K_{max}$ is a threshold chosen iteratively (Onatski, 2010).
*   **Penalty-Based Methods.** We began the chapter with the problem of minimizing the square residual error (Equation 7.2). We can select the number of factors by adding a penalty term, and by making it a function of the data and factor numbers.
    (7.37)
    $$ \min_{k: \text{rank}(\hat{\mathbf{R}}) \le k} \| \mathbf{R} - \hat{\mathbf{R}} \|_F^2 + k f(N,T) $$
    (7.38)
    $$ f(N,T) = \frac{N+T}{NT} \log \left( \frac{NT}{N+T} \right) $$

---

**7.3 Real-Life Stylized Behavior of PCA**

We now explore a real-life dataset with the goal of comparing the observed behavior of principal components and eigenvalues to the ideal spiked covariance model. We employ daily stock total returns belonging to the Russell 3000 index for the period 2003-2017. Assets that are included in this index must satisfy some essential requirements. As of 2022, on a designated day in May (“rank day”), Russell evaluates eligible U.S. securities. The stocks must trade on eligible U.S. exchanges. Among them, the 4,000 largest (by market capitalization) become members of the Russell 3000E Index. The smallest 1% of the stocks are excluded. The largest 3,000 stocks become the Russell 3000 Index. The market capitalization must exceed $30M, and the percentage of float (shares traded on exchange) must exceed 5%. The data is adjusted for stock splits, dividends, name changes, governance measures, and corporate structure issues. We use the closing price of each stock. Out of the eligible set, Russell assigns to an index the 3000 stocks with the highest market cap, and effectively changes the composition of the index on the fourth Friday of June. These criteria ensure that the asset characteristics are sufficiently homogeneous. Besides the geography, revenue source, and corporate governance and that the universe of assets is based on daily closing price. Based on stock price and market capitalization.[12]

**7.3.1 Concentration of Eigenvalues**

For our exploration, we consider Principal Components based on three types of returns. First, stock total returns. This is the simplest approach. Secondly, we normalize returns by dividing them by their predicted idiosyncratic volatilities. The benefits of this approach are discussed in the previous sections: the idiosyncratic volatilities of the normalized returns are closer to one. The eigenvalues of the normalized returns should be greater than one. Lastly, we normalize returns to their empirical total volatilities. The rationale for this choice is that we study the properties of the empirical correlation matrix. It has less reasonable than the previous one. Come what may, for our purposes, it is useful to compare the results. The resulting covariance matrix is the sample correlation matrix. We use the procedure in Bai and Ng (2002) and Ahn and Horenstein (2013) to estimate the number of factors. We use one full year of return data, for eight non-overlapping years. When we normalize by idiosyncratic volatilities, we use the data provided by a major U.S. model (Axioma US4). Since the idiosyncratic volatility estimation process takes time, in the chapter, we did not wait any further to show some empirical data. I will show later that the statistical model idiosyncratic volatilities are indeed quite close to those of a commercial model, via this illustrative example, is in fact quite close to a self-contained analysis.

The raw returns are winsorized at daily returns of [-30%, +30%], and the z-scored returns at returns of [-10, +10], i.e., plus or minus ten standard deviations. The idiosyncratic volatilities are winsorized at [0.1, 1.0]. The choice of the first two is not critical. These features are common. The first one is that there is no obvious gap between the variances. The second is that there is a consistent ranking between the spectra of the three covariance matrices. The plot shows the ratio of the variance of lower-order factors to that of the first factor. The standard deviation of the factor returns is higher for the raw returns covariance matrix, followed by the return/volatility covariance matrix, and lastly by the covariance matrix of total returns.

[Image: Figure 7.5: Variances of the eigenvalues (normalized to the variance of the first) for the first 40 factors. Note that the scale of the y-axis is logarithmic.]

This suggests that the first few eigenvectors explain a larger percentage of total variance of the associated covariance matrix. This is confirmed by Figure 7.6. Figure 7.6 plots the cumulative percentage of variance explained by the first 40 factors. For the period ending on June 30, 2008, the first factor explains 30% of the variance of asset returns. For the period ending on June 30, 2011, we need 30 factors for the raw covariance matrix, 15 factors for the z-scored returns, using total volatility, and only 10 factors for the z-scored returns, using idiosyncratic volatility. This suggests that the last choice is preferable. This metric, nonetheless, it suggests that, in this specific instance a model built on a transformed sequence of returns is more parsimonious.

[Image: Figure 7.6: Cumulative percentage of variance described by the first m factors, for difference covariance matrices.]

**7.3.2 Controlling the Turnover of Eigenvectors**

So far, we have focused on the properties of the eigenvalues. Eigenvectors exhibit a distinctive behavior as well. One important property of eigenvectors is their turnover. The turnover for two consecutive portfolios $\mathbf{v}(t-1), \mathbf{v}(t)$ is usually measured as the Gross Market Value (GMV), traded as a percentage of the GMV of the portfolio.
(7.39)
$$ \text{Turnover}_t(\mathbf{v}(t)) := \|\mathbf{v}(t) - \mathbf{v}(t-1)\|_1 $$
Alternatively, one can use as definition the square of the gross national.
(7.40)
$$ \text{Turnover}_t^2(\mathbf{v}(t)) := \|\mathbf{v}(t) - \mathbf{v}(t-1)\|_2^2 $$
There are good reasons for this. The first one is that the squared GMV is a fairly good approximation to the transaction costs associated to trading the factor portfolio. A second one is analytical tractability and an associated geometric intuition for eigenportfolios, recall that $\|\mathbf{v}(t)\|=1$, and that the numerator $\|\mathbf{v}(t) - \mathbf{v}(t-1)\|_2^2$ is
$$ 2(1 - \mathbf{v}^T(t) \mathbf{v}(t-1)) $$
The quadratic turnover is therefore related to the cosine similarity. Low turnover eigenportfolios thus have high cosine similarity.
(7.41)
$$ \text{Turnover}_t(\mathbf{v}(t)) = 2(1 - |S_c(\mathbf{v}(t), \mathbf{v}(t-1))|) $$
In the equation above we use the absolute value of $S_c$ because the eigenvectors are identified modulo the sign of the vector. In other terms, if
$$ S_c(\mathbf{v}(t), \mathbf{v}(t-1)) < 0 $$
, we flip the sign of $\mathbf{v}(t)$ in order to have a lower turnover of eigenvectors.
In Figure 7.7 we show the absolute value of the cosine distances over time for the first eight eigenvectors of our three sequences of covariance matrices computed on raw total returns, raw returns normalized by total volatility, and raw returns normalized by idiosyncratic volatility. In all three cases, we show the total distance between consecutive eigenvectors, computed on the first eight eigenvectors and in Figure 7.7 we show the cumulative returns in the three approaches. The covariance matrix on a given date is computed using the trailing 252 trading days of returns. The number of assets from one day to the next can change slightly. The turnover of the eigenvectors is, on average, low. The charts in Figure 7.7 show that the first eigenvector is associated to an eigenvalue that has a large gap from the second largest eigenvalue (see Figure 7.5). As a result, the PCA procedure has no issue in identifying it and its weights are very stable throughout the estimation period. This is termed a “market” profile. The turnover of the remaining eigenvectors is higher. The turnover of the eigenvectors for the (non-normalized) total returns. There are occasional spikes; for example, there are large spikes occurring on October 3, 2008, and November 20, 2009. The second one is so big that the eigenvectors in consecutive periods are almost orthogonal. What is happening? The market is in turmoil, and immediately before and immediately after the crisis, the eigenvectors change dramatically to a single, stable, but clearly different equilibrium. And this behavior qualitatively repeats across covariance matrices and eigenvectors. This is not an isolated event. In fact, there are more such spikes, but transformed and mild. Another qualitative phenomenon is that, as of February 15, 2008, eigenvalues, standardizing returns seems to reduce turnover and incidence of spikes, more so for idiosyncratic volatility normalization. For example, in the latter case, Figure 7.7 has a cleaner structure and less noise. This is only one of the cases. This lack of eigenvalue separation. When eigenvalues are close, the addition and removal of one or two assets in the estimation universe, is sufficient to affect the number of factors. The instability of the eigenvectors is then due to the instability of the number of factors. Within the change of factors, the eigenvectors change, the subperiod spanned by these eigenvectors may in fact be stable. In Figure 7.7, we show the turnover for the three cases above.[14] When the eigenvalues are small (being just “noise”), for three return vectors, and are smaller for idiosyncratic volatility z-scored returns. This does confirm yet again that statistical models built on normalized return sequences are more stable, suggesting that the eigenvalues of such models are better separated from each other.

[Image: Figure 7.7: Eigenvector turnover for different covariance matrices. Top: total returns; Middle: total returns/total vol; Bottom: total returns/idio vol.]

[Image: Figure 7.8: Distances between columns subspaces of the first eight eigenvectors in consecutive periods. The eigenvectors are generated by PCA on total returns, total returns/total vol, and total returns/idio vol.]

[Image: Figure 7.9: $L_2$ factor turnover for the first four eigenvectors. The eigenvectors are generated by PCA on total returns, total returns/total vol, and total returns/idio vol.]

Aside from the quality of the PCA for different choices of covariance matrices, we are faced with an inescapable issue in statistical models. Except for a few high-order factors and variances, most factors in statistical models suffer from a kind of indeterminacy. In consecutive periods, PCA may give us very different loading vectors, although the subspace spanned by these factors are often in reality very close. This is not a new problem. In the next section, we show that, even if this loadings can change a lot from one period to the next, the covariance matrix does not change. This means that a portfolio’s volatility prediction does not depend on the orientation of the factor loadings, and therefore that any portfolio optimization is also independent of it. This is good news. The bad news is that its factor exposures are also independent of it, which means that it is hard to assess the portfolio volatility, or combined factor volatility of the degenerate factors (i.e., factors with identical volatilities). In integrated fundamental/statistical models the consistency of loadings is not always the first thing that comes to mind. Table 7.1 summarizes the impact of the characteristics of the fundamental factors. Table 7.1 summarizes its specific applications.

**TABLE 7.1**
Summary of impact of High Factor Turnover

|                                       | Impact of High Factor Turnover |
| :------------------------------------ | :----------------------------- |
| Volatility Estimation                 | Not important                  |
| Portfolio Optimization/Hedging        | Not important                  |
| Integrated Stat./Fund. Models         | Not important                  |
| Performance Attribution               | Very high                      |

Essentially only single-factor performance attribution is made irrelevant by eigenvalue quasi-degeneracy. However, single-factor attribution depends on factor turnover. Since most statistical models are affected by rotations, we can always perform a rotation that minimizes the distance between eigenvectors in consecutive periods; this is a per-asset operation. In other words, if we have a sequence of loading matrices $\mathbf{B}_t$, we aim for new “rotated” loadings $\tilde{\mathbf{B}}_t$ that have low turnover.[15]:
(7.42)
$$ \tilde{\mathbf{B}}_{t+1} = \underset{\mathbf{X} \in \mathbb{R}^{N \times m}}{\arg \min} \| \mathbf{B}_t - \mathbf{Y} \mathbf{X} \|_F^2 $$
$$ \text{s.t. } \mathbf{Y} = \mathbf{B}_{t+1} \mathbf{X} $$
$$ \mathbf{X}^T \mathbf{X} = \mathbf{I}_m $$
First, we prove that the objective is equivalent to maximizing $\langle \mathbf{A}, \mathbf{X} \rangle$, with $\mathbf{A} = \mathbf{B}_t^T \mathbf{B}_{t+1}$. This follows from the sequence of identities
$$ \|\mathbf{B}_t - \mathbf{B}_{t+1} \mathbf{X}\|_F^2 = \text{trace}((\mathbf{B}_t - \mathbf{B}_{t+1} \mathbf{X})^T (\mathbf{B}_t - \mathbf{B}_{t+1} \mathbf{X})) $$
$$ = \text{trace}(\mathbf{B}_t^T \mathbf{B}_t) + \text{trace}((\mathbf{B}_{t+1} \mathbf{X})^T (\mathbf{B}_{t+1} \mathbf{X})) - 2 \text{trace}(\mathbf{B}_t^T \mathbf{B}_{t+1} \mathbf{X}) $$
$$ = \text{trace}(\mathbf{B}_t^T \mathbf{B}_t) + \text{trace}(\mathbf{X}^T \mathbf{B}_{t+1}^T \mathbf{B}_{t+1} \mathbf{X}) - 2 \text{trace}(\mathbf{A}\mathbf{X}) $$
The last equality follows from the orthonormality of $\mathbf{B}_{t+1} \mathbf{X}$. Let the SVD of $\mathbf{A} = \mathbf{U} \mathbf{S} \mathbf{V}^T$. Since $\mathbf{X}^T \mathbf{X} = \mathbf{I}_m$, the matrix $\mathbf{X}$ is orthonormal. It follows directly $\mathbf{Y} = \mathbf{V} \mathbf{U}^T \mathbf{X} = \mathbf{V} \mathbf{U}^T$. We replace these expressions in the objective function:
$$ \max_{\mathbf{X}} \text{trace}(\mathbf{A}\mathbf{X}) = \max_{\mathbf{X}} \text{trace}(\mathbf{S}\mathbf{Y}) = \sum_i s_i [\mathbf{a}_i \mathbf{A}^T]_{i,i} $$
which is maximized when $\mathbf{Y} = \mathbf{I}_m$, and so the solution is $\mathbf{X} = \mathbf{V} \mathbf{U}^T$.
Now for the last step. Unitary matrices have all eigenvalues equal to ones and orthogonal eigenvectors $\mathbf{u}_i$. The eigendecomposition of $\mathbf{Y}^T \mathbf{Y} = \mathbf{I}_m$, and the objective function is

---

**7.4 Interpreting Principal Components**

One criticism often leveled against PCA is that its loadings are not easy to interpret. The goal of this chapter is to partially dispel this myth. The output of PCA is interpretable, and in fact sometimes it provides additional non-trivial perspectives for the user.

**7.4.1 The Clustering View**

The first avenue of interpretation is to do no transformation at all. The principal components are uniquely determined up to a change of sign: if $\mathbf{u}_k$ is an eigenvector associated to eigenvalue $\lambda_k$, so is $-\mathbf{u}_k$. We show that their loadings can be interpreted as a clustering membership index (Ding and He, 2004). In order to retain this approach, we partition our $N$ assets into $K$ clusters, each characterized by a set membership $C_k$ and centroids
$$ \mathbf{m}_k = \sum_{i \in C_k} \mathbf{r}_i / |C_k| $$
The number of clusters $K < N$ is unknown. The cluster membership is found by minimizing the sum of squared distances from the centroids:
(7.43)
$$ \min_{C_k, \mathbf{m}_k} \sum_{k=1}^K \sum_{i \in C_k} \| \mathbf{r}_i - \mathbf{m}_k \|^2 $$
(7.44)
$$ \text{s.t. } \mathbf{m}_k = \sum_{i \in C_k} \mathbf{r}_i / |C_k| $$
(7.45)
$$ C_j \cap C_l = \emptyset, \quad i \ne j $$
(7.46)
$$ \bigcup_{k=1}^K C_k = \{1, \dots, N\} $$
We rewrite the objective function as
(7.47)
$$ \sum_{k=1}^K \sum_{i \in C_k} (\mathbf{r}_i - \mathbf{m}_k)^T (\mathbf{r}_i - \mathbf{m}_k) = \sum_{k=1}^K \sum_{i \in C_k} \mathbf{r}_i^T \mathbf{r}_i - \sum_{k=1}^K |C_k| \mathbf{m}_k^T \mathbf{m}_k $$
$$ = \sum_{i=1}^N \mathbf{r}_i^T \mathbf{r}_i - \sum_{k=1}^K \frac{1}{|C_k|} \left( \sum_{i \in C_k} \mathbf{r}_i \right)^T \left( \sum_{j \in C_k} \mathbf{r}_j \right) $$
The first sum is a constant and does not affect the optimization problem. We could represent cluster membership algebraically: let $h_{ik} \in \mathbb{R}$ and define $H_{ik} = 1 / \sqrt{|C_k|}$ if asset $i$ is in cluster $C_k$, zero otherwise. Because an asset must belong to exactly one cluster, $H$ is a column of ones. Define $\mathbf{H} = (h_1, \dots, h_K) \in \mathbb{R}^{N \times K}$.
Let
$$ \mathbf{g} = (\sqrt{|C_1|}\mathbf{m}_1, \dots, \sqrt{|C_K|}\mathbf{m}_K) $$
The condition that each asset belongs to precisely one cluster can be expressed as $\mathbf{H}\mathbf{g} = \mathbf{1}_N$. Therefore, to solve $K$-clustering problem, we need to solve
(7.48)
$$ \max_{\mathbf{H}, \mathbf{g}} \text{trace}(\mathbf{H}^T \mathbf{R} \mathbf{R}^T \mathbf{H}) $$
(7.49)
$$ \text{s.t. } \mathbf{H}_{ik} \in \{0, |C_k|^{-1/2}\} $$
Notice that the columns of $\mathbf{H}$ have unit norm and are orthogonal. Then it is natural to relax the discrete requirements on $\mathbf{H}$ and to solve
(7.50)
$$ \max_{\mathbf{H}} \text{trace}(\mathbf{H}^T \mathbf{R} \mathbf{R}^T \mathbf{H}) $$
This is the same formulation as the optimization version of the uncentered PCA, Equation (7.11). The interpretation of the loadings can then be one of approximate cluster membership. The simplest case is when we cluster on the first principal component. We can separate into two clusters based on some threshold on the loadings. The distribution of the loadings distribution will suggest an appropriate cut-off point. When inspecting multiple eigenvectors, a multivariate clustering algorithm will help identify groups.

**7.4.2 The Regression View**

Another way to interpret the loadings of a statistical model is to represent them as sums of vectors, whose weights are intuitive. Qualitatively we proceed as follows. First, assume meaningful stock characteristics for a given date. We fit a linear regression of the loadings on these characteristics. Then, we interpret the coefficients of the regression. We are left with residuals, which we interpret as the portion of the loadings that is not explained by the characteristics. The statistical model. We regress $\mathbf{B}_{i \cdot}$ on the columns of $\mathbf{G}_i$ and denote the regression coefficients $\beta^{(k)}$. In formulas, $\mathbf{B}_{i \cdot} = \mathbf{G}_i \beta^{(k)} + \mathbf{e}_i^{(k)}$, where $\mathbf{e}_i^{(k)}$ is a vector of residuals. We are interested in the subspace of $\mathbf{G}_i$. If we are not happy with a set of characteristics, then the regression may not explain much of the variance of the loadings. The approach is, of course, not restricted to statistical models; we could apply this regression approach to any pair of risk models, to interpret one based on information contained in the other.
As a (very simplified) example, we consider a model built on U.S. asset returns normalized by idio vol, for the date of July 6, 2017. In order to gain intuition about the loadings, we regress them against style loadings only; we use the same ARS(4) as in these loadings. In Table 7.2 and 7.3, we report only the most significant loadings.

**TABLE 7.2**
Regression coefficients for the first principal component

| Term                  | Estimate | Std.Error | t value | Pr(>|t|) |
| :-------------------- | :------- | :-------- | :------ | :------ |
| (Intercept)           | 1.7E-01  | 1.9E-02   | 9.1E+00 | <2e-16  |
| Dividend Yield        | -2.4E-01 | 1.9E-02   | -1.3E+01| <2e-16  |
| Volatility            | 2.4E-01  | 1.9E-02   | 1.3E+01 | <2e-16  |
| Short Term Momentum   | 2.5E-01  | 1.9E-02   | 1.4E+01 | <2e-16  |
| Long Term Momentum    | 1.3E-01  | 1.9E-02   | 7.0E+00 | 2.8E-12 |
| Earnings Yield        | 3.7E-01  | 1.9E-02   | 1.9E+01 | <2e-16  |

**TABLE 7.3**
Regression coefficients for the second principal component

| Term                  | Estimate | Std.Error | t value | Pr(>|t|) |
| :-------------------- | :------- | :-------- | :------ | :------ |
| (Intercept)           | -2.5E-01 | 1.9E-02   | -1.3E+01| <2e-16  |
| Dividend Yield        | 2.1E-01  | 1.9E-02   | 1.1E+01 | <2e-16  |
| Volatility            | -1.7E-01 | 1.9E-02   | -9.0E+00| <2e-16  |
| Short Term Momentum   | -2.0E-01 | 1.9E-02   | -1.0E+01| <2e-16  |
| Long Term Momentum    | 3.3E-01  | 1.9E-02   | 1.8E+01 | <2e-16  |
| Size                  | -1.8E-01 | 1.9E-02   | -9.3E+01| <2e-16  |

The first principal component is overwhelmingly explained by the market factor. Like the factor attribution of returns, this is usually the case. The most important explanatory variables are Value factor (Dividend Yield), Size, and (with negative coefficient) Short-Term Momentum. The opposite signs for value and momentum are consistent with experience, since the returns of these factors are usually negatively correlated. Size and Earnings Yield loadings are usually positively correlated, the reason being that large caps are likely to pay higher dividends—or dividends at all—than small caps. For this specific date, the correlation is 0.32. The first factor can be interpreted as a “risk-on” factor, where as the second factor can be interpreted as a defensive, or “risk-off” factor.

---

**7.5 Statistical Model Estimation in Practice**

So far, we have only presented the theory of statistical factor models. The next two sections discuss the issues related to its implementation. PCA is usually quite robust (or gentle) that do not have a time dimension. In contrast, we deal with temporal data, and we cannot assume that these data are drawn in each period from the same probability distribution. We will employ the PCA and SVD toolkits, i.e., at most in ways that do not presuppose that the data are approximately stationary. The next two sections discuss two adaptations that are common in practice and compare their performance on historical U.S. equity data.

**7.5.1 Weighted and Two-Stage PCA**

A recurring theme in factor estimation is that weighting observations differently helps. Observations in the distant past are less informative than recent ones; observations of stocks with high idiosyncratic risk should be downweighted compared to those of low-idio stocks. There are therefore two basic transformations that we can apply to the raw return matrix. The first one is time-weighting. We assign to each observation a weight $w_t$ that is a decreasing function of time. Let $W_t = \text{diag}(w_1, \dots, w_T)$ be a diagonal matrix. The weights could be, for example, exponential weights
$$ W_{t,t} = \kappa \exp(-t/\tau) $$
; the positive constant $\kappa$ is such that the squared diagonal terms sum to $T$. Then the time-weighted empirical uncentered covariance matrix is
(7.51) $ \tilde{\Omega}_R = \frac{1}{T} \mathbf{R} W_t \mathbf{R}^T $
This is the same as first transforming the returns $\tilde{\mathbf{R}} = \mathbf{R} W_t^{1/2}$, and then computing the empirical covariance matrix, Equation (7.8), of the transformed returns. In practice, we would not compute the covariance matrix and then perform the PCA, but rather perform the SVD on $\tilde{\mathbf{R}}$, which would be computationally less expensive and give us the same results.
A different type of transformation is cross-sectional reweighting. In Chapter 4 we used it as optimal to returns by the idiosyncratic volatility, at least as a proxy. As with time-weighting, we can apply the transformation first. Take the first $m$ principal components (say, $m=5$) and compute the idiosyncratic returns $\mathbf{E} = \mathbf{R} - \mathbf{B} \mathbf{F}^T$. A case we also consider is $m=0$, in which case $\mathbf{E}=\mathbf{R}$. Define the cross-sectional weights $W_c = \text{diag}(\sigma_1^{-1}, \dots, \sigma_N^{-1})$.
The asset-level reweighted covariance matrix is
(7.52)
$$ \hat{\Sigma} = W_c \mathbf{R} \mathbf{R}^T W_c $$
One can then perform a second-stage factor model on the reweighted covariance matrix.
(7.53)
$$ \tilde{\Sigma} \approx U_m S_m^2 U_m^T + I_N $$
Finally, pre- and post-multiply by the idiosyncratic weighting matrices $W_c^{-1}$.
We employ the steps above in the following process. We use two time-series reweightings with half-life $T_{1/2}$ of 63 for “fast” and $T_{1/2}$ of 252 for “slow”. An empirical insight in asset return data is that volatilities and correlations change over different timescales. Volatilities change rapidly, in fact they may change drastically over the course of a few days. The ratio between volatility during a quiet period and volatility during a quiet period. On the other side, pairwise correlations are quite stable. Even in the presence of large market stresses, these correlations marginally increase in absolute value. This suggests that we separate volatilities and correlations. Therefore, in the second stage we use a short half-life to estimate the idiosyncratic volatilities. In the second stage we use a longer half-life to estimate the factor structure of correlations.

**Procedure 7.1: Statistical model estimation**
1.  Inputs: $\mathbf{R} \in \mathbb{R}^{N \times T}$, $T_{1/2}^{(1)}, T_{1/2}^{(2)}$, $0 < p < N$
    $m > 0$
2.  Time-Series Reweighting
    $W_{t,t}^{(1)} := \kappa \text{diag}(\exp(-T/T_{1/2}^{(1)}), \dots, \exp(-1/T_{1/2}^{(1)}))$
    $\tilde{\mathbf{R}} = \mathbf{R} W_t^{(1)}$
3.  First Stage PCA: $\tilde{\mathbf{R}} = \mathbf{U} \mathbf{S} \mathbf{V}^T$
    Idio Proxy Estimation:
    $\mathbf{E}_t = \mathbf{U}_{m+1 \dots p} \mathbf{S}_{m+1 \dots p} \mathbf{V}_{m+1 \dots p}^T$ (truncated SVD)
    $\hat{\sigma}_i^2 = \frac{1}{T} \sum_{t=1}^T E_{it}^2$ (idio var proxies)
4.  $W_c = \text{diag}(\hat{\sigma}_1^{-1}, \dots, \hat{\sigma}_N^{-1})$
    Idio Reweighting:
    $\mathbf{R}_{idio} := W_c \mathbf{R}$
    $W_{t,t}^{(2)} := \kappa \text{diag}(\exp(-T/T_{1/2}^{(2)}), \dots, \exp(-1/T_{1/2}^{(2)}))$
    $\tilde{\mathbf{R}}_{idio} = \mathbf{R}_{idio} W_t^{(2)}$
5.  Second Stage PCA: $\tilde{\mathbf{R}}_{idio} = \mathbf{U}_{idio} \mathbf{S}_{idio} \mathbf{V}_{idio}^T$
    where: $\mathbf{F} = (\mathbf{B}_{idio}^T \mathbf{W}_c^{-1} \mathbf{B}_{idio})^{-1} \mathbf{B}_{idio}^T \mathbf{W}_c^{-1} \mathbf{R}_{idio} \mathbf{W}_t^{(2)} \mathbf{F}_{idio}$
    (7.54) $\mathbf{B}_{idio} = \mathbf{U}_{idio, m}$
    (7.55) $\mathbf{F}_{idio} = \mathbf{S}_{idio, m} \mathbf{V}_{idio, m}^T$
    We need to address some outstanding problems:
    1.  Sign indeterminacy of eigenvectors.
    2.  Time-varying universe of assets.
    3.  Imputation of loadings for non-estimation universe assets.
    4.  Imputation of missing values for new or temporarily non-traded assets.
    We tackle them in order.
    Sign indeterminacy of eigenvectors. Let us begin with a simple observation: the sign of an eigenvector is arbitrary. If $\mathbf{u}$ is an eigenvector of $\Sigma$ with associated eigenvalue $\lambda$, then so is $-\mathbf{u}$. When we compare the SVD for adjacent periods, we will remove observations, which may lead to a sign flip in the factors. It is important therefore that the loadings of an eigenvector (or factor) in adjacent periods is positive. Aside from the straightforward re-alignment exercise, the turnover of eigenvectors is important in two respects. First, because I observe that
    $$ S_c(\mathbf{u}^T(t), \mathbf{u}^T(t+1)) \approx 0 $$
    It is difficult to determine the sign of consecutive eigenvalues.
    As a result, it is difficult to determine the sign of the factor return $f_t(t)$. This is not a problem for volatility estimation, but it is for any statistical factor model where the sign of the factor return $f_t(t)$ has to be consistent. The second consideration is that very high turnover results in factor-mimicking portfolios with very high turnover as well, and is therefore a factor that is very difficult to trade, either for hedging or for alpha generation.
    Non-estimation universe. Similarly to fundamental models, statistical models are estimated on a predetermined set of assets. The rationale for the choice of such a universe is the same as for fundamental models. Assets in the estimation universe should represent most of the market capitalization of the total strategy. They should be sufficiently liquid to be considered tradable; and, ideally, they should be sufficiently traded to ensure good price discovery and therefore reliable return calculations. Assets enter and leave the universe over time. The number of assets in the estimation universe may be constant or variable. The treatment of additions to the index may be unreliable because the asset was illiquid, or be missing altogether. We can still opt to keep these recent additions, provided that their returns are well defined, or alternatively we can use the assets of the estimation universe of all the common stocks used for the regression. If the universe turnover is not too high, we will still have a sufficiently broad panel of assets. It is preferable to employ an estimation universe that has the lowest possible turnover, and it is important to use a consistent procedure to select the assets to include in the return matrix $\tilde{\mathbf{R}}$.
    Imputing loadings for non-estimation universe assets. There are assets that are not in the estimation universe, but that have complete returns. They do not have factor loadings. We can impute loadings by performing a cross-sectional regression of asset returns on the factor returns. This approach is justified by the results in Section 7.1.3: we can recover loadings from time-series regression, provided that the factor returns are obtained using the estimation universe are close to the true factor returns.
    Imputation of missing values for new or temporarily non-traded assets. Some assets do not have sufficient return history to regress their loadings: examples are newly listed assets (IPOs, ADRs), or assets that were suspended from trading for a long period of time, or had trading volumes suspended over too low to be considered reliable. We can impute its loadings to use additional characteristics of the asset to estimate its loadings. The approach is similar to the one we presented in Section 7.4.2 on the interpretation of loadings using regression. In this case, however, our quantity we are interested in is the loading to impute. We use the style characteristics (Momentum, Value, Volatility). All we have is knowledge of the industry and country of the asset. We regress observed loadings against these two characteristics, and predict the missing loading. It is common practice to remove predicted values that are too small. We will cover a rationale for this practice in later sections devoted to hedging.

3.  Second Stage Factor Model: $\mathbf{Y}_t = \mathbf{U}_{idio} \mathbf{F}_{idio,t} + \mathbf{\epsilon}_t$
    where: $\mathbf{F}_{idio,t} \sim N(0, \text{diag}(\lambda_1^{(idio)}, \dots, \lambda_m^{(idio)}))$
    $\bar{\lambda} = \frac{1}{N-m} \sum_{i=m+1}^N \lambda_i^{(idio)}$
    $\mathbf{\epsilon}_t \sim N(0, \bar{\lambda} \mathbf{I}_N)$
4.  Output: Final Factor Model $\mathbf{Y}_t = \mathbf{B} \mathbf{F}_t + \mathbf{\epsilon}_t$
    where $\mathbf{B} = W_c^{-1} \mathbf{U}_{idio,m}$
    $\mathbf{F}_t \sim N(0, \text{diag}(\lambda_1^{(idio)}, \dots, \lambda_m^{(idio)}))$
    $\mathbf{\epsilon}_t \sim N(0, \bar{\lambda} W_c^{-2})$
This procedure is flexible enough to include several PCA-related procedures as special cases, and to serve as a basis for further experimentation. Some examples:
*   When $m=0$, then idio reweighting becomes a z-scoring, so that the second-stage PCA is effectively applied to the correlation matrix.
*   The optimal use of Equation (7.52) in time is obtained in the single factor model step.
*   It is straightforward to use different shrinkage methods in the second-stage factor model step.
*   In the second-stage factor model step, we use the PPCA results of Section 7.1.2. We can also use these results to estimate their idiosyncratic covariance matrix, and then their covariance, so that their principles. However, we could replace this with a different estimation procedure, like Maximum Likelihood.

**7.5.2 Implementing Statistical Models in Production**

It is not sufficient to have a procedure that estimates the loadings and the covariance matrix at a point in time. In our applications, factor models are dynamic. At time $t$, we have an estimation universe of stocks, and we use return data up to $T_{max}$ periods in the past. We apply the two-stage PCA using return data between $t-T_{max}$ and $t$, to obtain:
*   Loadings $\mathbf{B}_t$. This is the output loadings matrix.
*   Factor returns and estimate returns at time $t$.
(7.55)

---

**7.6 Appendix**

**7.6.1 Exercises and Extensions to PCA**

**Exercise 7.1 (Low-Rank Factorization):**
Prove that a matrix $A \in \mathbb{R}^{m \times n}$ of rank $r \le \min(m,n)$ if and only if it can be decomposed into the product of two matrices $B \in \mathbb{R}^{m \times r}$ and $C \in \mathbb{R}^{r \times n}$.

**Exercise 7.2 (PCA Solution):**
Prove that the solution $\mathbf{w}^*$ to Problems (7.7) and (7.10) is unique and that constraint $\|\mathbf{w}^*\| \le 1$ is always binding, i.e., $\|\mathbf{w}^*\|=1$.

**Exercise 7.3 (Alternative PCA Formulation):**
Prove that the optimization (7.11) gives the same solution as finding the first $m$ eigenvectors of $\Sigma$, and as finding iteratively $k=1, \dots, m$ vectors $\mathbf{w}_k$ that maximize $\mathbf{w}_k^T \Sigma \mathbf{w}_k$ orthogonal to the first $k-1$ vectors, $\mathbf{w}_1, \dots, \mathbf{w}_{k-1}$.

**Exercise 7.4 (Covariance Matrix of a Linear Transformation):**
Prove that if the random vector $\mathbf{x}$ taking values in $\mathbb{R}^n$ has covariance matrix $\Sigma_x$, and if $A \in \mathbb{R}^{m \times n}$, then the random vector $A\mathbf{x}$ has covariance matrix $A \Sigma_x A^T$.

**Exercise 7.5 (A Simple Spiked Matrix):**
Let $B \in \mathbb{R}^{N \times m}$ be an $m$-rank matrix. Prove that the first $m$ eigenvalues of $BB^T + \sigma^2 I_N$ are greater than $\sigma^2$.

**Exercise 7.6:**
Solve the optimization problem Equation (7.1).

**Exercise 7.7 (The Power Method):**
A simple (the simplest) algorithm for computing the largest eigenvalue of a symmetric $A \in \mathbb{R}^{N \times N}$ is the power method.
1.  Start with a unit-norm $\mathbf{x}_0 \in \mathbb{R}^N$, chosen randomly (e.g., sampling from the standard normal distribution, then normalize it).
2.  Iterate: $\mathbf{x}_{k+1} = A \mathbf{x}_k / \|A \mathbf{x}_k\|$.
3.  After the vector converges (say, $\|\mathbf{x}_{k+1} - \mathbf{x}_k\| < \epsilon_{tol}$), approximate the top eigenvector, and $\tilde{\lambda}_N$ the top eigenvalue.
    (Hint:
    $$ \tilde{\lambda}_N = \mathbf{x}_k^T A \mathbf{x}_k = \sum_{i=1}^N \lambda_i (\mathbf{x}_k^T \mathbf{u}_i)^2 $$
    )
Prove the convergence and correctness of the power method. (Hint:
$$ \mathbf{x}_k = \sum_{i=1}^N c_i \mathbf{u}_i \implies A^k \mathbf{x}_0 = \sum_{i=1}^N c_i \lambda_i^k \mathbf{u}_i $$
)

**Exercise 7.8 (Iterations for the SVD):**
A simple (the simplest?) algorithm for computing the largest singular value of a matrix $R \in \mathbb{R}^{N \times T}$ is the following:
1.  Start with $v_0 \in \mathbb{R}^T$. Chosen at random (e.g., sample the coordinates from a standard normal distribution).
2.  Iterate
    (7.56) (i) $u_{k+1} = R v_k$
    (7.57) (ii) $v_{k+1} = R^T u_{k+1}$
3.  After the vectors converge, $s_N = \|u_{k+1}\|$, approximates the highest left eigenvector, $v_{k+1}$ the higher right eigenvector, and $s_N^2 / \|v_{k+1}\|^2$, the top singular value.
Prove the convergence and correctness of the algorithm. (Hint: power method.)
(Hint: How would you extend to find all the eigenvalues of $R^T R$? The same way as you would extend the power method.)

**Exercise 7.9 (Time-Series Regression from the SVD):**
Let $R = U S V^T$, and set $F = V_m S_m$. The vector $\hat{\beta}$ of regression coefficients of the time series of the $n$-th factor return is the $n$-th row of $F$. Prove that the least-squares regression coefficient of the time series of returns on $U_m$ is $U_m$.

**Exercise 7.10 (QR Iterative Algorithm):**
Let $A \in \mathbb{R}^{N \times N}$ be a time series of returns drawn from a common distribution with covariance matrix $\Sigma$. Prove that the following algorithm converges to the first $k$ eigenvalues of $\Sigma$.
1.  Set $j=0$. Choose $X_0 \in \mathbb{R}^{N \times k}$, uniformly at random.
2.  Choose column $q_j$ uniformly at random between 1 and $N$.
3.  Update the direction
    (7.58)
    $$ \mathbf{v}_{j+1} = \mathbf{v}_j + \eta_j (I - \mathbf{v}_j \mathbf{v}_j^T) (\mathbf{r}_j(i) - \mathbf{v}_j^T \mathbf{r}_j(i) \mathbf{v}_j) $$
    (7.59)
    $$ \mathbf{v}_{j+1} \leftarrow \frac{\mathbf{v}_{j+1}}{\|\mathbf{v}_{j+1}\|} $$
4.  Set $j \leftarrow j+1$. If $\|\mathbf{v}_{j+1} - \mathbf{v}_j\| < \epsilon_{tol}$, then stop. Otherwise go to Step 2.
Solution (sketch): Let $R_t \in \mathbb{R}^N$ and $X \in \mathbb{R}^{N \times k}$ be random matrices taking values in $\mathbb{R}^{N \times k}$. Let $X_0$ be one of $T$ values: $X_0^T X_0 = I_k$, with equal probability $1/T$. One can interpret the product $Y^T X_0 R_t^T$ on the expectation $E[Y^T X_0]$. The first $k$ eigenvalues of $E[Y^T X_0 R_t^T]$ are
(7.60)
$$ \lambda_i(E[Y^T X_0 R_t^T]) = \frac{\langle \mathbf{v}_i^* | \mathbf{v}_i^* \rangle}{\langle \mathbf{v}_i^* | \mathbf{v}_i^* \rangle} $$
We can apply (stochastic) gradient algorithm to the maximum search.
The derivation $f(\mathbf{v}) = \mathbf{v}^T E[R R^T] \mathbf{v} - \lambda (\mathbf{v}^T \mathbf{v} - 1)$
The derivative $\nabla f(\mathbf{v}) = 2 E[R R^T] \mathbf{v} - 2 \lambda \mathbf{v}$

**Exercise 7.11 (Distance Between Subspaces):**
Let $A, B \in \mathbb{R}^{N \times k}$ be orthonormal matrices. If the two column subspaces are “similar”, then the $k$-th principal angle between the column subspace of $A$ is well approximated by some unit-norm vector in the column subspace of $B$. Define similarity between the two subspaces as
(7.61)
$$ S(A,B) = \frac{1}{k} \max_{\substack{X \in \mathbb{R}^{k \times k} \\ \|X\|_F=1}} \|AX - BY\|_F^2 $$
Prove that $S(A,B) = 1 - \sigma_1 - \sigma_k$, where $\sigma_1 \ge \dots \ge \sigma_k$ are the $k$ first singular values of $A^T B$.
(Hint: Use the triangle inequality.)

**Exercise 7.12 (Angle Between Subspaces):**
Let $A, B \in \mathbb{R}^{N \times k}$ be orthonormal matrices. Let the least cosine distance between subspaces be the cosine of the smallest achievable angle between two vectors, one belonging to the column subspace of $A$, the other belonging to the column subspace of $B$.
Prove that
$$ S_c(A,B) = \sigma_k(A^T B) $$
where $\sigma_k(A^T B)$ is the last singular value of $A^T B$.

**Exercise 7.13 (Covariance Matrix Degenerate Eigenvalues):**
Consider a risk model with the following structure. Its loading matrix $B$ has the form $B = DU$, where $D \in \mathbb{R}^{N \times N}$ is diagonal positive-definite and $U \in \mathbb{R}^{N \times m}$ is such that $U^T U = I_m$, and its factor covariance matrix is proportional to $I_m$, $\Sigma_f = \lambda_f I_m$.
1.  Prove that we can replace $U$ with an “equivalent” $\tilde{U} = UG$ spanning the same subspace, the estimated covariance matrix does not change.
2.  Extend the result to the case where $\Sigma_f$ is still diagonal, but with the first $m$ variances being greater than the rest
    $$ \lambda_1 > \dots > \lambda_m > \lambda_{m+1} = \dots = \lambda_K $$
    and with
    $$ \tilde{U}_{:,1:p} = U_{:,1:p} $$
    $$ \tilde{U}_{:,(p+1):m} = I_{m-p} $$

**7.6.2 Asymptotic Properties of PCA**

This is a summary of the asymptotic properties of PCA in the regime where the number of variables $N$ is constant and the number of observations $T$ goes to infinity. We use $T$ observations of $N$ variables, $r_1, \dots, r_T$. We assume that the observations are iid from a distribution with covariance matrix $\Sigma$. We denote the $N$ eigenvalues and eigenvectors of the covariance matrix. Decompose the empirical and true covariance matrices into their eigenvalues and eigenvectors:
$$ \hat{\Sigma}_T = \frac{1}{T} \sum_{t=1}^T \mathbf{r}_t \mathbf{r}_t^T $$
By the Strong Law of Large Numbers, $\hat{\Sigma}_T \to \Sigma$ almost surely. Anderson (1963) proves a Central Limit Theorem for the eigenvalues of the covariance matrix. Decompose the empirical and true covariance matrices into their eigenvalues and eigenvectors:
$$ \hat{\Sigma}_T = \hat{U} \hat{S} \hat{U}^T $$
$$ \Sigma = U S U^T $$
with
$$ \lambda_1 > \lambda_2 > \dots > \lambda_N > 0 $$
, all eigenvalues are assumed to be distinct. Anderson proves that, as $T \to \infty$:
(7.62)
$$ \sqrt{T}(\hat{\lambda} - \lambda) \sim N(0, 2\lambda^2) $$
(7.63)
$$ \sqrt{T}(\hat{\mathbf{u}}_i - \mathbf{u}_i) \sim N(0, E_i) $$
(7.64)
$$ E_i = U \begin{pmatrix} 0 & & & \\ & \ddots & & \\ & & (\lambda_i - \lambda_j)^{-2} & \\ & & & \ddots \end{pmatrix} U^T $$
where the $j$-th row has all zeros. Therefore,
1.  The standard error on $\lambda_i$ is $\sqrt{2}\lambda_i / \sqrt{T}$.
2.  The standard error on the principal components, defined as $\sqrt{E[\|\hat{\mathbf{u}}_i - \mathbf{u}_i\|^2]}$, is
    (7.65)
    $$ \frac{1}{\sqrt{T}} \sqrt{\sum_{j \ne i} \frac{\lambda_i \lambda_j}{(\lambda_i - \lambda_j)^2}} $$
    The relative error depends on the separation between eigenvalues.

**The Takeaways**

*   Statistical factor models estimate both factor returns and exposures using return data only, without relying on firm characteristics or macroeconomic data.
*   Advantages: Complementarity to fundamental models, useful when data is sparse, captures short-horizon and multi-asset models.
*   Disadvantages: Interpretability of statistical factors is generally low. PCA identifies a factor model by minimizing the sum of squared residuals in the factor model.
*   Large eigenvalues of the empirical covariance matrix are biased upwards, and are separated in magnitude by a bulk of smaller eigenvalues. This is the spiked covariance model.
*   The sample factor eigenvalues are larger than the true ones, and should be shrinked. Statistical factors can be interpreted. PCA loadings admit a clustering interpretation and a regression interpretation.
*   Statistical models should be rotated in such periods in order to reduce turnover.

**Notes**

1.  [1] These are matrix norms that are invariant for left- and right-multiplication by orthonormal matrices: $\|A\| = \|UAV^T\|$. Special, Frobenius, and nuclear norms.
2.  [2] This problem was solved by Eckart and Young (1936) and generalized by Mirsky (1960). Standard references for PCA are (Johnson and Wichern (2007), Jolliffe (2002), Hastie, Tibshirani, Friedman (2009)). Yao et al. (2015), Jolliffe and Cadima (2016). PCA is also covered in any good book on multivariate statistics (e.g., Mardia, Kent, Bibby (1979)), machine learning (e.g., Bishop (2006), Murphy (2012)). Connor, Goldberg, Korajczyk (2010) is dedicated to the interpretation of SVD, PCA, non-negative matrix factorization and its applications.
3.  [3] This is the full SVD, as opposed to the reduced SVD, see Section 4.7.4.
4.  [4] You can prove (c) of this Solved Exercise 7.2.
5.  [5] In the statistical literature, the analysis of this model begins with Johnstone (2001). In a seminal paper, Chamberlain and Rothschild (1983) impose structure on the covariance matrix by assuming that the returns are generated by an $m$-factor model, with $m \ll N$, and that the idiosyncratic risk is $O(N)$. In our model, in which the diversifiable risk goes to zero.
6.  [6] We have only touched briefly on the asymptotic limit of the spiked model in Section 7.2.2 to give a taste of what happens and give a basis for heuristics. Several papers have characterized the behavior between the model. The first and most famous result is the Marcenko-Pastur (1967) law, which describes the limiting distribution of the eigenvalues of the sample covariance matrix. Bai and Yin (1993) and Bai (1999) extended these results. Baik and Silverstein (2006) and Paul (2007); El Karoui (2008); Mesot et al. (2008); Benaych-Georges and Nadakuditi (2011); Shen et al. (2016); Wang and Fan (2017); Wang and Yao (2017). A survey is Johnstone and Paul (2018). Recent advances are Bun et al. (2017) and Bouchaud and Potters (2019). The line of research concerned with properties of the spectrum in the regime $N/T \approx \gamma > 1$ “begins perhaps with Johnstone (2001)”.
7.  [7] As in Section 7.1.2, $\mathbf{U}_m$ is the submatrix of $\mathbf{U}$ obtained by taking the first $m$ columns.
8.  [8] From the very first result on biased asymptotic estimators, a reader may wonder about shrinkage methods. There is an extensive literature on factor model shrinkage. Standard references are Ledoit and Wolf (2003a,b, 2004) on linear shrinkage, and more recent work on non-linear shrinkage by the same authors (Ledoit and Wolf, 2012, 2015, 2017a,b, 2020). They derive optimal shrinkage functions for a large set of loss functions.
9.  [9] For a relatively old survey on methods to select the number of factors, see Bai and Ng (2002). For a more modern survey is Fan et al. (2013). The scree plot is due to Cattell (1966). The penalty method is due to Akaike (1974). The scree is the debris that form at the base of a cliff.
10. [10] An American Depositary Receipt (ADR) is a foreign company that is listed on a U.S. stock exchange, which also offers shares in U.S. exchange. A Global Depositary Receipt (GDR) is similar to an ADR, but is listed on exchanges in one or more countries outside of their primary market.
11. [11] Note, however, that Russell does not screen stocks based on trading volume, and that the smallest-capitalization companies in Kipoo and Kosso (2013) are often illiquid.
12. [12] For a definition of subspace similarity, see Exercise 7.12.
13. [13] If you are not convinced, or this statement does not seem obvious, this is a good time to solve Exercise 7.11.
14. [14] Note that this problem is closely related to Wahba’s Problem; see Wahba (1990).
15. [15] The two-step procedure for reweighting the PCA is relatively common; Bai and Ng (2002) reweights using idio volatilities, and Bollerslev (1990) using total volatilities.
   

Okay, here is the Markdown compilation for Chapter 8.

```markdown
Everand

**Chapter 8**
**Evaluating Excess Returns**

**The Questions**

1.  How does revising historical data impact alpha estimation and backtesting in factor models?
2.  What are the best practices we should follow in our backtests?
3.  What are the two main backtesting frameworks and what are their drawbacks?
4.  What approach could address these limitations?

The task of estimating factor models and testing alphas for systematic strategies usually involves reusing the same historical data. This is a major statistical conundrum. One of the defining features of the past 20 years has been the unprecedented number of new datasets and their broad dissemination. Investment firms spend large budgets of tens of millions of dollars allocated to the purchase of market and alternative data, and to the bespoke collection of data (e.g., via web scraping). And yet, the characteristics of the data are often poorly understood. The time series of data—the building blocks of our models and simulations—are often short, the number of times—of the order of a day or longer—do not necessarily employ tick-by-tick data. If we record prices for a broad local investment universe at 1-minute intervals, we collect 60 million numeric data points per year, including a security identifier and a timestamp. The required storage for this data is modest; the quality is not. It is increasingly common to deal with deep data. Deep data means that the past is not easy to produce a simulated version of the past that provably reproduces all of its features. Not deep, in the sense that we do not live in a time series. The world is much richer. The real world outside of finance is sprawling, breathtaking and awe-inspiring, and models are crude approximations. But even within finance, the introduction of new technology, of new market microstructure designs, of new regulations, and the ongoing collective learning process of all market participants make the investing world of five years ago very different from today’s. The fact that we have more data on our hard drives poses a major challenge to the modeler. Financial practitioners do not have a shared protocol for experimental analysis. Even if we had one, it is far from obvious that it is the correct one. Well-established disciplines like medicine and psychology have shared experimental practices accompanied by experimental design, and yet they have undergone a crisis of confidence when their peers found that some of their results were not replicable (Greenland, 2017; Open Science Collaboration, 2015).

This poses a few challenges for us modelers. We have a very large number of signal types, which themselves depend on continuous tuning parameters, and we only have a limited history. This is similar to the situation faced by biostatisticians, who deal with tens of thousands of simultaneous tests in the form of responses from a DNA microarray (Dudoit et al., 2003; Storey et al., 2004). The details are quite different. The response variable for a DNA microarray is usually continuous. For financial signals, returns are autocorrelated or weakly correlated. In quantitative finance, the response variable (be it return or Sharpe), is continuous, and signal correlation plays a decisive role.

This chapter has four sections. First, we list some basic best practices for data preparation and usage. Second, we describe some common backtesting practices and criticize them. The third section is entirely devoted to describing a new backtesting protocol, which is based on recent advances in statistical learning theory. We derive simple uniform probabilistic bounds on the Sharpe Ratio of a large set of strategies. The last section applies the theory developed so far to simulated and historical data.

---

**8.1 Backtesting Best Practices**

We review in this section practices for backtesting. They do not originate from some comprehensive Theory of Everything, but are born fully formed from the mind of Zeus. It is an ever-incomplete, occasionally shallow body of knowledge that has formed by experimentation. Some references covering these practices are Wang et al. (2014); Arnosti et al. (2017); López de Prado (2018).

**8.1.1 Data Sourcing**

High-quality data are essential to backtesting, and the search for better data is a never-ending task for a researcher. There are several broad areas of concern. The first one is data sourcing. There are multiple vendors offering similar data. When comparing them, ask the following questions:
*   Definition and interpretation. Perhaps the first and most important question is not only in data sourcing, but in quantitative finance in general, what do the data mean? Do we know the exact definition of the data? What are their physical units? If the dataset is money-related, it should be unambiguous what is the reference currency (or currencies, for exchange rates). If the data is flow-related (i.e., measuring units over time), the time unit should be defined. A common source of error is deciding between annual or annualized numbers.
*   Provenance. Where are the data coming from? Does the vendor collect the data themselves (e.g., via web scraping, or internet traffic)? Does the vendor buy the data from another vendor, and then act as a data integrator and the client? In the former case, what is the data collection criterion? Does the vendor sample the data or collect them exhaustively? Is the population sampling methodology sound? In the latter case, who is the original data vendor? Are they reliable?
*   Completeness. Are there data that are obviously missing from the dataset such as, for example, intermittently missing prices? Are there data that are non-obviously missing, such as, for example, unrecorded consumer credit card transactions? Both of these questions must be answered before performing exploratory analysis of the data. If there are issues, these need to be addressed with the vendor.
*   Quality assurance. How does the provider ensure that the data it collects or subjects are consistent and of good quality? Does it have checks for change points in the data (non-stationarities)?
*   Point-in-time versus restated data. Does the provider offer data collected as of a certain date, without changing them at a later date, based on corrections and company updates? This is an instance of data leakage, which we will cover in more detail later.
*   Transformations. Data are often transformed by the vendor. Transformations are: removal of missing data, winsorization and removal of outliers, end-of-period price calculations (last transaction, mid, bid-ask price, weighted average). These transformations should be documented, evaluated, and if possible, verified by the research analyst.

Exploring alternatives and complements. Always ask the following common-sense questions: can we obtain better data, across the following three dimensions. First, are there providers offering larger coverage (i.e., the same data but for more entities or more periods)? Second, are there providers offering more granular data? Third, are there providers with better data? For example, if data are collected from broker-dealers, the alternative provider has an agreement with a larger number of participating broker-dealers. Third, can we obtain complementary data? If data are flows that quantify activity on a social media platform or a given website, for example, we may want to obtain transactional data that help us estimate short-term revenues of a company, in addition to data that give us a good estimate of their costs.

**8.1.2 Research Process**

Every researcher has their own research process. This is part of their competitive advantage; it’s indeed part of what they are, of thoughts and learned lessons accumulated over a lifetime of experiences and of studying. It would be futile to superimpose the author’s own research process to that of the reader. Just as futile would be to recommend that the reader adopt some universal method, part of basic hygiene. Consider these akin to the prompt to never leave home without wearing underwear.
*   Data leakage. The first recommendation is to avoid data leakage. The definition of data leakage is the presence in the training data, the data available up to period $t-1$, of data that are referenced in time $t$, i.e., returns in period $t$, and that are contained in the test data (the data in period $t$ or later). Data that are referenced in time $t$ are used in production on that day. Detecting data leakage is more art than science, and it requires both a deep knowledge of the data (see above) and of the problem at hand. Below are a few examples.
    *   Survivorship bias. This is the most common form of data leakage. It is the practice of conditioning the performance of a strategy on an extended period of time, considering only the stocks that have continuously traded during this period, i.e., the surviving stocks at the end of the backtest, we are subject to survivorship bias. Stocks are most often delisted because of mergers or acquisitions, or because they become illiquid, or they do not meet some additional criteria for being listed on an exchange. Removing them biases the investment sample toward outperformers with different characteristics than those of the broader investment universe. As a point in time, the stocks in the universe, their characteristics, and size are larger than the universe.
    This is the simplest and most impactful instance of data leakage. The remedy to this issue is to: (a) employ a universe that is updated in time; (b) employ a universe that is static in time. By (a) specify a listing and delisting date in the backtest for the event of a delisting. For example, one could assume that the entire investment is written off. Note that the methodology in (a) should be specified before backtesting. (b) means that the universe is chosen based on the result of a backtest is also an instance of data leakage, and it should be avoided. Criteria for inclusion are indeed not straightforward to specify. A common recommendation is to use an investment universe defined by a commercial provider, like Russell 3000 Index, S&P500, MSCI benchmarks, or commercial factor models investment universes. Note that benchmark components are always announced before (“announcement date”) the effective date of the change. The performance of a stock is often affected by the announcement of an inclusion or exclusion. In your backtest, you may want to capture this information, in order to assess how much of the performance of your quantitative strategies is affected by benchmark rebalancing events.
    *   Financial statement information. Financial statement information for a given quarter or year should be included in the backtesting data on the day (or the day after) of their public release, not on the date of the statement data itself.
    *   Point-in-time versus restated data. Data in the backtest on a given date should always be the most recent data available as of that date. If a 10-Q (quarterly financial report) is restated because of a mistake, the backtest should not use the restated data. The decision must be made by allowing the variance of errors in its input data.
    *   Price adjustments. Shares are regularly split (or reverse-split) into multiple shares. The price of the split share is adjusted accordingly. This occurs when the firm appreciates, to the point one share becomes so expensive that it prevents investors from being able to buy it. In order to preserve liquidity, the firm splits its shares. Stock splits and dividends are usually split-adjusted. This introduces a complication. A low stock price at the distant past indicates that the shares have been split several times in the future, likely because of high returns. The price becomes indicative of future good performance. This is data leakage. We must use adjusted prices only for return calculation. For feature generation, use as-of prices.
    *   Missingness. In certain cases identify unstructured data. In particular, missing data are often imputed because they are either available and up-to-date, or because there is some sensitive information and were redacted. In the latter case, missingness may be suffering from look-ahead bias and is information about returns.
    *   Available information. The number of silly mistakes (in hindsight) that experienced, effective researchers make never ceases to amaze. For example, a stock characteristic available in a dataset had high Information Coefficients (IC). Upon further investigation, it was a stock split conversion factor, not the magic bullet after all. In another example, because of an erroneous $t$ versus $t-1$ conversion error, a researcher included the next-day return in a three-month momentum factor definition, also causing a false positive.

Shrinkage and regularization. These techniques are ubiquitous, but, while missing a solid foundation, we hard to argue against.
Have a theory (if any). It is preferable to have a theory for every anomaly and to pre-register the predictions of the theory before the backtest. For example, many papers in the academic literature are based on a theory for the development of the factor. In De Franco and Pedersen (2014) when they analyze the beta anomaly. With a theory as a guide, it is easier to choose a security characteristic among many possible ones, reducing the number of strategies tested. The theory may not be correct and the result would be noise in it, and it is possible to critique and revise the characteristic, which is maybe not desirable (it would be nice if we got it right the first time) but necessary.
Experimental design. Document your assumptions and make sure you can reproduce and revise them at any time.
Use the same setting in backtesting and in production as much as possible. By this we mean that we should use the same point-in-time data, but also the same optimization formulations, the same market impact model, and the same codebase.
Calibrate the market impact model. When we perform a backtest, the market impact model has a “descriptive” role. It is not possible, however, to verify the realized market impact on historical data. In order to run a live backtest, performance has to be simulated out of sample. A market impact model of fair value, especially one provided by a vendor or a partner. Instead, calibrate its parameters against live performance of the current version of your strategy, so that realized PnL is as close to simulated PnL as much as possible.
Include borrow costs. As part of the effort to align production and simulated PnL, one should take borrow costs, for shorted securities, into account, since they can have a material impact on PnL. This is one of the main challenges. Historical borrow rates are not readily available historically. The researcher may have to approximate them, or predict them on the basis of security characteristics. Another complication, albeit minor in impact, is the tax treatment of dividends. When firms are owned by the investor, they are subject to taxation. When the investor is short the security, the treatment of dividends is more complex. In practice, tax-dividend treatment is usually ignored. There is a conceptual difference in backtests, so it is not well understood. Still, be aware.
Define the backtesting protocol beforehand. A backtesting protocol is the sequence of actions and decisions that lead to assessing the performance of a strategy. It is the subject of the next section. For the sake of this list of folk precepts, it is sufficient to say that the backtesting protocol should be charged to the client, for a good reason. And if it is a new design, tested, and evaluated as part of your process goes under the new protocol.
Define the dataset being used beforehand. If dataset selection is seen as part of the backtesting protocol, the heuristic follows from the previous point. The difference is that data and new data become available every day, both in the form of live data, and of extensions to historical dataset. Researchers may be prone to include datasets that confirm their findings, and ignore those that do not. Ignoring new data would be suboptimal, and including them selectively may lead to the wrong conclusions. Use your judgment and research integrity, which no theorems can help.

---

**8.2 The Backtesting Protocol**

**8.2.1 Cross-Validation and Walk Forward**

Evaluating trading strategies bears similarities with statistical model selection (Hastie et al., 2008). We have a family of strategies, a statistics, a loss, or a model, and a performance metric, such as Sharpe Ratio or PnL. We want to select the strategies themselves may depend on several parameters. Two evaluation schemes are most common. The first one is cross-validation (Hastie et al., 2008, Ch. 7; Mohri et al., 2018, Ch. 3). The available data is split into a training dataset and a holdout dataset. The model is trained on the training dataset, and its performance is evaluated on the holdout dataset. The estimate of the performance is then the average of the performance on the holdout dataset. The training dataset is split into $K$ equal-sized samples (“folds”). For the buffer between training and holdout datasets, we may want to separate the folds by a short buffer (for equities, just one or two days) to decrease dependence between the folds. The model is trained on $K-1$ folds, and its performance is evaluated on the remaining fold. This is repeated $K$ times. We perform $K$ estimation-evaluation cycles. The parameters are estimated on each of the possible combinations of $K-1$ folds, and the performance of the model is evaluated on the remaining fold using the optimized parameter; see Figure 8.2. The final estimate of the performance is then the average of the $K$ performances.
A scheme is shown in Figure 8.3. There are several considerations in using cross-validation for financial applications. First, the samples are not independent. The time dependence is reflected in the returns themselves. We know that serial dependence in returns is weak. However, the volatility of returns is serially dependent. If we shuffle the data (or some time series), it is possible to remedy this by keeping the order intact in the folds and the errors are serially uncorrelated (Bergmeir et al., 2018; Cerqueira et al., 2020). This is not the only issue. Financial data are non-stationary. For example, consider the inclusion of a security recently merged in a portfolio. This may create a structural break. If the validation fold precedes temporally the training fold, these past returns are in the validation fold and we are incurring a typical instance of data leakage: the predictors directly contain information about the target. For example, a momentum strategy is a problem. But some strategies, like those usually produced by machine learning, who base their judgment on past returns. Like momentum, we may have leaked target data into the training set. Besides the temporal dependencies, there is another practical obstacle to $K$-fold cross-validation in the influential book, Hastie et al. (2008, Section 7.10). The $K$ estimation-evaluation cycles are computationally very expensive. Cross-validation. Predictive variables (be they alpha or factors, in our framework) should not be screened in advance. This is often not the case in practice: the predictiveness of signals in fully-fledged strategies is tested separately.

(Right Sidebar from Page 351)
Perform cross-validation enough times on different classes of models, and you will inevitably obtain favorable results. The holdout dataset is meant to serve as a check against this overfitting. However, the holdout dataset is not greater than the training set. In the case of financial data, it is inevitable to cycle through several refinements and model revisions, so that the holdout sample performance becomes just another variable to be optimized, instead of a performance check to be run only once.

[Image: Figure 8.2: A scheme of the cross-validation procedure. Dashed boxes are validation folds, while lighter boxes are training folds. Shows a timeline with alternating Training Dataset and Holdout Dataset segments.]

[Image: Figure 8.3: A scheme of the cross-validation procedure. Data is split into two sets: Cross-Validation is performed on the first one (training dataset), to estimate the expected performance of a strategy. The model is then optimized on the entire training dataset, and validated on the second one (validation dataset). Shows a flow: Data -> Cross-Validation -> Training Dataset -> Best Parameters -> Holdout Dataset -> Final Training -> Final Validation.]

As an example we help illustrate the perils of cross-validation. We base $N=1000$ points. We simulate iid asset returns with $r_{it} \sim N(0, \sigma^2)$ with $\sigma = 0.01$. We introduce $P$ random features. These features are also iid random and are design not predictive of returns: $B_{ikt} \sim N(0,1)$.[1] These random features are to design not predictive of returns. The backtest consists of a fixed-fold cross-validation, to estimate the performance of the strategy. We choose $K=5$, and compute the IC and Sharpe Ratio of the strategy. We repeat the process on 1000 simulated datasets. Below are the results for two scenarios:
1.  The first one is the “many periods, few predictors” case: we set $T=5000$ (years of daily data) and $P=2$. Two predictors because one would have felt too lonely.
2.  The second one is the “few periods, many predictors” case: we set $T=250$ (1 year of daily data) and $P=500$, not nearly as many as we meet in practice.

The frequency histograms of the simulations are shown in Figure 8.4. Some summary statistics of the simulations are shown in Table 8.1. Percentages are close to zero, with the exception of the last column. The percentage of samples whose Sharpe Ratio passes the 1% significant level is shown in the last column of the table. Frequency histograms for the two simulated scenarios; the conversion IC to Sharpe Ratio is $\text{SR} = \text{IC} \times \sqrt{252 N}$.

[Image: Figure 8.4: Cross-validated Sharpe for (a) Scenario 1, (b) Scenario 2.]

**TABLE 8.1**
Backtesting results for the two simulated scenarios; the conversion IC to Sharpe Ratio is $\text{SR} = \text{IC} \times \sqrt{252 N}$ (252 trading days).

| T    | P   | "Holdout" p | Mean (SR) | Stdev (SR) | % passing |
| :--- | :-- | :---------- | :-------- | :--------- | :-------- |
| 5000 | 2   | 0.0187      | 0.02      | 0.07       | 1.2       |
| 250  | 500 | 0.04        | 0.04      | 1.4        | 19        |

A remedy to the data leakage issues arising in cross-validation is walk-forward backtesting (Pardo, 2012). In this scheme, we use historical data up to period $t$ and target returns for period $t+1$, see Figure 8.5. The scheme is as close as possible to the production process. It addresses two drawbacks of cross-validation for time-series—serial dependence and risk of data leakage—and it also allows us to naturally incorporate time-varying parameters as the environment changes. These advantages are complementary to cross-validation. As a result, it is often the case that signals, or simplified strategies, are first tested using cross-validation, and then tested “out of sample” in a walk-forward test. This is not ideal, however, since it has an opportunity cost caused by the delay in running the strategy in production. Walk-forward has an additional important drawback: it uses less training data than cross-validation. On the other side, the holdout dataset is large. It is also possible that the parameters of the model have been identified, and only a few new parameters need to be optimized. This drawback becomes negligible. Two additional settings in which walk-forward does not suffer from data limitation when: (a) data are plenty, (b) in the case of high-frequency trading. (b) data are scarce, but the strategy is very simple. Walk-forward is a necessary step in the validation of a strategy, and in its preparation for production.

(Right Sidebar from Page 355)
[Image: Figure 8.5: Two common walk-forward schemes. The top one uses fixed-length training data, thus keeping the estimation procedure comparable. The bottom one uses all of the past data available, possibly weighting data differently based on the interval from the estimation epoch.]

Summing up, neither cross-sectional nor walk-forward schemes are without flaws. Ideally, we would like a protocol with the following features:
1.  non-anticipatory (immune from data leakage);
2.  taking into account serial dependency;
3.  using all data (or possibly multiple testing if $K$ is large or the number of signals);
4.  providing a rigorous decision rule.
Walk-forward meets the first two requirements; cross-validation meets the third. Neither meet the last two. The next section introduces a novel backtesting protocol, the Rademacher Anti-Serum (in short, RAS), which meets these requirements.

---

**8.3 The Rademacher Anti-Serum (RAS)**

**8.3.1 Setup**

We will be concerned with testing the performance of strategies and signals.
1.  Strategies are the walk-forward simulated returns $r_{S,t}$. This is scored by the predicted volatility, which we denote by $\hat{\sigma}_{S,t}$, so that their average equals the empirical Sharpe Ratio for strategy $S$. In this chapter, we will use the notation $\hat{\theta}_S$ for the Sharpe Ratio.
2.  Signals are time-series of weights. For signals, we consider the Information Coefficient (IC) for the signal at time $t$, which is defined as the cosine of the angle (their cosine similarity) between the alpha vector predicted by signal $S$ in period $t-1$, and the idiosyncratic returns in the same period $t$.
The definitions are below:
$$ \text{IC}_{S,t} = \frac{\mathbf{w}_{S,t-1}^T \mathbf{r}_t}{\|\mathbf{w}_{S,t-1}\| \|\mathbf{r}_t\|} \quad \text{(Sharpe Ratio)} $$
$$ \text{IC}_{S,t} = \frac{\mathbf{w}_{S,t-1}^T \mathbf{r}_t}{\|\mathbf{w}_{S,t-1}\| \|\mathbf{r}_t\| \hat{\sigma}_{S,t} \hat{\sigma}_{R,t}} \quad \text{(Information Coefficient)} $$
We also denote by $|\mathcal{S}|$ the number of strategies. The interpretation will be clear from the context. In one case, the dataset needed for the analysis is a $T \times N$ matrix $\mathbf{X}$. Rows denote observations of a certain timestamp and columns denote strategies, whose set we denote $\mathcal{S}$. For notational simplicity, the $s$-th strategy is denoted by $X_s$, its $t$-th column is $X_{s,t}$. The following results are important as they are quite general. We have two justifications for the assumptions. The first one is empirical. Serial dependence is small for returns observed at daily frequencies or lower.[2] The second one is that our framework can be extended to the case of time-dependent observations. In this case, we assume that the time series of returns is $\alpha$-mixing, i.e., the autocorrelation up to lag $k$, then replace the original time series with $N/k$ non-overlapping, contiguous averages of blocks:
$$ (X_{s,1}, \dots, X_{s,k}), \dots, (X_{s, (N/k-1)k+1}, \dots, X_{s,N}) $$
We employ the following notation. We let the joint distribution of $X_s$ be $P$. Let $D = \otimes_{s \in \mathcal{S}} P_s$. The joint probability distribution on the space of $T \times N$ matrices in which the element $X_{s,t} \sim P_s$ has independent, identically distributed (iid) rows, each drawn from $P$.

(Right Sidebar from Page 356)
The expected value of $X_s$ is denoted by $\theta_S = E_P[X_s]$. This is the true strategy/signal performance. Define $\hat{\theta}_S = \frac{1}{T} \sum_{t=1}^T X_{s,t}$ as the vector of column averages of $\mathbf{X}$.
(8.1)
$$ \hat{\theta}_S = \frac{1}{T} \sum_{t=1}^T X_{s,t} $$
which is the expected value of $X_s$ according to the bootstrap distribution.
Let $\mathbf{\epsilon}$ be a Rademacher random vector in $\mathbb{R}^T$, $T$-dimensional random vector whose elements are iid, and take values $+1$ or $-1$ with probability $1/2$. The Rademacher complexity of $\mathcal{S}$ (Mohri et al., 2018)
(8.2)
$$ \hat{\mathcal{R}}_T(\mathcal{S}) = E_\epsilon \left[ \sup_{s \in \mathcal{S}} \frac{\mathbf{\epsilon}^T \mathbf{X}_s}{T} \right] $$
Before stating a rigorous result linking this quantity to a bound on performance, we focus our attention on its interpretation. Specifically, we can interpret $\hat{\mathcal{R}}_T$ as follows.
*   As the resemblance to random noise. Consider $S$ as a random covariate. We can interpret $\hat{\mathcal{R}}_T$ as the expected value of the highest covariance of the performance measure of a strategy to random noise, $E_\epsilon$. On average, for every set of $+/-1$ indicators, there is at least a strategy that covaries with it, then “we can do no wrong”: for every realization of random noise, there is a strategy that performs well. This implies that, if $E_\epsilon[\mathbf{\epsilon}^T \mathbf{X}_s / T] \approx 1$, if we interpret the $X_s$ as predictions for epoch $t$, then this means that for every sequence of events $\epsilon_t$, we have a strategy that predicts them well.
*   As generalized two-way cross-validation.[3] For sufficiently large $T$, the sets of positive and negative indicators are of size roughly $T/2$. Let $S^+$ be the set of $T/2$ periods where $\epsilon_t = +1$, and $S^-$ the other periods. Rewrite the term inside the sup as
    $$ \frac{1}{T} \sum_{t=1}^T \epsilon_t X_{s,t} = \frac{1}{2T} \sum_{t \in S^+} X_{s,t} - \frac{1}{2T} \sum_{t \in S^-} X_{s,t} = \frac{1}{2} (\hat{\theta}_{s,S^+} - \hat{\theta}_{s,S^-}) $$
    $$ \hat{\theta}_{s,S^+} := \frac{1}{T/2} \sum_{t \in S^+} X_{s,t} $$
    $$ \hat{\theta}_{s,S^-} := \frac{1}{T/2} \sum_{t \in S^-} X_{s,t} $$
    For strategy $s$, this is the discrepancy in average performance measured on two equal-sized random subsets of the observations. By taking the sup across strategies, we are selecting the worst case. We estimate performance on a subset, and get a very different result on the remaining subset. And if the discrepancy is high for each random subset, at least one strategy that performs well. This means that there is always a strategy that performs well. The Rademacher complexity is a measure of how well a strategy performs “out of sample” when the performance is measured on a random subset of the data, and then averaged over all possible random subsets.
*   As measure of span of possible performances. We interpret $\mathbf{X}_s \in \mathbb{R}^T$ as a “random direction” chosen at random in $\mathbb{R}^T$. The vector has Euclidean norm equal to $\sqrt{T}$. In the case where the performance measure is the IC, the vector $\mathbf{X}_s / \sqrt{T}$ is on the unit sphere, and is strongly concentrated around this value. The empirical Rademacher complexity $\hat{\mathcal{R}}_T(\mathcal{S})$ is then approximately equal to
    $$ E_\epsilon \left[ \sup_{s \in \mathcal{S}} \frac{\mathbf{\epsilon}^T \mathbf{X}_s}{\|\mathbf{X}_s\|} \right] $$
    This can be interpreted in the following way. We have a set of $N$ unit vectors $\mathbf{X}_s / \|\mathbf{X}_s\|$. We pick a random direction in the ambient space and observe the maximum collinearity (expressed as the cosine similarity) of this random direction to the vectors. The expected value of this maximum collinearity is the Rademacher complexity. If the vectors are very well spread, it is likely that one of them is very close to the random direction. If the vectors are all copies of the same vector, the maximum collinearity is not very well. If, conversely, these vectors are all orthogonal, we have $N$ unit vectors. The Rademacher complexity is a geometric measure of how much the vectors $\mathbf{X}_s$ “span” $\mathbb{R}^T$. [4]
One interesting characteristic of the Rademacher complexity is that it takes into account dependencies among strategies. If, for example, we had $N$ strategies to test, but $N-1$ are copies of the first one, then we would not need the Rademacher complexity. However, if the $N$ strategies are uncorrelated from each other, then the Rademacher complexity is high, indicating higher likelihood of overfitting.

**8.3.2 Main Result and Interpretation**

The thrust of this section is to provide a uniform, additive “haircut”. This term we subtract from the empirical performance to the performance of strategies. In other words, for each strategy $s$ we have an empirical performance $\hat{\theta}_s$, given by Equation (8.1). In the case of excess returns, this is the empirical Sharpe Ratio. Then, we can establish a probabilistic guarantee on the true Sharpe Ratio of strategy $s$. With probability, say, greater than $1-\delta$, the Sharpe Ratio of the strategy is greater than $\hat{\theta}_S - \text{haircut}$.
(8.3)
$$ \theta_S \ge \hat{\theta}_S - 2\hat{\mathcal{R}}_T(\mathcal{S}) - \sqrt{\frac{2\log(2/\delta)}{T}} $$
(data snooping) (estimation error)
The result is described in Procedure 8.1.

**Procedure 8.1: Rademacher Anti-Serum for signals**
1.  Backtest all the strategies using a walk-forward protocol. Let $\mathbf{X}_s \in \mathbb{R}^T$ be the time series of Information Coefficients of strategy $s$ at time $t$.
2.  Compute $\hat{\mathcal{R}}_T(\mathcal{S})$, as defined in Equation (8.2).
3.  Compute $\hat{\theta}_S(\mathbf{X}_s)$
    for all $s \in \mathcal{S}$, $t=1, \dots, N$
4.  $$ \hat{\theta}_S \ge \hat{\theta}_S - 2\hat{\mathcal{R}}_T(\mathcal{S}) - \sqrt{\frac{2\log(2/\delta)}{T}} $$
    with probability greater than $1-\delta$.
Now, we consider the case for Sharpe analysis. The formula is similar, but with a different, reset estimation error.
(8.4)
$$ \hat{\theta}_S \ge \hat{\theta}_S - 2\hat{\mathcal{R}}_T(\mathcal{S}) - \sqrt{\frac{2\log(2/\delta) (1+\hat{\theta}_S^2/2)}{T}} $$
(data snooping) (estimation error)
The proofs are in the Appendix, Section 8.5.

**Procedure 8.2: Rademacher Anti-Serum for Strategies**
1.  Backtest all the strategies using a walk-forward protocol. Let $\mathbf{X}_s \in \mathbb{R}^T$ be the matrix with Information Ratio of strategy $s$ at time $t$.
2.  Compute $\hat{\mathcal{R}}_T(\mathcal{S})$, as defined in Equation (8.2).
3.  Compute $\hat{\theta}_S(\mathbf{X}_s)$
    for all $s \in \mathcal{S}$, $t=1, \dots, N$
4.  $$ \theta_S \ge \hat{\theta}_S - 2\hat{\mathcal{R}}_T(\mathcal{S}) - \sqrt{\frac{2\log(2/\delta)}{T}} $$
    with probability greater than $1-\delta$.

We focus on the interpretation of the claims. The theorem states that the lower bounds on IC and Sharpe hold simultaneously, at least with probability $1-\delta$. Moreover the statement holds for any finite $T$; no asymptotic approximation is invoked. The true expected performance differs from the empirical performance because of two non-negative terms:
*   The first is the term $2\hat{\mathcal{R}}_T$. This is the data-snooping term. The larger the number of strategies, the higher the $\hat{\mathcal{R}}_T$, because $\sup$ is strictly increasing in the number of strategies. Moreover, as we saw in Section 8.3.1, higher dependency among strategies implies lower $\hat{\mathcal{R}}_T$. This is the first case where we test multiple replicas of the same strategy, $\hat{\mathcal{R}}_T$ is zero. To provide some intuition about the behavior of Rademacher complexity, we consider a set of strategies with normally distributed returns with mean $\mu_S$ and variance $\sigma_S^2$. We vary the number of strategies, and the correlation, and increases in the number of strategies. Given the data matrix $\mathbf{X}$, the quantity $\hat{\mathcal{R}}_T$ is estimated via simulation. An upper bound for this quantity is given by Massart’s lemma:
    $$ \hat{\mathcal{R}}_T \le \sqrt{\frac{2 \log N}{T}} \max_s \|\mathbf{X}_s\| $$

[Image: Figure 8.6: Rademacher complexity for poor strategies, with iid Gaussian returns and variable pairwise correlation. Estimate based on $10^4$ samples.]

*   The second is the estimation term. For some situation, consider the case of $T$ iid normal random variables $\theta_S$ with mean $\theta$ and unit variance. Their average $\hat{\theta}_S$ is distributed as a normal distribution with standard deviation $1/\sqrt{T}$. What if $\theta_S$ is quantile of the distribution? For example, the $5\%$ quantile of the distribution. For a normal distribution with zero mean and standard deviation $1/\sqrt{T}$, $F^{-1}(\delta) = \sqrt{2 \log(1/\delta)} / \sqrt{T}$, and Cumulative Distribution Function $F$.
    (8.5)
    $$ F^{-1}(\delta) = \frac{\sqrt{2\log(1/(2\sqrt{2\pi\delta}))}}{T} $$
    This is similar to, up to constants, to the estimation errors in Equation (8.3) and (8.4). In the limit $T \to \infty$, the estimation error in both procedures approaches 0.
    The estimation error above is independent of $N$ for bounded distributions and is $\propto 1/\sqrt{N}$ for sub-Gaussian ones. An argument for this property is based on the following. Consider the following special case. Given $N$ iid Gaussian random variables $X_i \sim N(0,1)$. The empirical Sharpe Ratios of the $N$ strategies are also iid, $\sim N(0, 1/T)$. It can be shown (Van Handel, 2016; Kamath, 2020) that:
    of $s$. This seems a loose bound, compared to the standard formula for the standard error of the Sharpe Ratio (i.e., $\text{stdev} = \sqrt{(1+SR^2/2)/T}$). For a strategy with Sharpe Ratio equal to 2, the estimation error haircut is
    $$ F(\delta) \sqrt{(1+SR^2/2)/T} \sqrt{251} \approx 1.7 $$
    The constant of the data-snooping term is also conservative, since in the proof we rely on a chain of inequalities to obtain a bound.
    I will close with the wise words of a former colleague. The path connecting theory to practice is often tortuous. But when it is straight, it is usually short. I hope that theory is insightful, applicable, useful, and not too complicated. The bound of Procedure 8.2 will take the form:
    $$ \theta_S - \hat{\theta}_S \ge -2\hat{\mathcal{R}}_T - b \sqrt{\frac{2\log(2/\delta)}{T}} $$
    with positive parameters $a,b$.

When the SR is zero, the maximum (and high quantiles) of the Sharpe Ratios grows as $\sqrt{2 \log N / T}$. This is not to say that the estimation error on the individual SR should be equal to $\sqrt{2 \log N / T}$. For some positive $\alpha$, in addition, we should have a term that captures the tail behavior of error, $T^{-\alpha}$. For large $N$, the dominant term of the estimation error is $\sqrt{2 \log N / T}$.
$$ \sqrt{2 \log N / T} + 2 \log(2/\delta)/T $$
which is majorized by
$$ \sqrt{2 (\log N / T + \sqrt{2 \log(2/\delta)/T})} $$
The first term is the $\hat{\mathcal{R}}_T$ growth term, and the second one is the term accounting for the confidence interval that we saw in Equation (8.4).
The procedure is operationally simple: simulate all possible strategies in a walk-forward manner. There should be no look-ahead bias: the strategies should be formulated without looking at future data. The strategies should be based on good modeling practice. As we mentioned before, “best practice” means that all strategies should be documented and should run in parallel to the production strategy. Then, estimate the Rademacher complexity of matrix $\mathbf{X}$ by the expectation in the definition of that statistic. The Rademacher complexity is easy to compute for small $N$. For large $N$, it can be computed for even larger sets of strategies using tools from numerical analysis.
The RAS procedure for signals uses the worst case $|\theta_S| \le 1$. In practice, however, it is extremely unlikely to observe IC close to one. IC greater than 0.1 is extremely unlikely. If we assume $|\theta_S| \le C \le 1$, and apply Theorem 8.3, the estimation term becomes smaller, by a factor of $c$.
$$ \text{“estimation error”} = 2 \epsilon_S \sqrt{\frac{\log(2/\delta)}{T}} $$
Consider some realistic parameters: $\epsilon_S = 0.02, \delta = 0.01$, and $T=2500$. Then the estimation error is about 0.002.
In the RAS procedure for strategies, the formula for the estimation error is rather simple and the constant factors are probably not too conservative. The error depends on the square root of $T$. For example, with $\delta=0.01, T=2500$ and $N=1.0\%$, then the estimation error is 0.03, corresponding to an annualized estimation error of $5\%$. The estimation error for $\delta=0.05$.
3.  The percentage of positive strategies, as per Equation (8.3).
4.  The percentage of Rademacher positives.
5.  The percentage of true positive strategies. This percentage is either 0 or 20%.
Figures 8.7 and 8.8 show the results for normally and subdistributed returns, respectively. We interpret the results below:
1.  For a fixed distribution of the population Sharpe, the maximum empirical Sharpe Ratio $\max_s \hat{\theta}_S$ is predictably increasing in $N$. It is also increasing in $\beta$ because the “effective” number of assets decreases, as the strategies are more correlated, and it is decreasing in $T$, by the Central Limit Theorem.
2.  Everything else equal, the Rademacher complexity is decreasing in $T$, by the Central Limit Theorem. It is interesting to compare the true $\hat{\mathcal{R}}_T$ from the simulations with the bound from Massart’s lemma. In Table 8.2, we report the highest $\hat{\mathcal{R}}_T$ from Table 8.3, and Massart’s bound is at most 15% higher than the observed Rademacher complexity.

**TABLE 8.2**
Comparison of “sup hat” and Massart’s bound

| N    | T    | "hold-italic cap r hat" | "hold-italic cap r hat" Massart's Bound |
| :--- | :--- | :---------------------- | :-------------------------------------- |
| 500  | 2500 | 0.020                   | 0.023                                   |
| 500  | 5000 | 0.017                   | 0.019                                   |
| 5000 | 2500 | 0.027                   | 0.030                                   |
| 5000 | 5000 | 0.021                   | 0.023                                   |
| 5000 | 7500 | 0.015                   | 0.018                                   |

---

**8.4 Some Empirical Results**

**8.4.1 Simulations**

Let us see how this approach performs in a simulated setting first. We first consider strategies whose returns are normally distributed, are iid (either across strategies or across time periods), and with correlation $\rho$. Specifically, the return of strategy $s$ in period $t$ is given by
$$ r_{s,t} = \rho f_t + \sqrt{1-\rho^2} \epsilon_{s,t} $$
with $f_t \sim N(0,1)$, $\epsilon_{s,t} \sim N(\mu_S, 1)$. $\mu_S$ are constants for different values of the population Sharpe Ratios, for different numbers of strategies, and for expected returns (and therefore non-annualized Sharpe Ratios) equal to 0 and 0.1. For each simulation, we report the maximum empirical Sharpe Ratio $\max_s \hat{\theta}_S$, the Rademacher complexity, the estimation error, and the percentage of detected positive strategies, i.e., of strategies whose lower bound of the 95% confidence interval of the true Sharpe Ratio. We also report the percentage of “Rademacher positive strategies,” i.e., the strategies that exceed the data-snooping haircut alone. In formula,
(8.6)
$$ \hat{\theta}_S - 2\hat{\mathcal{R}}_T(\mathcal{S}) > 0 \quad \text{(“positive”)} $$
(8.7)
$$ \hat{\theta}_S - 2\hat{\mathcal{R}}_T(\mathcal{S}) > 0 \quad \text{(“Rademacher positive”)} $$
We perform simulations with returns distributed both according to a Gaussian distribution and to a t-distribution with five degrees of freedom. The latter aims to approximate heavy-tailed returns. The simulations are performed for all possible combinations of the following parameters:
1.  Correlation: $\rho \in \{0.2, 0.8\}$.
2.  Number of strategies: $N \in \{500, 5000\}$.
3.  Number of periods: $T \in \{2500, 5000\}$.
4.  Population Sharpe: We consider two cases. In the first one, all strategies have SR = 0. In the second one, 80% have SR = 0, and 20% have SR = 0.2 (the Sharpe Ratio is not annualized).
For each effect, we use eight simulations. For each simulation we compute a historical return matrix $\mathbf{X}_s$. For each simulation we compute the following outputs:
*   $\max_s \hat{\theta}_S$, the maximum realized Sharpe Ratio across the strategies.
*   $\hat{\mathcal{R}}_T$, the Rademacher complexity of $\mathbf{X}_s$.

**TABLE 8.3**
Simulations for normally distributed returns

| rho | N    | T    | "hold-italic max over hat theta" | "hold-italic cap r hat" | "hold-italic est err" | Error % "hold-italic pos rad" | Error % "hold-italic pos true" |
| :-- | :--- | :--- | :------------------------------- | :---------------------- | :-------------------- | :---------------------------- | :----------------------------- |
| 0.2 | 500  | 2500 | 0.2                              | 0.019                   | 0.039                 | 0.0                           | 0.0                            |
| ... | ...  | ...  | ...                              | ...                     | ...                   | ...                           | ...                            |
| 0.8 | 5000 | 5000 | 0.2                              | 0.230                   | 0.010                 | 20.0                          | 20.0                           |

**TABLE 8.4**
Simulations for t-distributed returns

| rho | N    | T    | "hold-italic max over hat theta" | "hold-italic cap r hat" | "hold-italic est err" | Error % "hold-italic pos rad" | Error % "hold-italic pos true" |
| :-- | :--- | :--- | :------------------------------- | :---------------------- | :-------------------- | :---------------------------- | :----------------------------- |
| 0.2 | 500  | 2500 | 0.2                              | 0.016                   | 0.039                 | 0.0                           | 0.0                            |
| ... | ...  | ...  | ...                              | ...                     | ...                   | ...                           | ...                            |
| 0.8 | 5000 | 5000 | 0.2                              | 0.231                   | 0.010                 | 20.0                          | 20.0                           |

3.  The data-snooping term and the estimation error term have the same magnitude.
4.  In the null Sharpe case (all strategies have zero Sharpe Ratio), the percentage of detected positive cases (1% pos) is zero or nearly zero in all cases: there are no false positives.
5.  In the alternative Sharpe case (20% of strategies have Sharpe Ratio equal to 0.2), the percentage of true positives is smaller than the percentage of true positives. All detected positives are in fact true positives: the False Discovery Rate (FDR), defined as the ratio of false positives to all detected positives, is zero. In a few cases the percentage of positives is somewhat lower than the percentage of true positives.
6.  The percentage of Rademacher positives is much closer to the percentage of true positives. The FDR is still zero in this case.

---

**8.4.2 Historical Anomalies**

It is of independent interest to analyze anomalies published in the academic literature. We consider two sources of returns: the first (Jensen et al. (2021)) is a dataset of factor anomalies introduced by Hou et al. (2015), and test their replicability and out-of-sample performance. The dataset contains published characteristics, and it is not possible to know which characteristics were tested prior to publication. In principle, their variants should be included in the data. Had they been included, the Rademacher complexity of the dataset would have been higher. As criteria for inclusion, we required that the factor have at least 10 years of trading history, and that they be produced on the last day in the dataset, December 31, 2021. We perform the analysis at the country level. Table 8.5 presents the results. The table shows the number of strategies, the average percentage of true positives, which is common across a priori. The United Kingdom and Hong Kong are the only markets where a positive percentage of factors meet the Rademacher bound, Equation (8.6).

**TABLE 8.5**
Summary data for the factors in Jensen et al.’s database

| Country | N   | "hold-italic T" | max over hat theta | "hold-italic cap r hat" | Error % "hold-italic est err" | % "hold-italic pos rad" | % "hold-italic pos true" |
| :------ | :-- | :-------------- | :----------------- | :---------------------- | :---------------------------- | :---------------------- | :----------------------- |
| AUS     | 153 | 3584            | 0.058              | 0.046                   | 0.030                         | 0.0                     | 0.0                      |
| ...     | ... | ...             | ...                | ...                     | ...                           | ...                     | ...                      |
| ZAF     | 151 | 2876            | 0.092              | 0.047                   | 0.035                         | 0.0                     | 0.0                      |

Another source of factor return data is curated by Andrew (Chen and Zimmermann, 2022). Among the anomalies, we select those that were available as of the end of 2021 and had at least 5 years of history. The results are displayed in Table 8.6. The percentage of anomalies that meet the Rademacher bound is about 16%. The smaller percentage is attributable to the fact that the number of periods (days) with complete observations is 3931 (compared to 13,125 for the Jensen, Kelly, and Pedersen dataset) and to the Rademacher complexity being 0.033 (compared to 0.021 for the Jensen, Kelly, and Pedersen dataset).

**TABLE 8.6**
Summary data for the factors in Chen and Zimmermann’s database

| N   | "hold-italic T" | max over hat theta | "hold-italic cap r hat" | Error % "hold-italic est err" | % "hold-italic pos rad" | % "hold-italic pos true" |
| :-- | :-------------- | :----------------- | :---------------------- | :---------------------------- | :---------------------- | :----------------------- |
| 162 | 3931            | 0.126              | 0.033                   | 0.031                         | 0.0                     | 12.3                     |

---

**8.5 Appendix**

**8.5.1 Proofs for RAS**

We use some essential inequalities in the proofs. Standard references are Boucheron et al. (2013) and Vershynin (2018).

**Theorem 8.1 (McDiarmid's Inequality):**
Let $X_1, \dots, X_n$ be independent random variables, and $f: \mathbb{R}^n \to \mathbb{R}$, such that for each $i$,
$$ \sup_{x_1, \dots, x_n, x_i'} |f(x_1, \dots, x_i, \dots, x_n) - f(x_1, \dots, x_i', \dots, x_n)| \le c_i $$
Then, for all $\epsilon > 0$,
$$ P(|f - Ef| > \epsilon) \le 2 \exp \left( - \frac{2\epsilon^2}{\sum c_i^2} \right) $$
Specifically, if $c_i = c$, and with probability greater than $1-\delta/2$,
$$ f < Ef + \sqrt{\frac{nc^2 \log(\delta/2)}{2}} $$
A mean zero sub-Gaussian random variable $X$ is one for which a positive constant $c$ exists, such that the inequality
$$ P(|X| > \epsilon) \le 2 \exp(-\epsilon^2/(2c^2)) $$
holds for all positive $\epsilon$. The parameter $\sigma^2$ is the proxy variance.

**Theorem 8.2 (Generalized Hoeffding's Inequality):**
Let $X_1, \dots, X_n$ be iid random variables with finite sub-Gaussian norms and proxy $\sigma_i$. Then, for all $a_i > 0$,
(8.7)
$$ P \left( \left| \sum_{i=1}^n a_i (X_i - EX_i) \right| > t \right) \le 2 \exp \left( - \frac{t^2}{2 \sum a_i^2 \sigma_i^2} \right) $$
(8.8)
$$ \sup_{s \in \mathcal{S}} (\hat{\theta}_s - \theta_s) \le \phi(\dots, \mathbf{X}_s, \dots) + \frac{2\hat{\mathcal{R}}_T(\mathcal{S})}{T} $$
We apply McDiarmid’s inequality to $\phi$ to obtain the result. In order to obtain a lower bound on $E\phi$, we need an upper bound on $E\hat{\mathcal{R}}_T$. In the inequalities below, we introduce a probability measure $P'$ identical to, and independent from, $P$.
$$ E_P \phi_{sup} = E_P[\hat{\theta}_s] $$
$$ = E_P[\sup_{s \in \mathcal{S}} (\hat{\theta}_s(X) - \theta_s(X'))] $$
$$ = E_P[\sup_{s \in \mathcal{S}} (\hat{\theta}_s(X) - \hat{\theta}_s(X'))] \quad \text{(conditioning)} $$
$$ \le E_P E_{P'} [\sup_{s \in \mathcal{S}} (\hat{\theta}_s(X) - \hat{\theta}_s(X'))] \quad \text{(Jensen)} $$
$$ \le E_P E_{P'} [\sup_{s \in \mathcal{S}} \sum_{t=1}^T \epsilon_t (X_{s,t}(X) - X_{s,t}(X'))] $$
$$ = E_P E_{P'} [\sup_{s \in \mathcal{S}} \sum_{t=1}^T \epsilon_t X_{s,t}(X)] + E_P E_{P'} [\sup_{s \in \mathcal{S}} \sum_{t=1}^T \epsilon_t (-X_{s,t}(X'))] $$
We introduce an additional source of noise (a Rademacher matrix) and have a constant $K$. We can gain in tractability. We can change the signs of each summand by multiplying by some arbitrary factor $K \in [-1,1]$, since the terms are exchangeable.
$$ = E_P E_{P'} [\sup_{s \in \mathcal{S}} \sum_{t=1}^T \epsilon_t X_{s,t}(X)] + E_P E_{P'} [\sup_{s \in \mathcal{S}} \sum_{t=1}^T \epsilon_t' X_{s,t}(X')] $$
$$ \le E_P E_{P'} [\sup_{s \in \mathcal{S}} \sum_{t=1}^T \epsilon_t X_{s,t}(X)] + E_P E_{P'} [\sup_{s \in \mathcal{S}} \sum_{t=1}^T \epsilon_t' X_{s,t}(X')] $$
$$ = 2 E_P \hat{\mathcal{R}}_T $$
since we defined $\hat{\mathcal{R}}$ as the expected value of the Rademacher complexity over the distribution of performance realizations.
We now use McDiarmid again for all $P_s \in \mathcal{S}$.

(Right Sidebar from Page 375)
**Theorem 8.3 (Bounds for bounded performance metrics):**
Assume that $|\theta_{s,t}| \le c_s$ for all $s \in \mathcal{S}$, $t=1, \dots, T$.
For all $n=1, \dots, N$,
(8.8)
$$ \theta_n \ge \hat{\theta}_n - 2\hat{\mathcal{R}} - 3c_n \sqrt{\frac{2\log(2/\delta)}{T}} $$
Proof
The straightforward inequality holds for all $n=1, \dots, N$:
$$ \theta_n - \hat{\theta}_n \ge \sup_n |\theta_n - \hat{\theta}_n| - |\hat{\theta}_n - \theta_n| $$
Define
$$ \Phi := \sup_n |\theta_n - \hat{\theta}_n| $$
$$ \phi := \sup_n (\hat{\theta}_n - \theta_n) $$
We claim that with probability greater than $1-\delta/2$,
(8.10)
$$ \Phi \le E\Phi + c_n \sqrt{\frac{2\log(2/\delta)}{T}} $$
This allows one to deal with $E\Phi \approx E\phi_n - \theta_n$, which is easier. To prove the inequality, note that, for all $X_{s,t} \in [-c_s, c_s]$, $t=1, \dots, T$, $i=1, \dots, N$
(8.11)
$$ |\hat{\theta}_{s,t} (\dots, X_{s,t}, \dots) - \hat{\theta}_{s,t} (\dots, X'_{s,t}, \dots)| \le \frac{2c_s}{T} $$
from which it follows that
$$ |\hat{\mathcal{R}}(\dots, X_{s,t}, \dots) - \hat{\mathcal{R}}(\dots, X'_{s,t}, \dots)| \le \frac{2c_s}{T} $$
Hence, with probability greater than $1-\delta/2$
(8.12)
$$ \hat{\mathcal{R}} \le E\hat{\mathcal{R}} + c_n \sqrt{\frac{2\log(2/\delta)}{T}} $$
Now we employ the union bound on inequalities (8.10) and (8.12) to obtain the claim.

**Theorem 8.4 (Bounds for Sub-Gaussian performance metrics):**
Assume that
$$ P(|X_{s,t}| > \epsilon) \le 2e^{-\epsilon^2/(2\sigma_s^2)} $$
for all $s > 0$, for $n=1, \dots, N$, $t=1, \dots, T$.
Then, for all $s \in \mathcal{S}$,
$$ \theta_s - \hat{\theta}_s \ge -2\hat{\mathcal{R}} - 3\sigma_s \sqrt{\frac{2\log(2N/\delta)}{T}} $$
Proof
Let $a > 0$. We split $\theta_s - \hat{\theta}_s$ into the sum of two terms:
$$ \theta_s - \hat{\theta}_s = g(X^s, a) + h(X^s, a) $$
where
$$ g(X^s, a) := E_P[\sup_{s \in \mathcal{S}} (\hat{\theta}_s(X) - \theta_s(X)) \mathbb{I}(|\hat{\theta}_s(X) - \theta_s(X)| \le a)] $$
$$ h(X^s, a) := E_P[\sup_{s \in \mathcal{S}} (\hat{\theta}_s(X) - \theta_s(X)) \mathbb{I}(|\hat{\theta}_s(X) - \theta_s(X)| > a)] $$
We bound $P(\sup_s |h(X^s,a)| \ge \epsilon)$
By symmetrization
The random variable $h(X_s, a)$ is sub-Gaussian, since it is dominated by $|X_s|$. Both probability $X_s$ and $h$ has the same proxy variance as $|X_s|$. By the general Hoeffding inequality,
$$ P \left( \left| \sum_{t=1}^T h(X_{s,t}, a) \right| > t \right) \le \exp(-T t^2/(2\sigma_s^2)) $$
$$ P \left( \sup_{s \in \mathcal{S}} \left| \sum_{t=1}^T h(X_{s,t}, a) \right| > t \right) \le N \exp(-T t^2/(2\sigma_s^2)) $$
By the union bound,
(8.13)
$$ \hat{\theta}_S \ge \hat{\theta}_S - 2\hat{\mathcal{R}} - 3\sigma_S \sqrt{\frac{2\log(2N/\delta)}{T}} - \frac{a}{T} $$
probability $1-\delta$.
The reduced performance metric is guaranteed to be greater than or equal to the true performance metric with probability $1-\delta$.
The haircut is the sum of a “data-snooping term,” a function of the set of strategies, and an “estimation term,” function of the sampling interval.

**The Takeaways**

*   Strategy performance of systematic strategies is usually validated against historical data. Historical data is often scarce, whereas the number of strategies being tested can be extremely large. We reuse the same data to test and tune strategies.
*   Two core principles of an effective backtesting process are:
    1.  Perform careful data sourcing.
    2.  Use a backtesting protocol that ensures that the historical simulation reproduces the run of the same strategy in the real world.
*   Common backtesting procedures are cross-validation and walk-forward.
*   We propose an alternative procedure: the Rademacher Anti-Serum (RAS).
*   RAS provides a “haircut”, i.e., term that is subtracted from the empirical performance metric of every strategy. This haircut depends on $T$.

**Notes**

1.  [1] Assuming 6.5 trading hours, 252 trading days, and 3000 stocks.
2.  [2] Although, you may argue, this whole book is an exposition of my investment philosophy. Point taken, to an extent. I am providing some building blocks, and you are reshaping and assembling them into something sensible.
3.  [3] The Information Coefficient is formally defined in Section 8.3.
4.  [4] In order to short a security, the investor (or an agent on their behalf, like a broker-dealer) must borrow it first from a lender, who charges interest on the loan.
5.  [5] This is the percentage of simulation samples for which the condition $\text{SR} > 2.3 \sqrt{(1+SR^2)/T}$
6.  [6] The $\hat{\mathcal{R}}_T$ is featured prominently in Section 8.3.
7.  [7] For definitions and use of $\alpha$-mixing, see e.g., Cont (2001) and Taylor (2008).
8.  [8] See Section 7.2 and references therein, for example, Cont (2001) and Taylor (2008).
9.  [9] The estimation error of Equation (8.4) for $\delta=0.05$ and $SR=1.0\%$ is. The estimation error is independent of $N$ is smaller than for $\delta=0.01$.
    $$ 2 \sqrt{\frac{\log(2N/\delta)}{T}} \le 0.6 \times 3.3 \sqrt{\frac{\log(2/\delta)}{T}} $$
    , and is very weakly dependent on $N$.
10. [10] Data downloaded from https://www.aeaweb.org/journals/aer/data/106-12_data.zip, on August 20, 2022.
11. [11] Data downloaded from https://www.aeaweb.org/articles?id=10.1257/aer.20191645, on August 20, 2022.

```

Okay, here is the Markdown compilation for Chapter 9.
     Everand

**Chapter 9**
**Portfolio Management: The Basics**

**The Questions**

1.  Why is Mean-Variance Optimization (MVO) widely used in portfolio construction, and what are its main assumptions and limitations?
2.  How does the structure of the utility function impact investment decisions, specifically in terms of expected return and risk?
3.  How do we add factor risk to MVO? What does it mean to trade in factor space and in idio space?
4.  How do we add a factor to the model?
5.  How does the Information Ratio relate to an investor’s skill (Information Coefficient) and the diversification of a portfolio?
6.  Should a centralized approach to portfolio management be used over a decentralized one, and under what conditions are they equivalent?

This chapter is devoted to the basics of portfolio construction. The common theme throughout the chapter is that we limit ourselves to a single-period optimization setting. This is a chapter for hedgehogs, not for foxes: we set a narrow playing field, but dig a deep hole. The chapter requires knowledge of basic results from optimization theory.[1]

---

**9.1 Why Mean-Variance Optimization?**

Investors have objectives, information, and constraints. Besides this generic statement, there is not much in common among them. A large fraction of investment professionals cannot—and would not—articulate a clear objective function; their constraints are sometimes ad hoc, vague, or inconsistently enforced. Neither George Soros nor Warren Buffett, nor others among the most successful investors in recent history, would have used the tools of this chapter at any point in their career. At the other extreme, academics have applied optimization techniques for portfolio construction. In this book I use relevance to applications as a guiding principle. In the vast majority of applications, the optimization formulations are single-period. This is explainable by a combination of the following:
*   Interpretability. Multi-period optimization problems are vastly more complex to formulate and, once solved, their solutions are also harder to interpret.
*   Data availability. The amount of data needed for multi-period optimization is larger and more difficult to estimate.
*   Computational tractability. Single-period optimization problems are solvable by commercial solvers in a matter of seconds.
*   Usefulness. Multi-period optimization problems are all about the short term, partly because they heavily discount future information, partly because they do not know how to quantify information uncertainty and rate of change.

The objective function $E[u(W)]$ is a function of the portfolio weights via the end-of-period wealth $W$. The objective function $E[u(W)]$ is a utility function, taking different values under different realizations of the future. The expected value of the utility function gives the investor the ex-ante value of the utility. She would be taking by investing in a portfolio. We assume that the investor has initial wealth $W_0$, that she knows the distribution of the random vector $r$, and that she solves the problem
(9.1)
$$ \max_{\mathbf{w}} E[u(W_0 + \mathbf{w}^T \mathbf{r})] $$
The choice of $u(W)$ is not obvious. Common properties of $u'(W) > 0$ that it must be monotonically increasing (more wealth is better than less) and concave (corresponding to risk aversion, and to decreasing value of a marginal dollar as a function of wealth). One approach, followed by Markowitz (1952), is to consider a polynomial approximation of the utility function. If we assume that the investor’s utility is well approximated by a second-order Taylor expansion, then
$$ E[u(W_0 + \mathbf{w}^T \mathbf{r})] \approx u(W_0) + u'(W_0) E[\mathbf{w}^T \mathbf{r}] + \frac{1}{2} u''(W_0) E[(\mathbf{w}^T \mathbf{r})^2] $$
$$ E[V_0(W_0 + \mathbf{w}^T \mathbf{r})] = V_0(W_0) + V_0'(W_0) E[\mathbf{w}^T \mathbf{r}] + \frac{V_0''(W_0)}{2} (\mathbf{w}^T \Omega_r \mathbf{w} + (E[\mathbf{w}^T \mathbf{r}])^2) $$
$$ = V_0(W_0) + V_0'(W_0) E[\mathbf{w}^T \mathbf{r}] + \frac{V_0''(W_0)}{2} \mathbf{w}^T \Omega_r \mathbf{w} $$
We maximize a concave quadratic objective function which is the weighted sum of expected return and variance; hence the name Mean-Variance Optimization (MVO) (De Finetti, 1940; Markowitz, 1952)
$$ E[V_0(W_0 + \mathbf{w}^T \mathbf{r})] - V_0(W_0) = V_0'(W_0) \mathbf{w}^T \mu_r - \frac{\rho}{2} \mathbf{w}^T \Omega_r \mathbf{w} $$
$$ \rho = - \frac{V_0''(W_0)}{V_0'(W_0)} $$
$\rho > 0$ is called the coefficient of absolute risk aversion (CARA). The higher the $\rho$, the more risk-averse the investor is.
As examples, consider an objective function of the form
$$ V(x) = -\exp(-ax) $$
The CARA for this function is constant $\rho = a$. It is independent of the wealth $W_0$ of the investor and so are her allocation decisions. The optimization problem is
$$ \max_{\mathbf{w}} \mathbf{w}^T \mu_r - \frac{a}{2} \mathbf{w}^T \Omega_r \mathbf{w} $$
Alternatively, consider the objective function $V(x) = \log(x)$. This function is associated to the fully criterion for investing. It has unique properties which warrant a dedicated chapter. Here, let us consider its implications for approximate portfolio optimization. The CARA is $\rho_W = 1/W_0$, so that we solve
$$ \max_{\mathbf{w}} \mathbf{w}^T \mu_r - \frac{1}{2W_0} \mathbf{w}^T \Omega_r \mathbf{w} $$
The wealthier the investor is, the more risk-seeking she becomes.
We have shown that a quadratic utility function implies a mean-variance optimization problem for the investor. This result is standard. Less known is the converse: an investor selects an investment on the basis of mean and variance if and only if her utility function is quadratic (Chamberlain, 1983; Owen and Rabinovitch, 1983). Viewed in the context of axiomatic decision theory, portfolio MVO is not satisfactory, because a quadratic utility implies that investors are satiated, and have even a dislike of wealth beyond a certain threshold. As a local approximation, however, the quadratic approximation is useful. Indeed, the results derived from MVO are robust to the realm of what is plausible, as seen in Chapter 3. A portfolio manager settled a long discussion on the topic with the laconic statement that “the first two moments should be enough for everybody”.

---

**9.2 Mean-Variance Optimal Portfolios**

A factor model gives us an asset-asset covariance matrix $\Omega_r \in \mathbb{R}^{N \times N}$. Given this information, it is straightforward to compute the variance portfolio, as set out in Section 3.2, for risk decomposition. The other essential input to the optimization problem is a vector $\alpha \in \mathbb{R}^N$ of expected returns, over the same interval at which we have a volatility forecast. The simplest optimization problem is to maximize expected PnL, subject to a constraint on the maximum tolerable volatility, denoted by $\sigma^2$. The problem can be stated as
(9.2)
$$ \max_{\mathbf{w}} \alpha^T \mathbf{w} $$
$$ \text{s.t. } \mathbf{w}^T \Omega_r \mathbf{w} \le \sigma^2 $$
One of the most important metrics used for the evaluation of strategies is the Sharpe Ratio. If we have covariance matrix and expected returns, we can formulate the Sharpe Ratio optimization thus:
$$ \max_{\mathbf{w}} \frac{\alpha^T \mathbf{w}}{\sqrt{\mathbf{w}^T \Omega_r \mathbf{w}}} $$
This optimization, however, is indefinite because the objective function $\text{SR}(\mathbf{w})$ is independent of the portfolio size, i.e., homogeneous of degree 0: $\text{SR}(c\mathbf{w}) = \text{SR}(\mathbf{w})$ for $c > 0$. We can address this issue by adding the constraint that the portfolio has unit volatility. The additional condition the denominator is always binding if there is a portfolio $\mathbf{w}^*$ such that $\alpha^T \mathbf{w}^* > 0$.
$$ \max_{\mathbf{w}} \frac{\alpha^T \mathbf{w}}{\sqrt{\mathbf{w}^T \Omega_r \mathbf{w}}} $$
$$ \text{s.t. } \sqrt{\mathbf{w}^T \Omega_r \mathbf{w}} \le \sigma $$
equivalent to $\max_{\mathbf{w}} \frac{\alpha^T \mathbf{w}}{\sigma}$
$$ \text{s.t. } \mathbf{w}^T \Omega_r \mathbf{w} \le \sigma^2 $$
equivalent to $\max_{\mathbf{w}} \alpha^T \mathbf{w}$
$$ \text{s.t. } \mathbf{w}^T \Omega_r \mathbf{w} \le \sigma^2 $$
which is Optimization Problem (9.2). The First-Order Necessary Conditions (FONCs) for this problem are
$$ \nabla_{\mathbf{w}} (\alpha^T \mathbf{w} - \lambda \mathbf{w}^T \Omega_r \mathbf{w}) = \alpha - 2\lambda \Omega_r \mathbf{w} = 0 $$
$$ \mathbf{w}^T \Omega_r \mathbf{w} \le \sigma^2 $$
$$ \lambda \ge 0 $$
$$ \lambda(\mathbf{w}^T \Omega_r \mathbf{w} - \sigma^2) = 0 $$
The solution to these equations is
(9.3)
$$ \mathbf{w}^* = \frac{\sigma}{\sqrt{\alpha^T \Omega_r^{-1} \alpha}} \Omega_r^{-1} \alpha $$
(9.4)
$$ \lambda^* = \frac{\sqrt{\alpha^T \Omega_r^{-1} \alpha}}{2\sigma} $$
The expected return and the Sharpe Ratio of the portfolio are
(9.5)
$$ E(\mathbf{r}^T \mathbf{w}^*) = \sigma \sqrt{\alpha^T \Omega_r^{-1} \alpha} $$
(9.6)
$$ \text{SR}^* = \sqrt{\alpha^T \Omega_r^{-1} \alpha} $$
A way to interpret (and derive quickly) the solution is to recall that the optimal portfolio is proportional to $\Omega_r^{-1} \alpha$, and then to find the proportionality factor so that the variance constraint is met. The optimization problem is proportional to the volatility target $\sigma$. The larger the budget, the larger the return. However, the Sharpe Ratio is independent of the magnitude of the alpha vector (it is homogeneous of degree zero in alpha), replacing $\alpha$ with $c\alpha$ gives the same solution. This is interesting.

**Insight 9.1: Misallocation of alpha size is not catastrophic**
If you have a volatility constraint, a good volatility model, and your relative alphas are accurate, then the error in the absolute size of the alphas does not matter.

The parameter $\lambda^*$ also merits special consideration. It is the shadow price (or Lagrange multiplier) of the volatility constraint. If we increase the variance constraint by one unit, the expected return increases by $\lambda^*$. In other terms, the shadow price of the variance constraint is the derivative of the objective function with respect to the variance. This relationship is not very useful in this specific case; it will come handy in other cases.
In its simplicity, the solution contains the essential data of the problem: the inverse of the covariance matrix (also called the precision matrix), and the vector of expected returns. In the next few pages we will interpret, extend, and use this simple functional form. And finally, as we start believing it is useful, we will caution you against its unconditional use. Like all good things in life, MVO is at its most pleasant when it is accompanied by precautionary measures.

**Insight 9.2: MVO from ex-post Sharpe and correlations**
There is yet another formulation that is equivalent to the previous ones. Oftentimes, we think of portfolio positions not in terms of NAVs, but of volatility. We do not invest $10M in AAPL. The annualized volatility of AAPL is 20%, and therefore we have a $2M volatility position in the stock. This convention is useful when we want to manage the risk of the portfolio over the course of a year. Now, we can express the Sharpe-optimal portfolio in terms of volatility in the following way. Let the stock volatilities be $D_v = \text{diag}(\sigma_1, \dots, \sigma_N)$, and define $V_s$ a diagonal matrix whose entries are the volatilities to be chosen. Then, the optimal dollar-volatility allocation is $\mathbf{v} = D_v \mathbf{w}$. Now rewrite the solution to the MVO problem:
(9.7)
$$ \mathbf{w}^* = \frac{1}{2\lambda^*} (\mathbf{V} C \mathbf{V})^{-1} \alpha $$
$$ \mathbf{V} \mathbf{w}^* = \frac{1}{2\lambda^*} C^{-1} \mathbf{V}^{-1} \alpha $$
$$ \mathbf{v}^* = \frac{1}{2\lambda^*} C^{-1} \mathbf{s} $$
(9.8) $\text{SR}^* = \sqrt{\mathbf{s}^T C^{-1} \mathbf{s}}$ is the vector of optimal dollar volatilities. $\mathbf{s}$ is the vector of ex-post Sharpe Ratios. Therefore, the optimal dollar volatilities are proportional to the Sharpe Ratios, multiplied by the inverse of the correlation matrix. This is interesting, because dollar volatilities, rather than NAVs, are more intuitive quantities than constraints, and correlations.
First of all, we can derive the same solution when we solve an unconstrained problem:
(9.9)
$$ \max_{\mathbf{w}} \alpha^T \mathbf{w} - \frac{\lambda}{2} \mathbf{w}^T \Omega_r \mathbf{w} $$
s.t. $\mathbf{w} \in \mathbb{R}^N$
We have added the constraint to the objective function in the form of a penalty term; the informal term for this operation is giving out the constraint. The objective function is concave, and the solution is given by
$$ \mathbf{w}^* = \frac{1}{\lambda} \Omega_r^{-1} \alpha $$
which gives the same solution as the vol-constrained problem when
$$ \lambda = \frac{\sqrt{\alpha^T \Omega_r^{-1} \alpha}}{2\sigma} $$
The larger the volatility budget, the smaller the penalty coefficient.
Notice that this penalty value is the same as the shadow price in the previous formulation. This is not a coincidence. We obtain the same solution when we price out the constraint and we give the variance a unit price equal to the shadow price of that constraint.
A third equivalent formulation is the one where we minimize volatility, subject to a return constraint:
(9.10) $\min_{\mathbf{w}} \mathbf{w}^T \Omega_r \mathbf{w}$
(9.11) s.t. $\alpha^T \mathbf{w} \ge \mu$
The solution is
$$ \mathbf{w}^* = \frac{\mu}{\alpha^T \Omega_r^{-1} \alpha} \Omega_r^{-1} \alpha $$

**Insight 9.3: Asset correlations, dispersion, and limits to performance**
From Equation (9.8), when assets are uncorrelated, the optimal dollar-vol allocation is proportional to the asset Sharpe Ratios and the correlation matrix is the identity matrix $C=I_N$. Which is not true when the assets are correlated. If two assets have a positive correlation $\rho > 0$, then the optimal volatility allocated to asset $j$ in the two-asset case (and only) is proportional to the excess Sharpe Ratio of the asset, compared to the excess Sharpe Ratio of the asset, compared to the other one:
$$ v_j \propto S_j - \rho S_i $$
where we define $S_j = \text{SR}_j / \sqrt{1-\rho^2}$. The optimal Sharpe Ratio is
$$ \text{SR}^* = \sqrt{\frac{1}{1-\rho^2}} \sqrt{\text{var}(S) + \frac{n}{1+(n-1)\rho} E^2(S)} $$
with
$$ \text{var}(S) = E(S^2) - E^2(S) $$
If all assets have the same Sharpe Ratio $s$, then
$$ \text{SR}^* = \sqrt{\frac{ns^2}{1+(n-1)\rho}} $$
Finally, in the many-asset limit, we have $\text{SR}^* \approx s/\sqrt{\rho}$.
Summing up the results above:
1.  If there is no dispersion in Sharpe Ratios, then the Sharpe Ratio approaches an upper bound $s/\sqrt{\rho}$.
2.  If there is dispersion in Sharpe Ratios, then the Sharpe Ratio is still proportional to $\sqrt{N}$, and to the dispersion, measured as the cross-sectional standard deviation of the assets’ Sharpe Ratios.
3.  To prove this directly, verify that the inverse of the correlation matrix is
    $$ C^{-1} = \frac{1}{1-\rho} \left( I_N - \frac{\rho}{1+(n-1)\rho} \mathbf{e} \mathbf{e}^T \right) $$

**Insight 9.4: Reading the entries of the precision matrix**
Is there a way to interpret further the relationship $\mathbf{w}^* \propto \Omega_r^{-1} \alpha$? The optimal position of asset $i$ is a weighted sum of alphas. The $P_{ij} = (\Omega_r^{-1})_{ij}$ are proportional to minus the partial correlation of the returns of $i$ and $j$, after controlling for the effect of all other assets. The interpretation of partial correlation is that it captures collinearity between two random variables, after removing the collinearity of these variables with a set of controlling variables. In practice, one follows this procedure: regress the returns of asset $i$ and $j$ on the returns of the other assets, and compute the correlation between the residuals from the two regressions, which we denote $A_{ij}$. The formula for the optimal portfolio is
$$ \mathbf{w}_i^* \propto (\Omega_r^{-1})_{ii} \alpha_i - \sum_{j \ne i} (\Omega_r^{-1})_{ij} \alpha_j $$
The diagonal terms of the precision are always positive. The interpretation of this, rather counterintuitive formula is that, whenever the returns of two assets are positively correlated after removing the joint effect of correlations with other variables, the size of the portfolio is reduced. Because the collinearity makes the alpha common to both assets and $j$.

---

**9.3 Trading in Factor Space**

**9.3.1 Factor-Mimicking Portfolios**

We have a factor model, and we estimate the expected factor returns $\hat{\lambda}$. Say that we want to generate a portfolio which has unit positive exposure to one of the factors, say factor $k$, and zero exposure to all other factors. This portfolio is called the Factor-Mimicking Portfolio (FMP). We should be clear that the returns of the Factor-Mimicking Portfolio should be as close as possible to those of the factor. The variance of the difference of the returns should be minimized. A portfolio $\mathbf{w}$ has an associated factor exposure $\mathbf{b}_k = \mathbf{B}^T \mathbf{w}$. Its returns are $\mathbf{w}^T \mathbf{r} = \mathbf{w}^T \alpha + \mathbf{b}^T \mathbf{f} + \mathbf{w}^T \mathbf{\epsilon}$. The tracking variance between $\hat{f}_k$ and $\mathbf{w}^T \mathbf{r}$ is $E[(\hat{f}_k - (b_k - 1)f_k - \sum_{j \ne k} b_j f_j + \mathbf{w}^T \mathbf{\epsilon})^2]$. This is minimized when $b_k=1, b_j=0, j \ne k$, and the portfolio’s idiosyncratic variance is minimized. The optimization formulation is
$$ \min_{\mathbf{w}} \mathbf{w}^T \Omega_\epsilon \mathbf{w} $$
$$ \text{s.t. } \mathbf{B}^T \mathbf{w} = \mathbf{e}_k $$
The solution is
$$ \mathbf{v}_k = \Omega_\epsilon^{-1} \mathbf{B} (\mathbf{B}^T \Omega_\epsilon^{-1} \mathbf{B})^{-1} \mathbf{e}_k $$
The matrix whose column vectors are the FMPs is $\mathbf{P} \in \mathbb{R}^{N \times K}$ (“portfolio for factors”).
(9.12)
$$ \mathbf{P} := [\mathbf{v}_1 \quad \mathbf{v}_2 \quad \dots \quad \mathbf{v}_K] $$
$$ = \Omega_\epsilon^{-1} \mathbf{B} (\mathbf{B}^T \Omega_\epsilon^{-1} \mathbf{B})^{-1} [\mathbf{e}_1 \quad \mathbf{e}_2 \quad \dots \quad \mathbf{e}_K] $$
$$ = \Omega_\epsilon^{-1} \mathbf{B} (\mathbf{B}^T \Omega_\epsilon^{-1} \mathbf{B})^{-1} $$
We now have portfolios as tradable instruments. The expected return of a factor portfolio is
$$ (\alpha^T + \lambda^T \mathbf{B}^T) \mathbf{P} \mathbf{e}_k = \lambda_k $$
In practice, we:
1.  generate the FMPs compositions over time;
2.  compute their per-period PnL;
3.  compute their empirical average PnL;
4.  apply modifications to the expected PnL, such as penalties;
5.  now prove that FMPs emerge naturally from certain assumptions about returns and FMP composition, which we use in the Appendix, Section 9.7.2. We prove that if alpha spanned and zero if the idiosyncratic variance is small, then the MVO problem reduces to one in which we only trade FMPs. First, we solve the new-dimensional optimization problem
    $$ \max_{\mathbf{u}} \lambda^T \mathbf{u} - \frac{1}{2\gamma} \mathbf{u}^T \Omega_f \mathbf{u} $$
    $$ \text{s.t. } \mathbf{u} \in \mathbb{R}^m $$
    Say that the solution is $\mathbf{u}^*$. The optimal portfolio is the weighted sum of the FMPs: $\mathbf{w}^* = \mathbf{P} \mathbf{u}^*$. A few remarks on the appeal and limitations of the previous result:
    *   In factor space, the dimensionality of the problem collapses, but we still have an MVO problem, which is usually more interpretable. The problem is still an MVO problem, but in factor space. We can solve this, but to do so is possible only when we proceed in Chapter 7.
    *   FMPs make their appearance as the necessary synthetic instruments for trading in factor space. In synthesis, if we perform MVO and factor risk is sufficiently low (having low-idiosyncratic risk), then we necessarily trade FMPs. This means that the optimal portfolio is a linear map in mind that FMPs are associated to the loadings matrix $\mathbf{B}$; and there are many loadings matrices resulting in equivalent factor models (see Section 4.4). Think of FMPs as a vector basis in a finite-dimensional space. There are infinitely many such bases, and they don’t need to be orthogonal. This factor-based viewpoint is currently stifled.
    *   The assumption of small factor idiosyncratic variance can be expressed as
        $$ \| (\mathbf{B}^T \Omega_\epsilon^{-1} \mathbf{B})^{-1} \| < 1 $$
    The matrix inside the norm appears repeatedly in this book—in an ideal world we would like it to be small, but in the real world it is not. The observed values could be as large as a factor of 100. This is the main challenge of the portfolio construction, and not solve for the ideal case.
    *   In conjunction with the previous point, we have also ignored execution costs. They should not be ignored in applications. Chapter 10 is devoted to this subject.

---

**9.3.2 Adding, Estimating, and Trading a New Factor**

Let us consider an instructive example, and we work through the individual steps in a way, all the steps are implicitly contained in the theory developed so far. The starting point is a factor model with $m$ factors, with parameters $\mathbf{B}_m, \Omega_f, \alpha_m$. We assume that they are constant through time for notational simplicity, extending the example to time-varying parameters is straightforward. The factors have expected returns $\lambda_m$. We are exploring a new asset characteristic vector $\mathbf{a} \in \mathbb{R}^N$, and we would like to add it as a factor. We could add it to the existing model without orthogonalizing it to the existing model by pushing out the model.
1.  Orthogonalization. First we orthogonalize the new factor to the existing factors. The orthogonalized factor is given by standard linear regression formulas:
    $$ \mathbf{b}_{m+1} = (I_N - \mathbf{B}_m (\mathbf{B}_m^T \mathbf{B}_m)^{-1} \mathbf{B}_m^T) \mathbf{a} $$
2.  Estimation. Next, we regress in every period the residual returns from the existing model against the orthogonalized factor by using the Frisch-Waugh-Lovell Theorem:[8]
    (9.13)
    $$ \hat{\epsilon}_t = \mathbf{b}_{m+1} f_{m+1,t} + \mathbf{\epsilon}_{m+1,t} $$
    (9.14)
    $$ \hat{f}_{m+1,t} = \frac{\mathbf{b}_{m+1}^T \Omega_{\epsilon,m}^{-1} \hat{\epsilon}_t}{\mathbf{b}_{m+1}^T \Omega_{\epsilon,m}^{-1} \mathbf{b}_{m+1}} $$
    (9.15)
    $$ \hat{\lambda}_{m+1} = \frac{1}{T} \sum_{t=1}^T \hat{f}_{m+1,t} $$
    (9.16)
    $$ \hat{\sigma}_{m+1}^2 = \frac{1}{T} \sum_{t=1}^T (\hat{f}_{m+1,t} - \hat{\lambda}_{m+1})^2 $$
    (9.17)
    $$ \hat{\Omega}_{\epsilon, m+1} = \hat{\Omega}_{\epsilon,m} - \frac{\hat{\sigma}_{m+1}^2}{\mathbf{b}_{m+1}^T \Omega_{\epsilon,m}^{-1} \mathbf{b}_{m+1}} \mathbf{b}_{m+1} \mathbf{b}_{m+1}^T $$
    In the Appendix (Theorem 9.2), we show that the approximate variance of the new factor is
    $$ \sigma_{m+1}^2 = (\mathbf{b}_{m+1}^T \Omega_{\epsilon,m}^{-1} \mathbf{b}_{m+1})^{-1} $$
3.  Risk updating. We show in Section 9.7.2 that the approximate factor covariance matrix including the new factor is given by
    $$ \hat{\Omega}_f \approx \begin{bmatrix} \hat{\Omega}_{f,m} & \mathbf{0} \\ \mathbf{0}^T & (\mathbf{b}_{m+1}^T \Omega_{\epsilon,m}^{-1} \mathbf{b}_{m+1})^{-1} \end{bmatrix} $$
    This result holds only for constant parameters and well-diversified factor portfolios. For time-varying models, we need to resort to numerical estimation for the factor covariance matrix. The analytical results provide a useful approximation.
4.  Trading. The FMP of the new factor is
    $$ \mathbf{v}_{m+1,t} = \frac{\Omega_{\epsilon,m}^{-1} \mathbf{b}_{m+1}}{\mathbf{b}_{m+1}^T \Omega_{\epsilon,m}^{-1} \mathbf{b}_{m+1}} $$
    This follows from the definition of FMPs, Equation (9.12). A faster route is via the factor return estimation above. The factor return estimate is the same whether we regress using residual returns or total returns:[9]
    $$ \hat{f}_{m+1,t} = \frac{\mathbf{b}_{m+1}^T \Omega_{\epsilon,m}^{-1} \mathbf{r}_t}{\mathbf{b}_{m+1}^T \Omega_{\epsilon,m}^{-1} \mathbf{b}_{m+1}} $$
    $$ = \mathbf{v}_{m+1,t}^T \mathbf{r}_t $$
    Let $\tilde{\lambda} = (\lambda_m, \lambda_{m+1})$. Finally, we solve the optimization problem
    $$ \max_{\mathbf{u}} \tilde{\lambda}^T \mathbf{u} - \frac{1}{2\gamma} \mathbf{u}^T \tilde{\Omega}_f \mathbf{u} $$
    $$ \text{s.t. } \mathbf{u} \in \mathbb{R}^{m+1} $$
    whose solution is simple, because of the block structure of the factor covariance matrix
    $$ \mathbf{u}^* = \gamma \begin{bmatrix} (\hat{\Omega}_{f,m})^{-1} \lambda_m \\ (\mathbf{b}_{m+1}^T \Omega_{\epsilon,m}^{-1} \mathbf{b}_{m+1}) \lambda_{m+1} \end{bmatrix} $$
    So, our investment in the pre-existing factors is unchanged, but we add a position in the new factor, proportional to the expected factor return divided by its variance.

**Procedure 9.1: Adding a new factor to a model and trading it**
1.  Inputs: a factor model ($\mathbf{B}_m, \Omega_f, \Omega_{\epsilon,m}, \alpha_m$), with expected factor returns $\lambda_m$; raw loadings for the new factor $\mathbf{a}$.
2.  Orthogonalize the factor:
    $$ \mathbf{b}_{m+1,t} = (I_N - \mathbf{B}_m (\mathbf{B}_m^T \mathbf{B}_m)^{-1} \mathbf{B}_m^T) \mathbf{a}_t $$
3.  Compute the FMP:
    $$ \mathbf{v}_{m+1,t} = \frac{\Omega_{\epsilon,m}^{-1} \mathbf{b}_{m+1,t}}{\mathbf{b}_{m+1,t}^T \Omega_{\epsilon,m}^{-1} \mathbf{b}_{m+1,t}} $$
    $$ \hat{\lambda}_{m+1} = \frac{1}{T} \sum_{t=1}^T \mathbf{v}_{m+1,t}^T \mathbf{r}_t $$
4.  Compute new factor covariance matrix:
    $$ \hat{\Omega}_f \approx \begin{bmatrix} \hat{\Omega}_{f,m} & \mathbf{0} \\ \mathbf{0}^T & (\mathbf{b}_{m+1}^T \Omega_{\epsilon,m}^{-1} \mathbf{b}_{m+1})^{-1} \end{bmatrix} $$
5.  Compute new weights for FMPs:
    $$ \mathbf{u}^* = \gamma \begin{bmatrix} (\hat{\Omega}_{f,m})^{-1} \lambda_m \\ (\mathbf{b}_{m+1}^T \Omega_{\epsilon,m}^{-1} \mathbf{b}_{m+1}) \lambda_{m+1} \end{bmatrix} $$
and trade portfolios.
$$ \mathbf{w}_t = [\mathbf{v}_{1,t} \quad \dots \quad \mathbf{v}_{m,t} \quad \mathbf{v}_{m+1,t}] \mathbf{u}_t^* $$

**9.3.3 Factor Portfolios from Sorts?**

A very popular way to form factor portfolios is to sort securities by a given characteristic, and then form a portfolio in which the long positions are the top $q$-quantile positions (say, the top 10% positions) and the shorts are the bottom $q$-quantile positions. These portfolios (FMPs) in which each position is identical, so that the portfolio is dollar-neutral. For example, to construct a value-minus-growth portfolio for a U.S. investment universe of 3000 stocks, and go long $q=1000$ the 1000 stocks with the highest value of the characteristic, and short $q=1000$ the 1000 stocks with the lowest value of the ratio. This approach originates with the paper by Fama and French (1993), who construct factor portfolios based on size and value. The main motivation for this approach is simplicity, by estimating portfolios instead. The resulting portfolios are sometimes called portfolio sorts or characteristic portfolios (CRs; Daniel et al. (2020)). They are widely used by practitioners to convert a metric that describes a potential mispricing into an investable portfolio. What are the drawbacks of this approach? There are at least four:
1.  The resulting portfolios have unit exposure to one factor. As a result, they may be heavily exposed to the characteristics of other factors, as well as to some other sources of systematic risk and return. The unwanted exposures may both increase the overall portfolio risk and reduce the return of the portfolio.
2.  The securities in the characteristic portfolio are equally weighted. Intuitively, one may want securities that have lower idiosyncratic risk to have a higher weight.
3.  Being equal-weighted, the sizes in the characteristic portfolio do not reflect the magnitude of the characteristic. For example, if asset A has a value of the characteristic of 10, and asset B has a value of 0.1, and they are both in the top $q$-quantile of the characteristic, they receive the same weight. This is the same as dichotomizing the characteristic. Dichotomization of data is usually a poor modeling strategy (e.g., Harrell (2015)).
4.  Over time, due to business change, and certain securities become illiquid/delisted to new securities. This makes trading more expensive and requires some adjustment over the naive weights.

**FAQ 9.1: What about factor portfolios from sorts?**
Portfolios from sorts (or characteristic portfolios) are dollar neutral portfolios which consist of equal-weighted long positions in securities having the highest values of a certain characteristic, and equal-weighted short positions for an equal number of securities with the lowest value of a characteristic. They hold the intuitive appeal of being a simple representation of a dollar-neutral portfolio. However, they have major drawbacks: high volatility, often leading, non-optimal characteristic weighting, unwanted exposures to other factors, and high turnover due to abrupt inclusion/removal in the portfolio. FMPs are designed to be the most efficient (i.e., lowest risk) portfolios with unit exposure to a characteristic of interest.

---

**9.4 Trading in Idio Space**

In Section 4.3, we introduced the concepts of alpha spanned and alpha orthogonal. Alpha spanned are asset-expected returns attributable to co-movements with factor returns; alpha orthogonal are not explainable by factor returns. Because of Equation (4.2), Sharpe Ratio scales at least like $\sqrt{N}$. Because of this, alpha orthogonal is the golden currency in investing. How does one build a portfolio that exploits this alpha orthogonal, meaning that the optimal portfolio has zero factor exposures, is long alpha, is factor-neutral, and has minimum idiosyncratic risk, and they are encountered in practice. The first one is to build a portfolio that has an upper bound on volatility, maximizes expected returns, and has no factor exposures. By construction, the portfolio contains “pure alpha” and no factor-related PnL. The formulation is
(9.18)
$$ \max_{\mathbf{w}} \alpha^T \mathbf{w} $$
$$ \text{s.t. } \mathbf{B}^T \mathbf{w} = \mathbf{0} $$
$$ \mathbf{w}^T \Omega_\epsilon \mathbf{w} \le \sigma^2 $$
whose solution is[10]
$$ \tilde{\alpha}_\perp = (I_N - \mathbf{B}(\mathbf{B}^T \Omega_\epsilon^{-1} \mathbf{B})^{-1} \mathbf{B}^T \Omega_\epsilon^{-1}) \alpha_\perp $$
$$ \mathbf{w}^* = \frac{\sigma}{\sqrt{\tilde{\alpha}_\perp^T \Omega_\epsilon^{-1} \tilde{\alpha}_\perp}} \Omega_\epsilon^{-1} \tilde{\alpha}_\perp $$
In Section 4.3.1, we built an FMP for a factor through two steps: first, orthogonalization; second, inverse-variance weighting. The portfolio construction for an alpha orthogonal portfolio is, indeed, identical: orthogonalization and inverse variance weighting. If all the asset idiosyncratic volatilities are identical, $\Omega_\epsilon$ is proportional to the identity, and the orthogonalization step is superfluous: $\tilde{\alpha}_\perp = \alpha_\perp$.

---

**9.5 Drivers of Information Ratio: Information Coefficient and Diversification**

What makes a good strategy before we are trading (i.e., ex ante), and we are living the dream, i.e., Equation (9.1)?
$$ \text{SR}^* = \sqrt{\alpha^T \Omega_r^{-1} \alpha} $$
A substantial part of this and of the next chapter is dedicated to the notion that we do not live in the dreamtime. Our forecasted returns and risk models are incorrect, and we should incorporate this knowledge in the investment process. A first step is to re-analyze the problem of maximizing the Sharpe Ratio. Start with the solution to the MVO problem, Equation (9.3):
$$ \mathbf{w}^* = \frac{\sigma}{\sqrt{\alpha^T \Omega_r^{-1} \alpha}} \Omega_r^{-1} \alpha $$
and assume that the covariance matrix $\Omega_r$ is accurate, admittedly a strong assumption. The expected realized return is
$$ E(\mathbf{r}^T \mathbf{w}^*) = \frac{\sigma}{\sqrt{\alpha^T \Omega_r^{-1} \alpha}} (\alpha^T \Omega_r^{-1} \alpha) = \sigma \sqrt{\alpha^T \Omega_r^{-1} \alpha} $$
$$ E(\mathbf{r}^T \mathbf{w}^*) = \frac{E(\mathbf{r}^T \mathbf{w}^*)}{\sqrt{\mathbf{w}^{*T} \Omega_r \mathbf{w}^*}} = \frac{\sigma \sqrt{\alpha^T \Omega_r^{-1} \alpha}}{\sigma} = \sqrt{\alpha^T \Omega_r^{-1} \alpha} $$
Recall the Information Coefficient, already introduced in Section 8.3.1:
$$ \text{IC} := \frac{E(\mathbf{r}^T \mathbf{w}^*)}{\sqrt{E(\mathbf{r}^T \mathbf{r})} \sqrt{E(\mathbf{w}^{*T} \Omega_r \mathbf{w}^*)}} = \frac{\alpha^T \Omega_r^{-1} \alpha}{\sqrt{\alpha^T \Omega_r^{-1} \Omega_r \Omega_r^{-1} \alpha} \sqrt{\alpha^T \Omega_r^{-1} \alpha}} $$
The important thing to know is that the Information Coefficient is a correlation. To see why, we need to transform variables:
(9.19)
$$ \tilde{\alpha} = \Omega_r^{-1/2} \alpha $$
So that the Information Coefficient can be rewritten in a more succinct form
$$ \text{IC}(\tilde{\alpha}, \mathbf{r}) = \frac{E(\tilde{\alpha}^T \Omega_r^{1/2} \mathbf{r})}{\sqrt{\tilde{\alpha}^T \tilde{\alpha}} \sqrt{E(\mathbf{r}^T \Omega_r \mathbf{r})}} $$
which can be interpreted as a cross-sectional uncentered correlation between z-scored alpha and z-scored returns.
We can simplify things further by proving that $E[\mathbf{r}^T \Omega_r^{-1} \mathbf{r}] = m$. The random vector $\mathbf{z} = \Omega_r^{-1/2} \mathbf{r}$ has the same covariance matrix as $\mathbf{r}$, where $\mathbf{z}$ is a standard multivariate normal.
$$ E(\mathbf{r}^T \Omega_r^{-1} \mathbf{r}) = E(\mathbf{z}^T \Omega_r^{-1/2} \Omega_r \Omega_r^{-1/2} \mathbf{z}) = E(\mathbf{z}^T \mathbf{z}) $$
$$ = \sum_{i=1}^m E(z_i^2) $$
$$ = m $$
Putting everything together, the $E(\mathbf{r}^T \mathbf{w}^*)$ is
$$ \text{SR} = \frac{\text{IC}(\tilde{\alpha}, \mathbf{r})}{\sqrt{m}} $$
This relationship goes back to Grinold (1989) and Grinold and Kahn (2000), who named it The Fundamental Law of Active Management.[11] It is often invoked by practitioners. In practice, users of the formula do not whiten returns and alphas in advance, instead they replace $\Omega_r$ by the diagonal $\Omega_\epsilon$. So, IC is the cross-sectional correlation between alpha and idiosyncratic returns (not total returns). The returns in units of volatility are the standardized idio returns (so that they have unit variance).
The Fundamental Law has several important implications. The first, and most obvious one, is that performance is driven by two factors. The first one is a measure of skill: the Information Coefficient. It is a myth that the prediction strength of the IC is low. It has been shown to be as high as 0.2 for some strategies, and depending on its predictive power, we should do so? This may not be the case in real life, depending on the specifics of your strategy. Many investors also have a notion of “idea velocity”, expressed as the number of forecasts $T^*$ per year. A high-er idea velocity increases, in principle, the Information Ratio. It is really difficult, however, to increase effectively the frequency of forecasts $T^*$.

**Insight 9.5: Information Coefficient and prediction regression**
Being a correlation, the IC is also naturally related to the predictive strength of our alphas, as measured by a cross-sectional regression. An important step in exploring alpha is to regress realized returns on the forecasted expected returns. We want to explain a fraction of residual returns using alpha. We form an efficient $\mathbf{z}$ that solves the following minimization problem:
$$ \min_{\mathbf{z}} \sum_{i,t} \frac{(r_{it} - \alpha_i z_t)^2}{\sigma_{\epsilon,it}^2} = \min_{\mathbf{z}} \| \tilde{\mathbf{r}} - \tilde{\alpha} \mathbf{z} \|_F^2 $$
The solution is given by $\mathbf{z}^* = \tilde{\mathbf{r}}^T \tilde{\alpha} / \|\tilde{\alpha}\|^2$ and the residual sum of squares is
$$ \|\tilde{\mathbf{r}}\|^2 - (\tilde{\mathbf{r}}^T \tilde{\alpha})^2 / \|\tilde{\alpha}\|^2 $$
, while the total sum of squares is $\|\tilde{\mathbf{r}}\|^2$. The coefficient of determination ($R^2$ squared) is, in expectation, equal to
$$ R^2 = \frac{(\tilde{\mathbf{r}}^T \tilde{\alpha})^2}{\|\tilde{\alpha}\|^2 \|\tilde{\mathbf{r}}\|^2} = (\text{IC})^2 $$
And we can link the coefficient of determination in predictive regressions to the Information Ratio:
$$ \text{IR} = \sqrt{R^2 n} $$
If there are $T^*$ investment periods in a year, the annualized Information Ratio has a convenient form as a function of per-period cross-sectional R-squared:
$$ \text{IR} = \sqrt{R^2 n T^*} = \text{IC} \sqrt{n T^*} $$
Otherwise stated, the annualized Information Ratio is equal to the Information Coefficient times the independent number of assets/forecasts in a year.[12]
[12] For the relationship between coefficient of determination and IR, see Chincarini and Kim (2006, 2022).
The Fundamental Law also connects IR to an ex-post measure (IC) that is interpretable as a correlation, which can be related to a spatial kind of regression (as per Insight 9.5).

---

**9.6 Aggregation: Signals versus Portfolios**

So far, we have considered the optimization of a single portfolio. That is, the entire family found by a quantitative portfolio manager. But life is far from being this easy. Let us consider two examples. In the first one, you have a fundamental portfolio manager managing a large team. In order to scale her book, the PM delegates to the analyst trading decisions for the stocks they cover. The portfolio of the entire team is then simply the aggregation of the individual portfolios. Is this a fully decentralized model, or is it a centralized model? What are the advantages? The analysts do their own research, summarize it into a thesis for each stock, and communicate to the PM, who converts them into positions. This is the centralized solution to the problem. Now, we produce the second example by going up one level: the large team is one of many teams belonging to a large hedge fund. The CIO of the hedge fund would like to deploy capital and would like to deploy one option available to the hedge fund is to take the portfolio positions of the individual teams, and increase them by a given percentage, say 50%. This can be directly performed at the level of an order’s submittal. This is possible for the decentralized solution. The first one is, however, not necessarily a bad choice. The second one is that the portfolio manager is a prediction machine. The alternative is the centralized solution: gather the signals from the teams and construct a portfolio. Figure 9.1 visualizes the two approaches.

[Image: Figure 9.1: Left: the decentralized solution to portfolio combination. Right: the centralized solution.]

A lot of ink rides on the decision to centralize versus decentralize portfolio construction! How should we organize large teams? How should we deploy new capital in the most efficient way? The rest of this section is devoted to giving a simplified answer to these questions. The conditions are very roughly, that the portfolio constructor is an MVO problem, and there are no transaction costs. Technical details matter. However, the rest of the section spells them out in detail and states the precise result. As for most of the results in this book, the theorem is interesting not because it hasn’t held in practice. It allows us to evaluate centralized solutions under which it holds, and the real-world situation, and identify areas where one solution may have the advantage.
Let us formalize the problem. There is an investment universe of $N$ stocks. We have $M$ portfolio managers working under a principal hedge fund manager. Without loss of generality each one has the same investment coverage of $N_m$ stocks. Every portfolio manager sets the same asset covariance matrix $\Omega_r$, and has a forecast $\alpha_m$.
We model the portfolio managers by assuming they are mean-variance maximizers. Without loss of generality PM produces a unit-volatility portfolio.
$$ \mathbf{w}_m = \frac{1}{\sqrt{\alpha_m^T \Omega_r^{-1} \alpha_m}} \Omega_r^{-1} \alpha_m $$
$$ \sigma_m := \sqrt{\alpha_m^T \Omega_r^{-1} \alpha_m} $$
Correspondingly, we have two solutions.
1.  Decentralized. PMs trade; the hedge fund manager estimates their Sharpe Ratios and return correlations, and combines their portfolios so as to maximize the overall Sharpe Ratio.
2.  Centralized. The hedge fund manager receives the signals, simulates their properties (e.g., Sharpe Ratio or IC), forms a combined signal, and trades a single Sharpe-maximizing portfolio.
We consider the two solutions.
1.  Decentralized solution. The hedge fund manager observes Sharpe Ratio $S_m$ for $m=1, \dots, M$ for each PM, as well as the correlation matrix $C$ for the $M$ portfolios. Consider $s_m = \text{diag}(S_1, \dots, S_M)$. The optimal dollar volatility allocated to strategy $m$ is $v_m = (C^{-1} \mathbf{s})_m$. The $M$ portfolios have unit volatility, hence the aggregated portfolio is $\mathbf{w}_{dec} = \sum_m v_m \mathbf{w}_m$.
2.  Centralized solution. The hedge fund manager receives signals and aggregates them as $\alpha_{agg} = \sum_m v_m \alpha_m$. We need to identify weights $v_m$. Let $\alpha_{agg} = E(\mathbf{r})$. The expected PnL of the portfolio is $\mathbf{A}^T \mathbf{w} = \sum_m v_m \alpha_m^T \mathbf{w}_m = \sum_m v_m \sigma_m^2$.
    The covariance of the portfolio is
    $$ (\alpha_m \sigma_m^2, \alpha_n \sigma_n^2) \Omega_r (\alpha_m \sigma_m^2, \alpha_n \sigma_n^2)^T = \sum_{m,n} v_m v_n \sigma_m^2 \sigma_n^2 C_{mn} $$
    We find the weights so that the hedge fund manager maximizes the Sharpe Ratio. Define $S_m = \sigma_m$. The maximization problem is
    $$ \max_{\mathbf{s}} \frac{\mathbf{s}^T \mathbf{x}}{\sqrt{\mathbf{x}^T C \mathbf{x}}} $$
    $$ \text{s.t. } \mathbf{x} \in \mathbb{R}^M $$
    The solution is
    $$ \mathbf{x}^* = C^{-1} \mathbf{s} \sqrt{\mathbf{s}^T C^{-1} \mathbf{s}} $$
    , so that
    $$ \mathbf{w}_{cen} = \frac{1}{\sqrt{\mathbf{s}^T C^{-1} \mathbf{s}}} \sum_m (C^{-1} \mathbf{s})_m \frac{1}{\sigma_m} \alpha_m $$
    The two portfolios $\mathbf{w}_{dec}$ and $\mathbf{w}_{cen}$ are identical, save for a multiplicative constant, which is not essential.
    This equivalency result is, in a sense, positive, because it suggests that, at least to a first approximation, we can decentralize portfolio construction decisions. What could go wrong? A lot. It is a good point to re-examine the assumptions:
    1.  First, we have ignored execution costs. It is possible that the centralized solution has the advantage, since it would net out opposite side positions of individual portfolio managers. Optimal execution turns the problem into a multi-period one, so that the analysis in this section does not apply.
    2.  Second, we have assumed that the portfolio managers solve an MVO problem; the formulation accommodates total return and idio return problems. In real-world implementations, there are side constraints that may differ by portfolio managers. Coordination problems may also differ among managers, and between them and the hedge fund manager.
    3.  When the individual units are not systematic, but rather discretionary portfolios managers, the portfolios produced by them are not generally MVO.
    4.  In many cases, the volatility allocation to the signals of the PMs in the centralized solution is not done using MVO. Heuristics, precommitments to individual PMs, and other constraints may play a role.
    Finally, especially in the latter case of discretionary managers, the alpha signal may not be communicated in a timely manner.
    In summary, the result suggests that in a real-world setting, provided that transaction costs do not dominate and that agents are MVO optimizers, the centralized solution should not dramatically dominate the decentralized one. The emphasis is on “suggests”; more research is (always) needed.

---

**9.7 Appendix**

**9.7.1 Some Useful Results From Linear Algebra**

Spiked covariance matrices are the sum of a full-rank (possibly diagonal) matrix and a low-rank matrix. For this class of matrices, there are useful, computationally efficient formulas that relate the inverse and the determinant of the matrix to those of the constituents. These are the Woodbury-Sherman-Morrison Lemma and the Matrix Determinant Lemma.

**Woodbury-Sherman-Morrison Lemma.**
Useful to compute the inverse of a matrix (e.g., min-variance portfolio and log-likelihood)
(9.20)
$$ (D + B B^T)^{-1} = D^{-1} - D^{-1} B (I + B^T D^{-1} B)^{-1} B^T D^{-1} $$

**Determinant Lemma.**
Useful in log likelihood calculations.
(9.21)
$$ \det(D + B B^T) = \det(D) \det(I + B^T D^{-1} B) $$

**9.7.2 Some Portfolio Optimization Problems**

**Example 9.1 (Maximize expected return subject to a vol constraint and linear homogeneous equalities):**
$$ \max_{\mathbf{w}} \alpha^T \mathbf{w} $$
$$ \text{s.t. } \mathbf{B}^T \mathbf{w} = \mathbf{b} $$
$$ \mathbf{w}^T \Omega_r \mathbf{w} \le \sigma^2 $$
The solution $\mathbf{w}^*$ to this problem is given by
$$ \Pi := I_N - \mathbf{B}(\mathbf{B}^T \Omega_r^{-1} \mathbf{B})^{-1} \mathbf{B}^T \Omega_r^{-1} $$
$$ \tilde{\alpha} := \Pi \alpha $$
$$ \mathbf{w}^* = \frac{\sigma}{\sqrt{\tilde{\alpha}^T \Omega_r^{-1} \tilde{\alpha}}} \Omega_r^{-1} \tilde{\alpha} $$

**Example 9.2 (Minimum-variance portfolio subject to linear equalities):**
(9.22) $\min_{\mathbf{w}} \mathbf{w}^T \Omega_r \mathbf{w}$
(9.23) s.t. $\mathbf{B}^T \mathbf{w} = \mathbf{b}$
The solution is
$$ \mathbf{w}^* = \Omega_r^{-1} \mathbf{B} (\mathbf{B}^T \Omega_r^{-1} \mathbf{B})^{-1} \mathbf{b} $$
Of special interest is the case where
$$ \Omega_r = B \Omega_f B^T + \Omega_\epsilon $$
. The first term is constant, so the objective is $\mathbf{w}^T \Omega_\epsilon \mathbf{w}$, and the
$$ \mathbf{w}^* = \Omega_\epsilon^{-1} \mathbf{B} (\mathbf{B}^T \Omega_\epsilon^{-1} \mathbf{B})^{-1} \mathbf{b} = \mathbf{P} \mathbf{b} $$
where $\mathbf{P}$ is the matrix whose column vectors are the FMPs associated to the factor model. These are introduced in Section 9.3.1.

**9.7.3 Optimality of FMPs**

We now prove that FMPs emerge naturally from certain assumptions about returns and FMP composition, which we use in Section 9.3.1.

**Theorem 9.1:**
Consider a sequential model $S(\mathbf{B}, \Omega_f, \Omega_\epsilon)$. Assume that
1.  Alpha orthogonal is zero, so that $\alpha = \mathbf{B}\lambda$, for some $\lambda \in \mathbb{R}^m$.
2.  Idiosyncratic variance converges to zero in norm:
    $$ \lim_{N \to \infty} \| (\mathbf{B}^T \Omega_\epsilon^{-1} \mathbf{B})^{-1} \| = 0 $$
Then in the limit, the Sharpe-optimizing portfolio is a weighted sum of the FMPs, and the weights themselves solve an MVO in factor space.
$$ \mathbf{w}^* = \mathbf{P} \mathbf{u}^* $$
where: $\mathbf{u}^* = \underset{\mathbf{u} \in \mathbb{R}^m}{\arg \max} \lambda^T \mathbf{u} - \frac{1}{2\gamma} (\mathbf{u}^T \Omega_f \mathbf{u})$, $U = (\mathbf{B}^T \Omega_\epsilon^{-1} \mathbf{B})^{-1/2} \mathbf{B}^T \Omega_\epsilon^{-1}$
for some $\gamma > 0$. The Sharpe Ratio of the optimal portfolio is equal to
$$ \text{SR}^* = \sqrt{\lambda^T \Omega_f^{-1} \lambda} $$
The second condition deserves further scrutiny. A simple interpretation is easy to check. For the FMPs, the covariance matrix of the idiosyncratic PnL is $(\mathbf{B}^T \Omega_\epsilon^{-1} \mathbf{B})^{-1}$. The condition states that the idiosyncratic variance of the FMPs goes to zero.
Proof:
Start with the Sharpe-optimizing portfolio problem, Equation (9.3):
$$ \mathbf{w}^* = \frac{\sigma}{\sqrt{\alpha^T \Omega_r^{-1} \alpha}} \Omega_r^{-1} \alpha $$
$$ \Omega_r^{-1} = (\mathbf{B} \Omega_f \mathbf{B}^T + \Omega_\epsilon)^{-1} = \Omega_\epsilon^{-1} - \Omega_\epsilon^{-1} \mathbf{B} (\Omega_f^{-1} + \mathbf{B}^T \Omega_\epsilon^{-1} \mathbf{B})^{-1} \mathbf{B}^T \Omega_\epsilon^{-1} $$
The second identity is the Woodbury-Sherman-Morrison Lemma.
Now we perform a first-order expansion. Notice that:[13]
$$ (\Omega_f^{-1} + \mathbf{B}^T \Omega_\epsilon^{-1} \mathbf{B})^{-1} = (\mathbf{B}^T \Omega_\epsilon^{-1} \mathbf{B})^{-1} - (\mathbf{B}^T \Omega_\epsilon^{-1} \mathbf{B})^{-1} \Omega_f^{-1} (\mathbf{B}^T \Omega_\epsilon^{-1} \mathbf{B})^{-1} + O(\|\Omega_f^{-1}\|^2) $$
So we perform a first-order approximation of the inverse:[14]
$$ \Omega_r^{-1} \approx \Omega_\epsilon^{-1} - \Omega_\epsilon^{-1} \mathbf{B} (\mathbf{B}^T \Omega_\epsilon^{-1} \mathbf{B})^{-1} \mathbf{B}^T \Omega_\epsilon^{-1} + \Omega_\epsilon^{-1} \mathbf{B} (\mathbf{B}^T \Omega_\epsilon^{-1} \mathbf{B})^{-1} \Omega_f^{-1} (\mathbf{B}^T \Omega_\epsilon^{-1} \mathbf{B})^{-1} \mathbf{B}^T \Omega_\epsilon^{-1} $$
Replace the expression in the solution $\mathbf{w}^*$:
$$ \mathbf{w}^* = \mathbf{P} (\Omega_f^{-1} + \mathbf{B}^T \Omega_\epsilon^{-1} \mathbf{B})^{-1} \mathbf{B}^T \Omega_\epsilon^{-1} \alpha $$
$$ \approx \mathbf{P} (\mathbf{B}^T \Omega_\epsilon^{-1} \mathbf{B})^{-1} \mathbf{B}^T \Omega_\epsilon^{-1} \alpha - \mathbf{P} (\mathbf{B}^T \Omega_\epsilon^{-1} \mathbf{B})^{-1} \Omega_f^{-1} (\mathbf{B}^T \Omega_\epsilon^{-1} \mathbf{B})^{-1} \mathbf{B}^T \Omega_\epsilon^{-1} \alpha $$
$$ = \mathbf{P} \mathbf{u}^* $$
The second PnL of the optimal solution is $\mathbf{u}^{*T} \Omega_f \mathbf{u}^*$. The factor exposure of the optimal solution is $\mathbf{u}^*$. The factor variance is $\mathbf{u}^{*T} \Omega_f \mathbf{u}^*$. The idiosyncratic variance is
$$ (\mathbf{w}^*)^T \Omega_\epsilon \mathbf{w}^* = \mathbf{P}^* \Omega_f \mathbf{P} $$
$$ \approx (\mathbf{u}^*)^T (\mathbf{B}^T \Omega_\epsilon^{-1} \mathbf{B})^{-1} (\mathbf{u}^*) $$
and is zero in the limit, per the second assumption. The Sharpe Ratio is $\sqrt{\lambda^T \Omega_f^{-1} \lambda}$.

**9.7.4 Single Factor Covariance Matrix Updating**

Here we prove a basic result on the updated factor covariance matrix when adding a new factor. The analysis assumes that the parameters $\mathbf{B}_m, \Omega_f, \Omega_\epsilon$ of the factor model are constant, and so is the vector $\mathbf{a}$ or characteristics that we are using to augment the factor model. As in Section 9.3.2.

**Theorem 9.2:**
Let the loadings, factor covariance matrix, and idiosyncratic of a factor model be $\mathbf{B}_m, \Omega_{f,m}$ and $\Omega_{\epsilon,m}$. Let $\mathbf{a} \in \mathbb{R}^N$ be a vector of characteristics. Define
$$ \mathbf{b}_{m+1} = (I_N - \mathbf{B}_m (\mathbf{B}_m^T \Omega_{\epsilon,m}^{-1} \mathbf{B}_m)^{-1} \mathbf{B}_m^T \Omega_{\epsilon,m}^{-1}) \mathbf{a} $$
The factor covariance matrix associated to the model with loadings $[\mathbf{B}_m, \mathbf{b}_{m+1}]$ is given by
$$ \hat{\Omega}_f \approx \begin{bmatrix} \hat{\Omega}_{f,m} & \mathbf{0} \\ \mathbf{0}^T & \sigma_{m+1}^2 \end{bmatrix} $$
Proof:
Let the factor return of the new factor be
$$ \hat{f}_{m+1,t} = \frac{\mathbf{b}_{m+1}^T \Omega_{\epsilon,m}^{-1} \mathbf{r}_t}{\mathbf{b}_{m+1}^T \Omega_{\epsilon,m}^{-1} \mathbf{b}_{m+1}} $$
$$ = \mathbf{v}_{m+1,t}^T \mathbf{r}_t $$
as in Equation (9.14). We assume that the new factor does not have a big impact on the idiosyncratic returns in the sense that
$$ \text{cov}(\hat{f}_{m+1,t}, \hat{f}_{k,t}) \approx 0, \quad k \le m $$
, so that $\Omega_f$ is approximately unchanged by the addition of the new factor. Then the volatility of the new factor is
$$ \hat{\sigma}_{m+1}^2 = (\mathbf{b}_{m+1}^T \Omega_{\epsilon,m}^{-1} \mathbf{b}_{m+1})^{-1} $$
$$ E[\hat{f}_{m+1,t}^2] = \frac{E[(\mathbf{b}_{m+1}^T \Omega_{\epsilon,m}^{-1} \mathbf{r}_t)^2]}{(\mathbf{b}_{m+1}^T \Omega_{\epsilon,m}^{-1} \mathbf{b}_{m+1})^2} $$
$$ \hat{\sigma}_{m+1}^2 = \frac{\mathbf{b}_{m+1}^T \Omega_{\epsilon,m}^{-1} \Omega_r \Omega_{\epsilon,m}^{-1} \mathbf{b}_{m+1}}{(\mathbf{b}_{m+1}^T \Omega_{\epsilon,m}^{-1} \mathbf{b}_{m+1})^2} $$
$$ = (\mathbf{b}_{m+1}^T \Omega_{\epsilon,m}^{-1} \mathbf{b}_{m+1})^{-1} $$
We show that $f_{m+1,t}$ is approximately uncorrelated to the first $m$ factors. The column vector of the first $m$ ex-factor returns is $\mathbf{P}^T \mathbf{r}_t$.
$$ E[\hat{f}_{m+1,t} \mathbf{P}^T \mathbf{r}_t] = E[\mathbf{v}_{m+1,t}^T \mathbf{r}_t \mathbf{r}_t^T \mathbf{P}] $$
$$ = \mathbf{v}_{m+1,t}^T (\mathbf{B} \Omega_f \mathbf{B}^T + \Omega_\epsilon) \mathbf{P} $$
$$ = \mathbf{v}_{m+1,t}^T \mathbf{B} \Omega_f (\mathbf{B}^T \Omega_\epsilon^{-1} \mathbf{B})^{-1} + \mathbf{v}_{m+1,t}^T \Omega_\epsilon \Omega_\epsilon^{-1} \mathbf{B} (\mathbf{B}^T \Omega_\epsilon^{-1} \mathbf{B})^{-1} $$
$$ = \mathbf{P}^T \Omega_f \mathbf{P} \mathbf{v}_{m+1,t} $$
The last equality follows from the orthogonality of $\mathbf{b}_{m+1}$. The correlation between FMPs is given by the idiosyncratic component of their returns, which should be small if the factors are diversified.

**The Takeaways**

1.  Mean-Variance Optimization (MVO) is a foundational approach to portfolio construction due to its interpretability, data efficiency, and computational simplicity in single-period settings.
2.  Factor models enable systematic decomposition of portfolio risk and return by representing asset covariance through factors, simplifying the optimization process and enhancing interpretability.
3.  Factor-Mimicking Portfolios (FMPs) are valuable instruments for factor-based investing, offering efficient trading strategies focused on specific characteristics.
4.  The Information Ratio (IR) is influenced by the quality of signals (Information Coefficient) and the degree of diversification, providing a comprehensive measure of performance potential.
5.  Portfolio construction can be approached via a centralized or decentralized approach when the MVO principles, but practical differences like transaction costs and constraints may make one approach preferable.

**Notes**

1.  [1] Extensive treatments of convex optimization are Boyd and Vandenberghe (2004), Bazaraa et al. (2006), and Luenberger and Ye (2008); and finance-oriented optimization textbooks are Cornuejols et al. (2006), Palomar (2014).
2.  [2] On justification of the mean-variance approach to portfolio optimization, see Huang and Litzenberger (1988). Both cover the standard cases of exponential and quadratic utilities. A number of textbooks exist covering portfolio construction. A classic is Grinold and Kahn (1999); see also Qian et al. (2007), Isichenko (2018). On the definition of the Sharpe Ratio see Lo (2002), and for a comprehensive and detailed treatment of the (Sharpe) ratio and its uses, there is
3.  [3] We ignore the term $\alpha_k$, both out of simplicity and because it is very small.
4.  [4] The subject will be covered in Section 10.2.1.
5.  [5] See Section 4.7.2.
6.  [6] See Sections 4.7.2 and 4.7.3.
7.  [7] See Sections 4.7.2 and 4.7.3.
8.  [8] Devise it as an exercise, or see Section 4.7.3.
9.  [9] Prove this step-by-step in Exercise 4.3.
10. [10] Quite an important name for a “law”. And why not? Nobody had thought of using this cute acronym before. I can imagine Grinold playing air guitar and screaming to Iron Maiden when he was writing this mighty paper.
11. [11] For example, Modigliani-Miller’s theorem and Merton’s result on the equivalence of an option and a replicating portfolio.
12. [12] Given square matrices $A, B$, the inequality on spectral norms $|AB| \le |A| |B|$ holds.
13. [13] The first-order expansion (from von Neumann’s series) is $(I+A)^{-1} \approx I-A$.
   

Okay, here is the Markdown compilation for Chapter 10.

```markdown
Everand

**Chapter 10**
**Beyond Simple Mean Variance**

**The Questions**

1.  When does Mean-Variance Optimization (MVO) suggest shorting an asset with positive returns, and even short selling with its counterintuitive implications, when justifiable?
2.  How do different types of constraints (e.g., on market exposure, trading costs, portfolio turnover) address investor preferences, regulatory requirements, or practical considerations in portfolio construction?
3.  What are the potential benefits and drawbacks of using penalties instead of hard constraints in portfolio optimization?
4.  How do forecast errors in expected returns affect the realized Sharpe Ratio of an optimal portfolio?
5.  In what way does the error in estimating the covariance affect Sharpe Ratio?

---

**10.1 Shortcomings of Naive MVO**

Before considering more complex optimization problems, let’s work through a simple example—perhaps the simplest instance of the simplest optimization problem—to illustrate the implications of MVO. We have just two assets, with non-negative Sharpe Ratios $s_1, s_2$. Their returns have correlation $\rho$. The inverse of the covariance matrix is
`C⁻¹ = 1 / (1 - ρ²) * [[1, -ρ], [-ρ, 1]]`
So from Equation (9.16), the optimal volatility allocation is
`w*ᵢ = κ / (1 - ρ²) * (sᵢ - ρsⱼ)`
where $\kappa > 0$ is a parameter determined by the risk tolerance or by the constraint on total variance (see Section 9.2.4). If $\rho > 0$, we have three cases. Consider first the case where $s_1 > \rho s_2$ and $s_2 > \rho s_1$. In this case, weights are positive, and asset 2 acts as hedge. Shorting it is beneficial because (a) it has no cost (zero expected return), (b) it reduces the volatility of the portfolio, since it is positively correlated to asset 1. When the Sharpe Ratio of asset 2 is positive, then there is a cost to shorting it. If the asset is “too good” to short, shorting it no longer improves the Sharpe Ratio; the correlation must exceed the threshold $s_2/s_1$.

Even though the recommendation to short an asset with positive return is explainable, it is probably at odds with the intuition of many readers. If two assets are very correlated, wouldn’t it be preferable to go long both, thus averaging out the signal error? We will make this reasoning more rigorous by assessing the impact of estimation error on expected returns and on the correlation.

Impact of errors in forecasted Sharpe Ratios. We denote the true Sharpe Ratios $s_1, s_2$ and assume that the error between true and forecasted Sharpe Ratios is bounded by `||s̃ - s|| ≤ ε`. We choose optimal dollar volatility based on $s_1, s_2$ and true Sharpe Ratios $s_1, s_2$, and derive performance that is a function of $s_1, s_2$. The realized expected return is
`E[PnL] = κ / (1 - ρ²) * (s₁² - ρs₁s₂ + s₂² - ρs₁s₂)`

(Right Sidebar Text from Page 440)
**Insight 10.1: A simple linear-quadratic problem**
Let $a, x_0 \in \mathbb{R}^n$. The problem
`min_{x} (a, x) | ||x - x₀||² ≤ ε²`
has solution
`x* = x₀ - a / ||a|| ε`
`(a, x*) = (a, x₀) - ||a|| ε`
In the worst case, we solve the problem
`min E[PnL]`
`s.t. ||s̃ - s|| ≤ ε`
`s̃ ∈ ℝ²`
We leave the solution as an exercise (also, see Insight 10.2); the relative reduction in PnL is
`√((s₁ - ρs₂)² + (s₂ - ρs₁)² ) / (s₁² - 2ρs₁s₂ + s₂²) * ε`
This is the relative loss in Sharpe, since the volatility of the portfolio is unaffected by return forecast error. Figure 10.1 shows numerical results for two assets, assuming an error $\epsilon = 0.1$ in Sharpe Ratio estimation. As $\rho \to 1$, the perhaps counterintuitive, actual difference in forecasted versus realized Sharpe Ratios are higher. Notice that high correlation makes things worse. In all scenarios, the percentage in efficiency is significant. It is of course lower for higher Sharpes because the relative forecasting error is smaller, and is higher for higher correlations. In all cases it amounts to 10% and can be as high as 50%.

---
(Continuation from Page 444)
that the estimation error is bounded `||ρ̃ - ρ|| ≤ ε`. The error in estimated correlation affects the volatility; the return is not affected. The Sharpe Ratio is minimized when the realized volatility is maximized.
`max (v')ᵀ C̃V'`
`s.t. ||ρ̃ - ρ|| ≤ ε`
`ρ̃ ∈ ℝ`
In this case the worst-case realized relative volatility (exercise) is
`√( (V')ᵀ C̃V' + 2ε|v'₁v'₂| )`
and the associated relative loss in Sharpe Ratio is
`√( (V')ᵀ C̃V' ) / √( (V')ᵀ C̃V' + 2ε|v'₁v'₂| ) - 1`
We show the impact of the error in Figure 10.2 for a reasonable error in correlation estimate of $\epsilon = 0.1$. Moreover, in periods of crisis, the error can be larger (albeit not systematically so). Figure 10.2 shows the impact of correlation error on Sharpe.

**Figure 10.1:** Level plots of the loss of PnL (and Sharpe Ratio) as a function of the Sharpe Ratio of two assets, assuming a maximum error ε in the Sharpe Ratio norm. Parameters: ε = 0.1; Correlation ρ = 0.1 (top), ρ = 0.5 (bottom).

**Figure 10.2:** Fraction loss in Sharpe ratio for two strategies with Sharpe Ratios of 1 and 2, a return correlation ρ = 0.3, and error ε ranging from 0 to 0.3.

**Insight 10.2: Degradation in performance due to forecasting error**
When we use naive MVO optimization, the degradation in Sharpe Ratio arising from forecasted (ex-ante) parameters for volatilities and returns versus realized values (ex-post) can easily range in the 10-50%.

---

**10.2 Constraints and Modified Objectives**

Equation (9.16) is the starting point for more complex optimization problems. This section details some of the extensions: short-term constraints, long-term constraints, and implementation considerations. In applications, optimization formulations differ widely because they address a wide range of concerns:
*   Investor’s preferences: “Keep medium-term momentum exposure exactly equal to zero.”
*   Tactical considerations: “Don’t trade this stock because it could be acquired tomorrow” or “short this stock because it could be acquired tomorrow,” both of which represent constraints.
*   Regulatory considerations: “The portfolio must be long only.”
*   Fiduciary considerations: “The returns must track a benchmark, i.e., the difference in returns between the portfolio’s returns and the benchmark’s returns must not exceed a certain tracking volatility.”
*   Implementation considerations: “The objective function must include the trading costs.”

From a modeling viewpoint, constraints can take several forms. We introduce these first, and then we map them to the applications at hand. The “mapping” part will be brief, since it can never have been implemented, or is normally being done by an asset manager on a case-by-case basis. As in the previous chapter, we will focus on the linear group, and communicate with the latter.

**10.2.1 Types of Constraints**

Although one can imagine infinite types of constraints, some of them are much more common than others. We review them below.

Linear constraints. These can be inequality or equality constraints:
`Aᵀw = c` (Equality constraints)
`Aᵀw ≤ c` (Inequality constraints)
These are perhaps the most common constraints in financial optimization. For example, some strategies are required to be long-only. The constraint is simply
`w ≥ 0` (Long-Only constraint)
Extending this is a bound on maximum short and long size for a single position is only a small step. The main rationales for such constraints are many. There are natural limits due to maximum institutional ownership of a stock (say, no more than 5% of outstanding shares), or to maximum risk concentration in a stock (the idiosyncratic variance of a stock may not exceed a certain percentage of the total idiosyncratic variance, which translates to a linear constraint). Furthermore, we may impose a maximum liquidation cost requirement on all stocks, which also becomes a constraint on single-position sizes.

A slightly more complex constraint which does not seem linear at first sight, is on GMV. Recall that GMV is `Σᵢ |wᵢ|`. We can manage an upper bound on financial leverage that the fund can apply to its managed assets. The constraint can be turned into a linear one, by introducing ancillary variables representing the long and short side of a position, and additional constraints:
`x ≥ 0` (long positions)
`y ≥ 0` (short positions)
`w = x - y` (portfolio)
`Σᵢ (xᵢ + yᵢ) ≤ G` (GMV constraint)
A similar constraint is on the long versus short ratio, `LSR`. If we want the long/short ratio to be equal to a certain value, then the constraint is `Σᵢ xᵢ = K Σᵢ yᵢ`. This constraint is the same as the GMV constraint, with the exception of the factor `K`, which can be negative.
`Σᵢ xᵢ = K Σᵢ yᵢ` (Long/Short ratio constraint)
Yet another class of constraints is that on factor model exposures, and/or exposures to other asset characteristics not in the model. An example is the constraint on historical market betas `βᵢ`. The constraint then is `Σᵢ βᵢwᵢ = β₀`. The general form of factor exposure is verbatim that of Equation (10.3a).
A constraint on maximum portfolio turnover takes a similar form to the previous constraints that use absolute values. I am leaving it as an exercise to the reader. The turnover constraint may be either (poorly) justified to control costs, or by fiduciary requirements on portfolio turnover. A better way to model execution costs takes us in the domain of non-linear constraints.

Non-linear constraints. A constraint of a different nature is trading related. Trading costs are lumpy, and one approach has been to use piece-wise linear or piece-wise trading to account for asset-specific trading cost, in each portfolio rebalancing. This is equivalent to assuming linear transaction costs. We generalize this a little bit, and model trading costs as superlinear in the traded amount, or equivalently, as a quadratic cost of the form `Σᵢ cᵢ(wᵢ - w⁰ᵢ)² ≤ C`, where `cᵢ > 0` and `w⁰ᵢ` is the portfolio held at the beginning of the period. The constraint takes the form
`Σᵢ cᵢ|wᵢ - w⁰ᵢ| ≤ C` (Trading cost constraint)
where `w⁰ᵢ` is the portfolio held at the beginning of the period. The constraint is convex, so that the portfolio optimization problem has a unique solution.

Quadratic constraints appear naturally when we want to control risk at a finer resolution than that of total portfolio variance. For example, let `Bᵀw` be the principal subfactors in the factor covariance matrix, and let `D⁻¹` be the vector of style-factor exposures. Then a constraint on the maximum style-factor risk becomes
`(Bᵀw)ᵀD⁻¹(Bᵀw) ≤ ψ` (Style-factor vol constraint)
Risk constraints are often not only applied to the positions of a portfolio, but to the active positions of the portfolio itself. For example, consider a large-cap portfolio with a list of S&P 500 stocks, which is benchmarked to the S&P500 benchmark. The active holdings are `w_a = w - w_bench`. Tracking error is the volatility of the active portfolio, and is a measure of the freedom the portfolio manager has in selecting stocks. A constraint on the tracking error is
`(wᵀΩw)⁰.⁵ ≤ σ_max` (Tracking error constraint)
Non-convex constraints. Finally, there are a few constraint types that lead to a non-convex feasible region. Finding a global optimum is in general NP-hard. Convex solvers may either not accept such constraints, or may not converge. I would argue that, in most cases, these constraints should not be used on grounds of sensible modeling. I am presenting them both for completeness and as a cautionary tale.
The first constraint type is on the maximum number $N_{max}$ of assets in the portfolio. This is usually implemented by introducing 0/1 variables $x_i$, and by setting a maximum (large) absolute position size $M$. The constraint becomes
`|wᵢ| ≤ M xᵢ, i = 1, ..., n` (Max number of positions)
`Σᵢ xᵢ ≤ N_{max}`
`xᵢ ∈ {0,1} i = 1, ..., n`
The rationale for this constraint is that a very broad portfolio may be too burdensome to trade or manage. This combinatorial constraint can be handled by some commercial solvers for realistic problem instances. However, it makes the problem NP-hard. Usually it is much preferable to model trading costs directly, rather than include a constraint at all, or have a threshold for trading below which the trades of the optimal solution are set to zero. This usually has a negligible impact on optimality.

A very different type of constraint is on the minimum idio variance as a percentage of the total variance. We have mentioned this metric in Section 9.2.4. It is tempting to include a constraint of the form
`wᵀP_idioB_sB_sᵀP_idioᵀw ≥ ω₀ wᵀΩw`
or, equivalently,
`wᵀP_idioB_sB_sᵀP_idioᵀw - P_idioB_s(1 - P_idio)P_idioᵀw ≤ 0` (This seems to be a typo in the book, the formula is `wᵀ[P_idioB_sB_sᵀP_idioᵀ - ω₀Ω]w ≥ 0` or similar)
The problem is that the matrix `P_idioB_sB_sᵀP_idioᵀ - ω₀Ω` is in general not positive-definite, and therefore the constraint is not convex (exercise: prove it by providing an example).
A constraint type with a similar objective is to require a minimum idiosyncratic dollar volatility `σ_idio² ≥ σ_min²`. This is obviously a non-convex constraint, and its proponents should be excommunicated from the Orthodox Church of Optimization. A sensible approach is to simply upper bound the factor variance, or impose bounds of factor exposures, and test the impact of the bound on the portfolio’s performance.

Yet another excommunicable offense is imposing a lower bound on total volatility. I would not mention it, had I not witnessed actual humans proposing it.

In the same spirit, i.e., the goal of ensuring that the portfolio meets a minimum return, is a lower bound on GMV. The reason for these constraints is that the investor wants to ensure that, after accounting for return forecasts, trading costs, and risk constraints, the optimal portfolio is small, then maybe it should stay small. And if they really want to make it bigger (again, not advisable), one could loosen the upper bound on risk or underestimate the transaction costs.

---

**10.2.2 Do Constraints Improve or Worsen Performance?**

The naive answer to the title of this section is that—of course!—they worsen performance. If you reduce the feasible region of your optimization problem by adding a constraint, you will not get a better optimum. Specifically, if we maximize the Sharpe Ratio, adding constraints will degrade the Sharpe Ratio. This is true if the Sharpe Ratio, constraints, and expected returns are measured correctly. If we take estimation error into account, however, constraints may help. The next section interprets constraints as regularization terms for parameters entering in the optimization.

---

**10.2.3 Constraints as Penalties**

One alternative way to interpret a constraint in portfolio optimization is as a penalty term added to the objective function. Given a problem
`max f(x)`
`s.t. g(x) ≤ a`
with optimal solution $x^*(\lambda)$, there is a $\lambda^* > 0$ such that
`max f(x) - λ*(g(x) - a)`
has the same solution $x^*(\lambda)$. We used this result at the beginning of the chapter. The parameter $\lambda^*(\alpha)$ can also be interpreted as a sensitivity to the constraint’s right-hand-side parameter $a$. $\lambda$ is the marginal change in the optimum when we increase $a$ by $da$:
`df*(λ)/dλ = a(λ)`
Since a commercial solver returns both $x^*$ and $\lambda^*$, this means that we get sensitivity for free from the solution. This result also opens up a different interpretation. What if a potential constraint is not binding? Does this mean that the outcome, for the appropriate penalizing coefficient, is the same? Does this mean that the approaches are equivalent? The answer is no, and the remainder of this section is devoted to illustrating the difference.

First, let us focus our attention on the meaning of constraints and penalties. There are constraints that are communicable with the objective, and that are naturally expressed as penalties. For example, you could argue that the objective function should include trading costs and expected PnL in the objective function in the same unit (dollar) and it makes more sense to express the objective function as the difference of PnL and trading cost. The penalty parameter is simply one. What about constraints on risk? The total variance constraint has the dimension of dollar squared, and therefore our excommunicable way to add it to the objective is to add to the objective function is `λwᵀΩw`. This is possible in some optimization packages. However, if we know the approximate value of $\lambda$, of final volatility, we can choose a penalty parameter such that the adding a volatility term or a variance one gives a similar result. We do so by linearizing in the region of the optimum portfolio.
`-λ²(wᵀΩw - σ₀²) ≈ λσ₀²/2 - λ/2σ₀² λ²wᵀΩw`
The constant term is relevant to the optimization problem, and the volatility is loosely approximated by a variance.

A second class of constraints does not have an obvious interpretation. Should we add the constraint on GMV as a penalty? Or long-only constraints? The answer, somewhat surprisingly, is that adding those constraints as a penalty may actually help when we have an unconstrained portfolio, when the parameters in the model are not accurately estimated.

Let us start with an augmented version of Problem (9.16):
`max αᵀw - λwᵀΩw`
`s.t. ||w||² ≤ G`
whose penalized version is
`max αᵀw - λwᵀΩw - λ_G||w||²`
This problem can interpreted in many different ways. The first one is a simple rewriting of the quadratic term as
`λwᵀΩw + νwᵀ(I_n)w = wᵀ(λΩ + νI_n)w = wᵀΩ̃w`
The problem then is an MVO with a modified covariance matrix. The correlations $\rho_{i,j}$ of the original covariance matrix have been reduced by a factor
`(1 + ν/λ)⁻¹ ≈ 1 - ν/λ`
The asset variances have been increased, and covariances set closer to zero, each other, in the limit $\nu \to \infty$ they are identical. The norm constraint therefore has a “regularizing” effect on the solution. There are different optimization formulations that lead to the same solution of the Optimization Problem (10.10).

1.  Uncertain alpha (Goldfarb and Iyengar, 2003). Let us start with the assumption that the vector $\alpha$ is not known with accuracy. We make the assumption that the vector is distributed according to a multivariate Gaussian $\alpha \sim N(\alpha_0, \Sigma_\alpha)$. We still solve an MVO, using once more the certainty equivalence.
    `var*(wᵀα) = var(wᵀα*) + (w - w*)ᵀΩ(w - w*)`
    The MVO formulation is again the same as in that of Equation (9.16), but with a modified covariance matrix. As in the case of Equation (10.11), such a formulation will make more sophisticated calculations and shrink toward zero.

2.  Robust alpha (Pedersen et al., 2021). Instead of modeling alpha’s imperfect estimation by assuming that we know their distribution, we model their error deterministically, and adversarially: we know that the true alphas are within a certain distance $d$ from our estimate and, we are at the beginning of this chapter, we look at the worst case. The realized alpha is the worst possible one among the admissible realizations. In formulas, we solve
    `max_{w} α̃ᵀw - λwᵀΩ̃w`
    `s.t. α = argmin_{x̃} ||x̃ - x||² ≤ d²`
    We know the solution to the nested Problem (10.13a) from Insight 10.1; it is equal to `α̃ = α - d(w/||w||)`. Hence we solve
    `max_{w} αᵀw - λwᵀΩw - d||w||`
    This is similar, but not identical to, Equation (10.10): the norm penalty term is not squared. The same argument can be made to show that the norm and the norm squared are interchangeable, since the penalty constant $d$ is rescaled:
    `d||w|| ≈ (d/||w₀||) ||w||²`
    for $w$ close to $w_0 = w^*$ of the final solution.

3.  Robust factors (Ceria et al., 2012). We consider another instance of constrained optimization. A recurrent theme in this book is model misspecification. Factor models can be misspecified both in their factor structure and in their expected returns. Here, like in the case of robust alpha, we consider an unobserved factor, or a special case of misspecification. In effect, to worsen the Sharpe Ratio of the MVO portfolio. In order to reduce the impact, let us consider again an adversarial approach. Assume that there is a hidden factor, whose loadings we do not know, but whose volatility is given. We add this as a parameter that quantifies the impact of the missing factor.
    The new factor model contains an additional factor loading $v$ orthogonal to $B$. The covariance matrix is
    `Ω̃ = Ω + τ²vvᵀ`
    We solve
    `max_{w} αᵀw - λwᵀ(Ω + τ²vvᵀ)w`
    If $v$ is one of the basis vectors $e_i$, then the problem is
    `max_{w} αᵀw - λwᵀ(Ω + τ²/N Σᵢ eᵢeᵢᵀ)w` (The formula in book is `max αᵀw - λwᵀ(Ω̃ + τ²vvᵀ)w` then `max αᵀw - λwᵀ(Ω̃ + τ²/N Σᵢ eᵢeᵢᵀ)wwᵀ` which seems to have extra `wwᵀ`)
    So, yet again, we are solving an optimization problem with a penalized covariance matrix.

4.  Robust asset correlations (Boyd et al., 2017). Here we have another case of adversarial modeling that is expressed as a penalization term. Assume that we estimate the asset correlation matrix terms with some error independent of the asset pair, so that the difference between the estimated correlation and the true correlation is at most $d_{i,j}$. This is a common assumption in robust MVO problems and elsewhere (Natarajan’s “chooser” chooses a covariance matrix with the highest variance compatible with the error bound).
    `s.t. σ²(w) = arg max_{Δ} wᵀ(Ω̃ + Δ)w`
    `s.t. |Δᵢⱼ| ≤ dᵢⱼ, i,j = 1, ..., n`
    The objective of the nested problem is equivalent to
    `wᵀΔw = Σᵢⱼ wᵢΔᵢⱼwⱼ`
    Every term is maximized when
    `ρᵢⱼ = d × sgn(wᵢwⱼ)`
    and the objective function value is
    `(wᵀΔw)* = d Σᵢⱼ |wᵢwⱼ| Ω̃ᵢⱼ⁰.⁵`
    `= d (Σᵢ |wᵢ| Ω̃ᵢᵢ⁰.⁵)²`
    where `V` is a diagonal covariance matrix whose $i$-th diagonal term is the volatility of asset $i$. Let us plug this back in the original problem:
    `max αᵀw - λwᵀΩ̃w - λd||Vw||₁`
    And we have yet again a penalization term, which is, in this case, the square of an L1 norm of the portfolio weights. The function `||Vw||₁` is concave, so the optimization problem is convex. I summarize the penalization approaches in the table in Figure 10.3.

5.  Robust covariance matrix (Fabozzi and Wolf, 2009). Consider a different starting point to model robust covariance optimization. We assume that the adversary has a budget for the maximum cumulative squared error of the asset covariances `Σᵢⱼ Δᵢⱼ² ≤ d²`. This is the same as a bound on the Frobenius norm of the error matrix `||Δ||_F ≤ d`. The robust optimization problem is similar to the previous case:
    `max_{w} αᵀw - λwᵀΩ̃w - λσ²`
    `s.t. σ² = arg max_{Δ} wᵀ(Ω̃ + Δ)w ||Δ||_F ≤ d²`
    The strategy to solve this problem is similar to previous cases: the adversary maximizes a linear objective function with a norm constraint, see Appendix C.4 for the solution. In this case, `(wᵀΔw)* = d||wwᵀ||_F = d||w||²`, and the problem becomes an MVO with a quadratic penalization term.

**Exercise 10.1:**
Define the norm `||x||_A := ||A⁻¹x||`. Extend Goldfarb and Iyengar (2003), Reha Tütüncü and DeMiguel (2006) for additional interpretations of this penalty, and discuss their applicability to real-world settings.

| Approach             | Penalty                                                              | Parameter Interpretation                                                                                                |
|----------------------|----------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------|
| Uncertain Alpha      | λ_α times (sum squared times absolute value of α_hat)                  | λ_α times distance times volatility of missing factor                                                              |
| Robust Alpha (α̃)     | λ_α times (absolute value of hold) α̃                                   | λ_α times distance times volatility of hold-idio alpha_hat                                                              |
| Robust Factor        | λ_F times (sum squared times absolute value of hold) F                 | λ_F times distance times volatility of missing factor                                                              |
| Robust Correlations  | λ_ρ times (sum of abs value of the sub i comma j times hold) w squared | λ_ρ times distance times (sum of abs value of the sub i comma j times hold) w squared                                   |
| Robust Covariance    | λ_Ω times (sum of abs value of times hold) w squared                   | λ_Ω times distance times (sum of abs value of times hold cap omega hat sub hold) times omega hat sub hold times absolute value of... |

**Insight 10.3: Distinction between constraints and penalties**
Although they can yield the same optimal portfolio, the constrained and penalty version differ in two important ways. The first one is that the shadow price of the constraint is known only after the optimization. It is true that for some values the solution can be the same, but with a poor choice of the right-hand side of the constraint we don’t know the trade off between constraint limit and optimum value. This is not the case with a penalty: we set the price, and the price is often a more intuitive parameter than the quantity. For a risk-averse optimization, the price is unchanged, making comparisons easier. When the interpretation is clear, penalties are preferable. The second difference is in a continuous way: the first one is that the constrained solution may have no feasible solution, which is, in a loose sense, like saying that the price of the constraint is infinite. This is never the case with a penalized formulation, which is always feasible.

---

**10.3 How Does Estimation Error Affect the Sharpe Ratio?**

An investor starts with estimates of expected returns $\alphã$ and of the covariance matrix $\Omegã$. As derived in Section 9.2.4, the optimal portfolio is proportional to $\alphãᵀ\Omegã⁻¹$. The proportionality constant is irrelevant for the Sharpe Ratio. The realized Sharpe Ratio, however, is a function of the true expected returns and covariance matrix $\alpha, \Omega$:
`SR(α̃, Ω̃) = √(α̃ᵀΩ̃⁻¹α̃)`
We compare the realized Sharpe Ratio to the best Sharpe Ratio, based on the true values of $\alpha$ and $\Omega$, given by Equation (9.18):
`SR(α, Ω) = √(αᵀΩ⁻¹α)`
We call this the Sharpe Ratio Efficiency (SRE). It is important to study this quantity, because we want to know, at all times, whether we are losing a great deal of performance from inaccurate parameter estimation or large transaction costs. We will ask a few qualitative and quantitative questions, and see how far the analysis can take us.

First, prove an intuitive fact: incorrect estimates worsen performance.

**Theorem 10.1**
The Sharpe Ratio Efficiency is less or equal to one, and is equal to one if and only if $\Omegã⁻¹α̃$ and $\Omega⁻¹α$ are collinear.
Proof:
The SRE is
`SR(α, Ω̃) / SR(α, Ω) = (αᵀΩ̃⁻¹α̃) / (√(αᵀΩ⁻¹α) √(α̃ᵀΩ̃⁻¹α̃))`
Let
`a = Ω⁻¹/²α, b = Ω̃⁻¹/²α̃`
so that
`SR(α, Ω̃) / SR(α, Ω) = (aᵀb) / (||a|| ||b||)`
The Sharpe Ratio Efficiency is always less than one because of the Cauchy-Schwarz inequality, unless $\Omegã⁻¹/²α̃$ and $\Omega⁻¹/²α$ are collinear.

**10.3.1 The Impact of Alpha Error**

It is more useful to derive a lower bound on performance inefficiency, based on the estimation error of either expected returns or covariance.
We need to introduce a few basic results. Let the norm of a matrix be defined as the operator norm. Define the relative alpha error as
`||α̃ - α|| / ||α|| ≤ δ_alpha`
In the Appendix (Section 10.4.2) I prove the following result:
`SR(α̃, Ω_T) / SR(α, Ω_T) ≥ 1 - 2 ||Ω_T¹/²(α̃-α)|| / ||Ω_T¹/²α|| - ||Ω_T¹/²(α̃-α)||² / ||Ω_T¹/²α||²`
The alpha error inflates the Sharpe Ratio by magnified by the norm `||Ω_T¹/²||`. This is quite intuitive: the ratio of the largest eigenvalue to the smallest eigenvalue of the matrix `Ω_T`, or the ratio of the largest variance to the smallest variance associated to eigenfactors. The ratio is the condition number of a matrix. If we are operating in this span (all alphas are orthogonal to factor returns), then there is no variance misestimation, and the condition number is one. The ratio of the largest asset idiosyncratic variance to the smallest asset idiosyncratic variance.

**10.3.2 The Impact of Risk Error**

If there is $\kappa > 0$ such that
`||Ω̃¹/²Ω⁻¹/² - κI|| ≤ δ_risk`
then
`SR(α, Ω̃) / SR(α, Ω) ≥ 1 - 2δ_risk / (κ + δ_risk)`
This formula follows directly from Equation (10.26). At first sight, what is interesting about this result is how weak it is. Let us consider a few special cases. We define
`H := Ω̃⁻¹/²ΩΩ̃⁻¹/²`
1.  If the estimated covariance matrix is biased, but uniformly so, i.e., `Ω̃ = kΩ`, then `H = k⁻¹I` and there is no efficiency loss. We knew this already from the previous chapter. What happens in practice is that we would deploy a portfolio with the highest Sharpe Ratio, but incorrect volatility.
2.  Say that we correctly estimate the covariance matrix structure, only that we scale it. `Ω̃ = kΩ`. It can still happen that we have an SRE of one! This will happen if `α` is proportional to an eigenvector of `H` with a positive eigenvalue. Say the associated eigenvalue is `η²`. Then, use directly Equation (10.24):
    `SRE = (αᵀ(η²Ω)⁻¹α) / ||α||² = sgn(η)`
    Even more paradoxically though, the formula implies that if `α` is proportional to an eigenvector of `H` with negative eigenvalue, then the Sharpe Ratio Efficiency is $-1$. Incidentally, `H` is neither necessarily symmetric nor positive-definite, so a negative eigenvalue is indeed a possibility.
3.  But, you may argue, this is an exceptional circumstance. Consider a simpler but instructive case. We make the assumption that `Ω̃, Ω` have the same eigenvectors (aka eigenfactors) as `H`. In other words, they only differ because of the singular values.
    `Ω̃ = UΛ̃Uᵀ, Ω = UΛUᵀ`
    so that
    `H = Ω̃⁻¹/²ΩΩ̃⁻¹/² = UΛ̃⁻¹/²UᵀUΛUᵀUΛ̃⁻¹/²Uᵀ = UΛ̃⁻¹/²ΛΛ̃⁻¹/²Uᵀ`
    A great simplification. Decompose the eigenvalue ratio as $\nu_i = \lambda_i / \lambdã_i$. What is the lower bound on the SRE in this case for $\kappa$?
    `δ := min_i |(λ̃ᵢ - λ_i)/λ_i| = min_i |(νᵢ - κᵢ)/κᵢ|`
    and the optimal point is $\kappa^* = \nu_{avg} = n^{-1} \Sigma_i \nu_i$. We use these values in Equation (10.29) to obtain
    `SRE ≥ ( (1/2)(min_i ν_i + max_i ν_i) ) / √(min_i ν_i max_i ν_i)`
    `SRE ≥ 1 - (max_i ν_i - min_i ν_i)² / ( (min_i ν_i + max_i ν_i)² )`
    Hence the loss in efficiency arises from the fact that we misestimate the risk towards the volatility of eigenvectors of the error covariance matrix. If we underestimate them (or overestimate them) by the same constant, then we lose nothing, as noted in the first point above. Let us think of an adverse case. Say we estimate all volatilities exactly (`ν_i = 1`) except for one, which we underestimate by 50%. Then the worst-case loss of Sharpe Ratio can be 33%.

---

**10.4 Appendix**

**10.4.1 Theorem on Sharpe Efficiency Loss**

These theorems are informally introduced in Section 10.3.
We recall that
`||H⁻¹x|| ≤ ||H⁻¹|| ||x||`
and
`| ||Hx|| - ||Hy|| | ≤ ||H|| ||x-y||`
so that
`||Hx|| - ||Hy|| ≤ ||H(x-y)|| ≤ ||H|| ||x-y||`
Also, use the cosine rule:
`||a-b||²/||b||² = 2(1 - aᵀb / (||a|| ||b||) )` (assuming `||a|| = ||b||`)
`SR(α̃, Ω̃) / SR(α, Ω) = (ãᵀb̃) / (||ã|| ||b̃||)`
`= 1 - (1/2) ||ã-b̃||²/||b̃||²` (approximation for `ã ≈ b̃`)
where `a, b` are defined by Equations (10.23) and (10.28).

**Lemma 10.1:**
Let `H` be symmetric positive-definite, `x, y ∈ ℝⁿ`, and
`| ||x||/||y|| - xᵀy / (||x|| ||y||) | ≤ δ`
Then
`|| (x/||x||) - (y/||y||) || ≤ √(2δ)`
(Proof on page 475, right column)
Let $a, b \in \mathbb{R}^n$.
`||Hx|| / ||Hy|| ≤ 2 min{||H||, 1}` (This formula seems specific or misprinted)
The proof involves decomposing vectors and using eigenvalue properties, leading to:
`||Hx||/||Hy|| ≥ 1/√(1 + ||H||²δ²)`
This bound is tight, up to a constant. For example, consider the case of diagonal `H = diag(λ₁, ..., λ_n)`. We have
`x = e_n + δe_1, y = e_n`, with $e_i$ the standard basis vectors. We have
`||x||/||y|| - xᵀy/(||x|| ||y||) ≈ (3/2)ε := δ`
`||Ω̃⁻¹/²Ω¹/² - I_n|| ≤ δ`
Then
`SR(α, Ω̃) / SR(α, Ω) ≥ 1 - (1/2) ||Ω̃⁻¹/²Ω¹/² - I_n||_F² δ` (This formula seems to mix norms and parameters)
The image shows: `SR(α, Ω̃) / SR(α, Ω) ≥ 1 - 2 ||Ω̃¹/²Ω⁻¹/² - I_n|| δ`

**Theorem 10.2 (Misspecification of risk)**
If `||Ω̃⁻¹/²Ω¹/² - I_n|| ≤ δ`
then `SR(α, Ω̃) / SR(α, Ω) ≥ 1 - 2δ / (κ + δ)`
where $\kappa$ is the condition number of $\Omegã^{-1/2}\Omega^{1/2}$.

**Theorem 10.3 (Misspecification of alpha)**
If `|| (α̃/||α̃||) - (α/||α||) || ≤ δ_α`
then `SR(α̃, Ω) / SR(α, Ω) ≥ 1 - 2 ||Ω|| ||Ω⁻¹|| δ_α`
Proof:
Let `H_α := Ω̃¹/²Ω⁻¹/²`. Using this notation, the SRE Equation (10.24) and Condition (10.27) are:
`SR(α̃, Ω_T) / SR(α, Ω_T) = α̃ᵀH_α / (||α̃|| ||H_α||)`
`||H - H_α I_n|| ≤ δ`
Let `λ₁ ≥ λ₂ ≥ ... ≥ λ_n` be eigenvalues of `H_α`. The condition `||H - H_α I_n|| ≤ δ` is equivalent to `λ_i - κ*| ≤ δ` for all `i`. Then
`α̃ᵀHα / (||α̃|| ||Hα||) ≥ κ - δ`
`α̃ᵀHα / (||α̃|| ||Hα||) ≤ κ + δ`
`(α̃ᵀHα / ||α̃||²) / (αᵀHᵀHα / ||Hα||²) ≥ (κ-δ)/(κ+δ)`

---

**The Takeaways**

1.  Mean-Variance Optimization (MVO) can suggest shorting assets with positive expected returns if their correlation with other assets is high relative to their Sharpe Ratios.
2.  Errors in forecasted Sharpe Ratios and correlations can substantially reduce realized portfolio Sharpe Ratios, with parameter estimation errors worsening performance loss due to estimation error.
3.  Estimation errors in expected returns degrade portfolio performance, especially when errors are large relative to the accuracy of risk estimates.
4.  Constraining portfolio allocations (e.g., long-only, gross exposure limits) can reduce sensitivity to estimation error by limiting out-of-sample variation, but potentially lowering maximum achievable Sharpe Ratio.
5.  Non-linear and quadratic constraints, such as those on factor exposure or tracking error, allow for more tailored risk control in portfolio construction.
6.  Penalties can serve as a flexible alternative to constraints, especially when risk tolerance or trading costs need to be balanced within feasible limits.
7.  Robust optimization, which models uncertainty in alpha and covariance estimates, helps mitigate performance loss by introducing penalties that account for estimation risk.
8.  Shrinking or regularizing asset correlations and variances can improve realized Sharpe Ratios when covariances are uncertain, reducing sensitivity to estimation error.
9.  Transaction costs, market impact, and trading costs can reduce portfolio drift and control rebalancing expenses, particularly in markets with high transaction costs.
10. The augmented Lagrangian method often combines constraints and penalties to balance estimation error tolerance with implementation feasibility, allowing for adaptable portfolio construction.

---

**Notes**

1.  Before reinventing the wheel, know that some financial optimization packages abstract the modeling of the GMV constraint, so that you just have to specify it.
2.  ... for example, a few years ago, 130/30 portfolios were popular. These strategies managed net-long portfolios, with 30% of NAV invested in shorts and 130% in matching longs.
3.  Some solvers are able to understand from the description of the problem whether $f$ is convex or not.
4.  For example, see Clarke et al. (2022).
5.  J.P. Morgan (2007) finds that this analysis is not very large. See Jagannathan and Ma (2003) for an early contribution to the analysis of long-only constraints; the work by DeMiguel et al. (2009a) on trading penalties; Fan et al. (2012) on GMV constraints and Ceria et al. (2012); Saxena and Stubbs (2012) on penalties on the factor covariance matrix.
6.  A volatility constraint or penalty is in practice computationally more burdensome than a variance constraint or penalty.
7.  The third leg of the trading costs is market impact modeling cost. We will cover this in later chapters.
8.  Early papers on model estimation error, and the relative impact of alpha and estimation errors, are Michaud (1989), Chopra and W. Ziemba (1993), Broadie (1993).
9.  Let H be a symmetric positive-definite matrix and let X,Y be its SVG. Define H¹ᐟ²X = YΛ¹ᐟ²Vᵀ. Then ||H¹ᐟ²X - Y||_F² ≤ ||H¹ᐟ²X||_F² + ||Y||_F² - 2σ_min(H¹ᐟ²XYᵀ), which can be found in almost any linear algebra book. If x,y ∈ ℝⁿ, then |aᵀb| ≤ √aᵀa √bᵀb with the equality holding only if a = kb.
10. We use the notation e₁, ..., e_n for the standard basis in ℝⁿ.

```

Okay, here is the Markdown compilation for Chapter 11.
     Everand

**Chapter 11**
**Market Impact-Aware Portfolio Management**

**The Questions**

1.  What are the main sources of trading costs, and how do they affect the profitability of a trading strategy?
2.  How can we model and quantify market impact, specifically temporary market impact, in the context of trading?
3.  How does market impact propagate over time, and what functional forms are commonly used to describe this propagation?
4.  How can finite-horizon optimization be structured to manage expected returns, market impact, and risk constraints over multiple periods?
5.  How does an infinite-horizon optimization framework differ from finite-horizon models, and when is it appropriate to use each approach?

Trading can possibly make money, but it surely costs money. When we execute a trade, we incur costs of all sorts: financing costs when we leverage our portfolio; borrowing costs when we short securities; commission costs to exchanges and other intermediaries. In addition to all of these costs, we pay for information, our or other market prices. Information that, once acted upon, that is, once we place a sell order, we somewhat push its price upward, which in turn makes the additional purchase of a security more expensive. What is less intuitive, however, is that this “price impact” can turn a strategy that is potentially profitable into a very unprofitable one. We see that there are two components to this cost. The first one is an instantaneous cost, the other governing price impact dynamics. The second is to use these laws to optimize the performance of our trading strategy. These two questions inform the organization of the chapter. In the next section, we provide a quick description of market impact models. Then we descend into the infernal circles of optimal execution.

---

**11.1 Market Impact**

A synthetic definition of market impact is the following (Kyle et al., 2020): “Market impact is the cumulative market-wide response of the arrival of new order flow.” The underlying process is complex and results from the joint contribution of several factors:

*   First, there is a direct reduction in inventory of the securities being bought or sold, causing a price movement.
*   Second, there is an informational effect: concluding a transaction may reveal private news about the future price of a security, as well as be indicative of future transactions (i.e., order flow).
*   Third, there is a mimetic effect: when participants, in the absence of information, imitate each other’s behavior, leading to temporary run-ups or run-downs.
*   Fourth, there is a strategic aspect. Even in the absence of information, strategic participants trade so as to exploit potential arbitrages arising from price impact.

Each one of these phenomena is complex, and hard to model. The total transaction cost associated to a trade is usually decomposed into three components:

Expected Transaction Cost = (spread cost)
                        + (temporary market impact)
                        + (permanent market impact)

The spread cost reflects the difference between the bid and the ask price. A market order “crosses” the spread, i.e., is executed at the best price offered by the contra-party. A limit order rests in the orderbook awaiting for execution, and thus consumes liquidity. On the other side, a limit order has an associated execution price, and adds liquidity. The average cost incurred in a trade is modeled as a function of the bid-ask spread, and assumed to be independent from other transactions. It is usually modeled as an asset-dependent percentage of the dollar traded.

The permanent impact is the price change that persists long after the order has been executed.

The temporary impact (also called “slippage”) is the price change that occurs during order execution and immediately afterwards, until price reaches equilibrium.

In the rest of the chapter, we focus on temporary impact, and effectively ignore both spread costs and permanent impact, although they are both interesting areas of research. The rationale for this choice is that both quantities are limited from the vantage point of a modeler specifically concerned with portfolio optimization, as opposed to one interested in understanding the mechanisms underlying price impact. Spread costs and temporary impact are by far the most important concerns because of their magnitude compared to permanent impact. Even our discussion of temporary impact is kept as short as possible, but not shorter.

**11.1.1 Temporary Market Impact**

We want to submit a large order, usually called a parent order or a meta-order. Depending on the asset class, we have different options for execution. For example, we could split the parent order into smaller “child” orders and execute them on exchange, or place them with a single algorithmic broker, whose mandate is to minimize cost, despite the broad array of trading venues and matching mechanisms, the expected market impact is described well by a common formula. Let `ẋ_t` denote the net number of shares traded up to time `t`, and with `ẋ_0` the trading rate, i.e., the number of shares traded per unit time. We may introduce two functions: the instantaneous impact function `f: ℝ → ℝ⁺`, and the propagator `G: ℝ⁺ → ℝ⁺`. We also have a positive constant term `κ`, which is a function of the security characteristics. The expected temporary market impact is given by the formula
`(11.1) E(P_T) - P_0 = κ ∫₀ᵀ f(ẋ(t))G(T-t)dt`
For an interpretation, consider the case of a marketable order: single-buy trade, short `N` shares, by selling at time `t_0`. Then the market impact `E(P_T) - P_0 = κ f(N)G(T-t_0)`. The market impact is proportional to the trade size, and is followed by a “relaxation” back to an equilibrium level. The function `G` is monotonically decreasing, thus reflecting the long-term convergence to an equilibrium level (see Figure 11.1). The function `f` should intuitively be monotonically increasing: the higher the trading rate, the higher the instantaneous impact. The overall impact (see Equation 11.1) is then a linear superposition of pulse trades, each one having an impact that relaxes back to equilibrium over time. The big question is then what is the functional form of `f` and `G`. Below are a few alternatives.

**Figure 11.1:** Market impact over time for a single trade executed at time `t₀`. The decay after `t₀` is proportional to `G`.

The functions are
`f(ẋ) = σ sgn(ẋ) |ẋ|^(β/2)`
`G(t) = δ(t)`
where `β ∈ (0.1, 1)` is the security’s volatility, `σ` is the total number of shares traded per unit time by all market participants, and `δ(.)` is the Dirac delta function.
We consider here and in the remainder of this book a buy order, i.e., `ẋ > 0`. The trading cost is
`C[ẋ] = κ ∫₀ᵀ dτ ẋ₀² ∫₀^(T-τ) dδ δ(t-s)`
`= κσ ∫₀ᵀ dτ ẋ₀^(β/2) ∫₀^(T-τ) dδ δ(t-s)`
`= κσ (Q/T)^(β)`
`= κσ (Q/T)^(β) T`
As an important example, we trade share quantity `Q` at constant rate in `[0,T]`, and the total traded volume in the market in the same period is `V = σT`. The ratio `Q/V` is usually referred to as the participation rate (or percentage of volume). From the formula above, the total unit costs are
`C = κσ (Q/V)^(β)`
The unit cost is decreasing in the execution time. By replacing `V = σT`, we have `C ∝ T^(1-β)`.

There is an argument made on the basis of physical dimensions; this suggests that `β = 1/2`. Toth et al. (2011) proposed an argument based on generalizing the Almgren-Chriss model. They assume that there are only three quantities that matter:
`Q`, which we interpret as the dollar value traded during a period.
`V`, which we interpret as the dollar value traded by all participants during the same period.
`σ`, the security’s volatility during the same period. Volatility has the physical unit of the inverse square root of time.
The transaction cost `c` is dimensionless and invariant in the units chosen for currency or time. If the argument is a polynomial of the input quantities above, we write
`c(Q, σ, V, T) = f(V^(γ)Q^(α))`
`(currency) / ( (currency)^(γ) * (time)^(γ/2) * (1/time)^(α/2) )`
from which `γ = -α` and `-γ/2 - α/2 = 0`. Set, without loss of generality `α = -1/2`. It follows that the cost is a function of
`V^(-1/2)Q^(1/2) σ`. `c(Q, σ, V) = f(V^(-1/2)Q)`
(Kyle, 1985; Huberman and Stanzl, 2004) This model is a special case of Almgren-Chriss’s model and precedes it historically. The functions are
`f(ẋ) = σ (ẋ/v)`
`G(t) = δ(t)`
The model is interesting in two regards. First, it is robust to price manipulation: a round-trip trade where an agent starts and ends flat, and is expected to extract a profit from the market impact they generate (Huberman and Stanzl, 2004; Gatheral, 2010). Second, it is empirically supported. We will use this model in Chapter 12, where we present a model of information trading.

(Obizhaeva and Wang, 2013) The functions are:
`f(x) = ẋ/v`
`G(t) = e^(-t/τ)`
The trading cost is
`C[ẋ] = κ ∫₀ᵀ dτ ẋ(τ) e^(-(T-τ)/τ) ∫₀^(T-τ) ds e^(-s/τ) ẋ(s)`
Consider again the constant-rate trade of `Q` shares over an interval `[0,T]`. The trading cost is:
`C = κ (Q/T)² τ [1 - τ/T (1 - e^(-T/τ))]`
`c = κ [τ/T - (τ/T)² (1 - e^(-T/τ))] (Q/V)`
Consider the two cases where timescales of execution and relaxation separate: “slow” execution `τ ≪ T` and “fast” execution `τ ≫ T`.
`c ≈ κ (Q/V) τ/T` if `τ ≪ T`
`c ≈ κ (Q/V) T/(2τ)` if `τ ≫ T`
For the slow execution case, the unit cost is inversely proportional to execution time, whereas it is independent of `T` when `τ ≪ T`. The overall market impact time series is shown in Figure 11.2. The Obizhaeva and Wang (OW) model (Obizhaeva and Wang, 2013) has a dynamic formulation. Let `Q_t = ∫₀ᵗ ẋ_s ds` be the cumulative traded notional, and `I_t ∈ ℝ` be the OW market impact. The OW market impact is modeled as
`I_t = κ/τ ∫₀ᵗ e^(-(t-s)/τ) ẋ(s) ds`
`İ_t = κ/τ ẋ_t - 1/τ I_t`

**Figure 11.2:** Market impact over time. The dashed line is the permanent market impact of the unit flow. The sum of temporary and permanent market impacts.

With an initial condition `I(0) = 0`, and with constant rate of execution `ẋ_0 = Q/T`, this differential equation has a simple solution:
`I_t = κQ/τ (1 - e^(-t/τ))`
and the trading cost is given by
`C = ∫₀ᵀ dt I_t q`
`= (κT/v) [τ/T (1 - τ/T (1 - e^(-T/τ)))]`
`= κT [τ/T - (τ/T)² (1 - e^(-T/τ))] (Q_T/V)`
The formula of `c = Q_T/V` is the same form as Equation 11.6.

(Gatheral, 2010) The functions are
`f(ẋ) = σ sgn(ẋ) |ẋ|^(1/2)`
`G(t) = 1/√t`
The trading cost is
`C = κσ ∫₀ᵀ dt ẋ(t) ∫₀^(t) ds (ẋ(s)/√(t-s))`
Assuming constant rate trading `ẋ_0 = Q/T` shown over an interval `[0,T]`, i.e., `ẋ_0 = Q/T` ... yields our final result:
`C = (4/3) κσ √(Q³/T)`
`c = (4/3) κσ √(Q/T)`
The unit execution cost is `c = (4/3) κσ √(Q/T)`, and independent of `T`.

---

**11.2 Finite-Horizon Optimization**

We have a large class of models to choose from. Which one to use is a question that can be settled empirically. In the following, we use the general form of Equation (11.1) for market impact, and a term proportional to trade size for transaction costs.

Let us focus on a single security. The market-impact-related trading cost is, after integrating by parts,
`ΔP_k = z_k P_k = z_k P_0 + z_k P_1 + ... + z_k P_k`
`ΔP_k = z_k P_0 + z_k P_1 + ... + z_k P_k = ∫₀^(t_k) ż_s P_s ds`
The term `P_0ẋ_0` is not a decision variable, so we can ignore it in the optimization process. As a boundary condition on the optimization, we assume that we end flat, i.e., `x_N = 0`. The overall trading cost becomes `-∫₀^T μ_s dx_s`. Now, let us write the expected costs from trading for a single asset:
`Cost_{trade} = - ∫₀^T μ_s dx_s - ∫₀^T f(ẋ_s, G_s) dx_s`
`(transaction cost) (impact cost)`

The idea behind multi-period optimization is to use the current forecast for excess returns over time, and plan trades for the entire horizon. Only the front-end of the trade is executed. In the next trading period, we develop or receive a new forecast, and we optimize again, using the updated portfolio as initial condition. This approach provides both stability and feedback. The stability comes from the fact that we use a long-term forecast, and the feedback from the fact that the functions will allow us to account for the decay in impact. In addition, we can also include as many side constraints as we want. In this section, we only include linear constraints, since they are the most common ones (e.g., constraints on factor risk, turnover, maximum position size, etc.). We have to solve numerically an optimization, whose execution time may introduce delays in trading and therefore adversely affect profitability. The second one is that the convergence properties of the problem depend on the forecast. Specifically, we need to ensure that the objective function is concave. This depends on the choice of market impact, which can make the problem non-concave. The third one is that we are incorporating the change in expected returns as a function of the horizon, but are not incorporating in the problem the dynamics of updates in our return forecast from one period to the next.

We split the trading periods into intervals delimited by timesteps `T_i`. We use the convention
`Δ_i := T_i - T_{i-1}`
For example, `Δ_k` may be in minutes, `Δ_N` may be in hours. `Δ_N` could be one day, `Δ_1` could be one week and `Δ_0` could be four weeks. At time `T_k`, we hold `x_k` dollars of the security. In interval `[T_i, T_{i+1}]` we have expected return `μ_i` and trade at rate `ẋ_i`. The relationship between `x_i` and `ẋ_i` is
`x_i = x(T_i)`
`ẋ_i = (x_i - x_{i-1})/Δ_i`
At time `t ∈ [T_i, T_{i+1}]`, we hold
`x(t) = x_i + ẋ_i(t - T_i)`
dollars in the security. This equation assumes we are not adjusting our holdings with price changes. The correct formula would be `ẋ_i = ż_i P_i`. In the words of Boyd et al. (2018), we are ignoring “second-order terms” in the holdings. This may be reasonable on two grounds. First, for short-enough periods, `P_i ≈ P_0`. Second, because we are not including the impact of `ẋ_i` on `P_i`, which is smaller than other errors already present in the model. For example, we replaced the realized market impact with the expected impact. The initial condition `x_0` and the trading rates `ẋ_i` determine `x_N`. We can then express `PnL_{total}` as a function of `ẋ_i`, and add this term to the objective function. The rest is (hairy) details.
`(transaction cost) = - Σ_{i=1}^N μ_i Δx_i`
`(impact cost) = - Σ_{i=1}^N f(ẋ_i, G_i) Δx_i`
`a_{i,j} > 0` if `i ≠ j`, `a_{i,j} < 0` if `i = j`
The variance penalty is integrated over a one interval.
`Var(x_N) = ∫ x_Nᵀ Ω x_N ds`
`Var(x_N) = Σ_{i,j} Δx_i Δx_j Ω_{i,j} + Δx_iᵀ Ω_{ii} Δx_i + (Δx_i + Δx_{i+1}) ...`
Now we can write the optimization formulation. We use the following notation:
`X = [x_1ᵀ, ..., x_Nᵀ]ᵀ`
`f(x) = -μᵀx - f_I(x)`
We also introduce `n×1` pairs of matrices and vectors `H_k ∈ ℝ^{m_k×n}`, `h_k ∈ ℝ^{m_k}`. These objects store linear constraints on holdings and portfolios for each stage of the optimization problem.

`max_{x_0, ..., x_N} Σ_{k=0}^{N-1} μ_kᵀ(x_{k+1} + x_k)` (expected PnL)
`- Σ_{k=0}^{N-1} A_kᵀ |x_k|` (trading cost)
`- Σ_{k=0}^{N-1} Σ_{j=k|j≠k}^{N-1} x_kᵀ Ω_{k,j} x_j` (impact cost)
`- (1/2) Σ_{k=0}^{N-1} [x_kᵀ Ω_{k,k} x_k + ... + (λ/2)ᵀΩ_N x_N]` (variance penalty)
`s.t. x_k - x_{k-1} - Δ_k = 0` (flow conservation)
`H_k x_k = h_k` (side constraints)
`x_k ∈ ℝ^n, k = 0, ..., N-1`
We assume that the initial position `x_0` is given, and usually (but not necessarily) we set a final holding condition `x_N = 0`. The “not necessarily” qualification depends on the parameters used in the problem. For example, if we set `μ_N = 0`, the optimization will attempt to reduce the size of the portfolio in the last stage, since holding the position incurs a risk cost. For large variance penalties and flat expected returns, the optimizer will sell a lot of `x_N`, that is, obtain `x_N < 0`, without the need of boundary condition.

---

**11.3 Infinite-Horizon Optimization**

We now present an infinite-horizon optimization model, introduced by Litterman et al. (2003). Compared to the finite-horizon optimization model of the previous section, the model allows only for quadratic costs and cannot accommodate generic side constraints `H_k x_k = h_k`. On the other side, it is flexible with respect to alpha processes.

We maximize a mean-variance objective, inclusive of transaction costs.
`(11.7) max_{ẋ} ∫₀^∞ e^(-ρt) [ μ_tᵀẋ_t - (1/2)ẋ_tᵀCẋ_t - (1/2)x_tᵀΩx_t ] dt`
where:
1.  The asset expected returns are described by a non-anticipative, stochastic process `μ_t` taking values in `ℝ^n`, defined over a probability space `(Ω, F, P)`.
2.  The matrix `C ∈ ℝ^{n×n}` is positive-definite and diagonal.[5] The cost rate from trading `ẋ_t` at time `t` is `(1/2)ẋ_tᵀCẋ_t`.
3.  The return covariance matrix `Ω ∈ ℝ^{n×n}` is positive-definite, with positive penalty factor `ρ`.
The optimal trading policy is described in Procedure 11.1.

**Procedure 11.1: Infinite-horizon optimal trading policy**
**Input:**
symmetric positive-definite cost matrix `C ∈ ℝ^{n×n}`;
symmetric positive-definite return covariance matrix `Ω ∈ ℝ^{n×n}`;
expected return process `μ_t` taking values in `ℝ^n`;
initial portfolio `x_0 ∈ ℝ^n`.
**Define:**
`(11.8) Γ := (C⁻¹Ω)¹/²`
`(11.9) b_t := ∫_t^∞ e^(-ρ(s-t)) Γ⁻¹ C⁻¹ E_s[μ_s] ds`
**Output:**
Optimal trading policy.
`x_t = e^(-Γt) (x_0 + ∫₀ᵗ e^(Γs) b_s ds)`
`ẋ_t = -Γx_t + b_t`
Optimum: `μ_t - Cẋ_t - (1/2)∫_t^∞ e^(-ρ(s-t)) Ωx_s ds = 0`

Let us try to interpret the (rather magical) objects we have introduced.
The `b_t` term of the vector `x_t` is a discounted expected return of asset `j`, where the discount factor is determined by the matrix `Γ`.
Consider the special case of uncorrelated asset returns, so that `C` and `Ω` are diagonal. The greater the volatility or the risk aversion, the larger the elements of `Γ`, thus the larger the discount factor.
On the other side, the higher the trading costs, described by `C_j`, the less we want to discount the future. Why? Because trading is expensive, we want to weight future returns more, so that we do not chase only instantaneous performance.
What is being discounted in `b_t` is not quite the future expected returns, but the alpha-normalized expected returns `C⁻¹E_s[μ_s]`. If unit costs are higher, we have a smaller future adjusted returns being discounted. However, we have a smaller `Γ`, hence we discount the future less. There are two competing effects. In Exercise 11.1, you will explore their relative impact. The term `Γ⁻¹` in `b_t` is the discounted version of the optimal trading policy.
`(11.10) b_t = (∫_t^∞ e^(-ρ(s-t)) (Γ⁻¹C)⁻¹ E_s[μ_s] ds)`
The optimal trading policy is recursive. The next optimal portfolio is a linear combination of the existing portfolio, discounted using matrix `Γ` and of the “alpha-to-go” `b_t`.

**Exercise 11.1 (The Impact of Costs on Trading).**
Consider the following simple problem. There is only one asset with volatility `σ` and cost parameter `c`. Consider two cases:
1.  The signal’s strength `μ` is exponentially decaying over time: `μ_t = μ_0 e^(-λt)`, with `λ > 0`.
The optimal strength is constant in interval `[0,T]`.
Prove that `b_0(c)` is a decreasing function of `c` in both cases. Generalize this result.

**11.3.1 Comparison to Single-Period Optimization**
Let us use the single-period problem. Define
`(11.11) Max E_k[μ_{k+1}ᵀ(x_{k+1} - x_k) - (1/2)(x_{k+1} - x_k)ᵀC(x_{k+1} - x_k) - (1/2)x_{k+1}ᵀΩx_{k+1}]`
`(11.12) Max E_k[μ_{k+1}ᵀx_{k+1} + C x_kᵀx_{k+1} - (1/2)x_{k+1}ᵀ(C+Ω)x_{k+1}]`
`(11.13) x_{k+1} = (C+Ω)⁻¹(E_k[μ_{k+1}] + C x_k)`
In the case `ρC⁻¹Ω ≪ I`, we can approximate
`x_{k+1} ≈ (I + ρC⁻¹Ω) C⁻¹ E_k[μ_{k+1}]`
The solution is similar to multi-period, in that it is a combination of the existing portfolio and an alpha-related term. If we assume that `Ω = 0`, i.e., no risk aversion, and `ρC⁻¹Ω ≪ I`, we approximate the first term with `x_k` and the multi-period solution is
`x_{k+1} ≈ (I - (ρC⁻¹Ω)²) C⁻¹ E_k[μ_{k+1}]`
The two are identical, except that a square-root term appears in the multi-period approximation.

**11.3.2 The No-Market-Impact Limit**
Consider the case of vanishing market impact. We set `C = cI_n` and let `c ↓ 0`. When `Γ ≥ I` from Equation (11.8), we have
`b_t = ∫_t^∞ e^(-ρ(s-t)) E_s[μ_s] ds`
`≈ e^(-ρt) C⁻¹ μ_t`
`= Γ⁻¹ e^(-ρt) C⁻¹ μ_t |_{s=0}^{s=∞}`
`= Γ⁻¹ (e^(-ρt) C⁻¹ - I) μ_t`
`≈ Γ⁻¹ C⁻¹ μ_t`
and
`ẋ_N+1 = -Γx_N + b_N`
`x_N+1 = (I - ρC⁻¹Ω)⁻¹ C⁻¹ E_N[μ_{N+1}]`
`≈ (I - ρC⁻¹Ω)⁻¹ C⁻¹ μ_{N+1}`
`x_{k+1} = (I - ρC⁻¹Ω)⁻¹ C⁻¹ E_k[μ_{k+1}]`
In the limit `ρC⁻¹Ω → 0`, a solution exists if
`x_t = (ρC⁻¹Ω)⁻¹ C⁻¹ μ_t`
`= ρ⁻¹Ω⁻¹μ_t`
This is the solution to the single-period MVO problem in the absence of transaction costs. The optimal solution is to rebalance instantaneously to the MVO allocation. Depending on the instantaneous alpha prediction. We have recovered the result from traditional single-period optimization.

**11.3.3 Optimal Liquidation**
Suppose that we hold a portfolio `x_0`, and have no forward-looking alpha: `μ_s = 0` for `s ≥ 0`. What is the optimal trading policy? In this case, `b_s = 0` and the optimal trade-value solution to the solution to the equation `ẋ_s = -Γx_s`. We reduce the position at an exponential rate, with the rate of liquidation depending on the matrix `Γ`. The larger the coefficient of risk aversion `ρ` and the volatility, the faster the liquidation. The higher the cost, the slower the liquidation.

**11.3.4 Deterministic Alpha**
Say that the future excess returns are a deterministic function `μ_s`. The function `b_t` is also deterministic and given by the integral (11.9). The solution to the Ordinary Differential Equation (ODE) (11.10) is
`b_t = ∫_t^∞ e^(-Γ(s-t)) C⁻¹μ_s ds`
`x_t = e^(-Γt) (x_0 + ∫₀ᵗ e^(Γs) C⁻¹μ_s ds)`
It is useful to present an indicative case of a “spiked” alpha: `μ_s(t-s_0) = μ_0 f(t-s_0)`. In this case the function `b_t` takes a simple form:
`b_t = 1/(t_0-t) ∫_t^(t_0) e^(-Γ(s-t)) C⁻¹μ_0 ds`
For `t ≤ t_0`,
`x_t = e^(-Γt) (x_0 + ∫₀ᵗ e^(Γs) Γ⁻¹ C⁻¹μ_0 ds)`
`= e^(-Γt) (x_0 + Γ⁻¹ cosh(Γt) Γ⁻¹ C⁻¹μ_0)`
In the formula above, we have introduced a direct extension of the hyperbolic cosine to square matrices, i.e.,
`sinh(X) := (e^X - e^(-X))/2`
When `t → ∞`, the optimal portfolio position is
`x_∞ = e^(-Γt_0) (x_0 + Γ⁻¹ cosh(Γt_0) Γ⁻¹ C⁻¹μ_0)`
For `t > t_0`, the portfolio is liquidated in the absence of alpha.

**11.3.5 AR(1) Signal**
Let us consider first the case of autoregressive expected returns:
`(11.17) μ_{t+1} = Φμ_t + η_t`
where
`Φ` is a diagonal matrix with `Φ_ii ∈ C, |Φ_ii| < 1`.
`η_t ~ N(0, Σ_η)` with `Σ_η` diagonal and positive-definite.
`η_t` are jointly independently time-dependent, i.e., `E_s[η_t] = η_s` for all `s`.
`E_t[η_s] = η_s` for all `s ≤ t`.
By repeated substitution we have
`(11.18) μ_{t+k} = Φ^k μ_t + Σ_{i=0}^{k-1} Φ^i η_{t+k-1-i}`
`(11.19) E_t[μ_{t+k}] = Φ^k μ_t`
The long term inverse covariance of `μ_t` are `B_k = (I - Φ^k)` and `Ω_k = (I - Φ^k)⁻¹ Σ_η`.
The continuous-time solution is
`(11.20) Γ = [C⁻¹(ρI - ΦᵀC⁻¹Φ)]¹/²` (from Equation 11.20)
`b_t = ∫_t^∞ e^(-Γ(s-t)) C⁻¹Φ^(s-t)μ_t ds` (from ρ = 0)
`= (Γ + C⁻¹Φ)⁻¹ C⁻¹μ_t`
Define `Γ = USVᵀ` and `Φ = VDVᵀ`. We rewrite `b_t` as
`b_t = U (∫₀^∞ diag(e^(-s_i t), ..., e^(-s_n t)) e^(-AΦ^k) dt) Φ^k μ_t`
`∫₀^∞ diag(e^(-s_i t), ..., e^(-s_n t)) AΦ^k dt = A_0 ∫₀^∞ (e^(-s_i t) Φ_i^k) dt`
`= A_0 [ -1 / (s_i - log(Φ_i)) ]`
`< ∞`
Define a matrix `H` by
`[H]_{i,j} = (s_i - log(Φ_j))⁻¹`
Then
`b_t = U ( (VᵀC⁻¹V) ○ H ) μ_t`
The optimal trading policy at time `t`, given portfolio `x_t` and predicted returns `μ_t`, is
`(11.21) δẋ_t = (-Γx_t + Kμ_t) δt`
(liquidation) (investment)
`(11.22) K := U ( (VᵀC⁻¹V) ○ H )`
Equation (11.21) has an intuitive interpretation. In the absence of expected returns, liquidate the book using a trading rate proportional to position size. With non-zero expected returns, we combine the liquidation with a trade that is a linear function of the expected returns.

---

**11.4 Appendix**

**11.4.1 Proof of the Infinite Horizon Quadratic Problem**

We need a few definitions:
`(x,y) := ∫₀^∞ e^(-ρt) x_tᵀ y_t dt`
`||x||² := (x,x)`
`(Kx)(t) := ∫₀ᵗ x_s ds`
The adjoint operator of `K` is such that
`(K⁺x, y) = (x, Ky)`
In formulas:
`(Kx,y) = ∫₀^∞ e^(-ρt) [∫₀ᵗ x_s ds]ᵀ y_t dt`
`= ∫₀^∞ e^(-ρt) x_sᵀ [∫_s^∞ e^(-ρ(t-s)) y_t dt] ds`
`= ∫₀^∞ e^(-ρs) x_sᵀ [∫_s^∞ e^(-ρ(t-s)) y_t dt] ds`
`(K⁺x)_s = ∫_s^∞ e^(-ρ(t-s)) x_t dt`
We solve Equation (11.7):
`max_{ẋ} ∫₀^∞ e^(-ρt) [ μ_tᵀẋ_t - (1/2)ẋ_tᵀCẋ_t - (1/2)x_tᵀΩx_t ] dt`
Introduce the variable `u` such that `x = Ku`
`max_{u} E_0[μᵀu] - (1/2)uᵀCu - (1/2)(Ku)ᵀΩ(Ku)`
FOC on `u`: `μ - Cu - K⁺ΩKu = 0`
`K⁺μ = CK⁺u + K⁺ΩKu`
`E_s[x_t] = E_s[x_s]`. The tower property of expectation is `E_s[E_t[X]] = E_s[X]` for `s < t`. Let `X_s,t = E_s[X_t]`. From the definition `X_s,t = X_s`.
Apply `E_s` to Equation (11.22) (assuming (11.22) is `μ_t - Cẋ_t - Ωx_t = 0` in continuous time):
`E_s E_t μ_t ds = C d/dt E_s x_t + ρE_s x_t + ∫_s^∞ E_s Ωx_u du` (This line seems to be a derivation step)
`d/dt E_s μ_t = C d²/dt² E_s x_t + ρ d/dt E_s x_t + ΩE_s x_t`
This is a linear ODE in `x_s,t`, which we can solve analytically. First, define
`Γ := (C⁻¹Ω)¹/²`
`b_t := ∫_t^∞ e^(-Γ(s-t)) C⁻¹E_s[μ_s] ds`
The solution that satisfies `lim_{t→∞} x_s,t = 0` is
`(11.23) x_s,t = e^(-Γ(t-s))x_s + ∫_s^t e^(-Γ(t-u)) b_u du`
from which it follows directly
`d/dt x_s,t |_{t=s} = -Γx_s + b_s`
Finally, from `dx_s/dt = ẋ_s` and `ẋ_s = u_s`, the law for the optimal trading policy follows:
`(Left) ẋ_s = -Γx_s + b_s`
`(11.24) x_t = e^(-Γt) (x_0 + ∫₀ᵗ e^(Γs) b_s ds)`
The value of the objective function is:
`∫₀^∞ (μ_tᵀẋ_t - (1/2)ẋ_tᵀCẋ_t - (1/2)x_tᵀΩx_t) dt`
`= ∫₀^∞ (μ_tᵀ(-Γx_t+b_t) - (1/2)(-Γx_t+b_t)ᵀC(-Γx_t+b_t) - (1/2)x_tᵀΩx_t) dt`
`(11.25) = (μ_0ᵀx_0 + b_0ᵀCT⁻¹x_0 - (1/2)x_0ᵀΩx_0 - (1/2)b_0ᵀCb_0)`

---

**The Takeaways**

1.  Trading incurs various costs, including market impact, which can turn profitable strategies unprofitable.
2.  Market impact is the cumulative market response to new order flow, influenced by inventory reduction, informational effects, mimetic effects, and strategic trading.
3.  Total transaction costs comprise spread costs, temporary market impact, and permanent market impact.
4.  Spread costs arise from the bid-ask spread; market orders cross the spread and remove liquidity.
5.  Temporary impact is the short-term price change during post-execution; temporary impact occurs during and immediately after execution.
6.  Temporary market impact is modeled using functions `f` (instantaneous impact) and `G` (propagator), representing price impact dynamics.
7.  Models like Almgren-Chriss, Kyle, Obizhaeva-Wang, and Gatheral use specific forms of `f` and `G` to describe impact.
8.  Finite-horizon optimization plans trades over multiple periods, accounting for market impact, transaction costs, and risk constraints.
9.  Multi-period optimization is flexible but may require complex numerical solutions and has convergence concerns.
10. Infinite-horizon optimization provides analytical optimal trading policies by maximizing a mean-variance objective with transaction costs.
11. The optimal policy balances expected returns, trading costs, depending on initial risk aversion and costs.
12. Special cases like no-market-impact limit and optimal liquidation illustrate the policy under different conditions.

---

**Notes**

1.  The academic literature on optimal execution is vast, and growing rapidly. This chapter offers a selective treatment of portfolio optimization. Reference texts are Gârleanu (2009); Bouchaud et al. (2018); Bacidore (2020); Velo et al. (2020); Moallemi (2021).
2.  There are at least two classes of costs associated with it. First, there are opportunity costs. If the price moves away, we may be forced to reprice the order and pay a higher price than the market order we could have submitted. Second, and counterparty is typically an informed trader who is forcing a market order to reveal their expectation on our side.
3.  A market order is an order to buy or sell a stock at the best available price offered by a counterparty, and that therefore removes inventory.
4.  `δ(.)` is a “pulse” generalized function, zero everywhere except the origin, and whose integral is 1.
5.  The argument on dimensional analysis, see Bussan and Ramaj (2019); Toth et al. (2011); Gatheral (2010); Cont (2011); Mahajan (2012).
6.  Linear equality constraints can be priced in the objective function, but linear inequality constraints can’t.
7.  A looser description of such a process is that the value of `μ_k` is known based on the information available at time `t`. The rigorous definition of non-anticipative (or adapted) process is beyond the scope of this book; see Shreve (2004a) for a more satisfactory such treatment (Vol I).
8.  We make the assumption of diagonal cost matrix because it is intuitive and most relevant to applications. It can be relaxed to model cross-market impact among securities. Many such models use quadratic costs. See, e.g., Mastromatteo et al. (2017); Alfonsi et al. (2022).
   

Okay, here is the Markdown compilation for Chapter 12.

```markdown
Everand

**Chapter 12**
**Hedging**

**The Questions**

1.  What is the purpose of hedging in a portfolio, and what are the different types of hedges available?
2.  How can a simple hedging model with no transaction costs or parameter uncertainty apply to real-world portfolio management?
3.  How does the inclusion of parameter uncertainty affect optimal hedging strategies?
4.  What are the implications of execution costs in multi-period hedging?
5.  How can factor models be used in constructing hedging strategies, especially when managing factor exposures?
6.  What scenarios is it beneficial to hedge with FMPs, liquid assets, or futures, and how do these impact portfolio risk and return?

Hedging is the process of reducing the risk of a pre-existing portfolio by means of augmenting the portfolio with additional investments, whose returns are negatively correlated to the existing portfolio. The most common forms of hedging are market hedging and exposure hedging. In these cases, we use an instrument or a combination of instruments to partially manage the risk. The first is hedging by means of Factor-Mimicking Portfolios (FMPs) obtained from a fundamental factor model. The second one is hedging by means of a future or liquid asset capturing equity and non-equity risk. This includes energy and interest rate futures, bond futures, ETFs and ETNs (exchange-traded (ET) notes, i.e., debt). The first application of interest is, e.g., XLE, an ETF tracking the stocks in the technology sector), or style (e.g., MTUM, an ETF reproducing the behavior of the momentum factor) risk. The last application of interest is the creation of thematic tradeable baskets by banks. One can buy these baskets to hedge or speculate on political risk (e.g., elections) or economic risk (e.g., G7 vs. China) thematic exposure using investible baskets.

This chapter is broadly organized into three sections. The first part covers naive hedging. There are no effects in this section: no transaction costs, no parameter uncertainty, and a single period. Yet, such a simple model is still widely used in many applications. In the second part we explore the impact of parameter error and how it affects optimal hedging. Lastly, we look at multi-period hedging in the presence of execution costs.

---

**12.1 Toy Story**

In its simplest form, we have the following ingredients:
*   We have two decision dates `t₀, t₁`, and one realized return between them. We make investment decisions at `t₀` and observe realized returns at `t₁`.
*   We have two assets, which we denote core and hedge, with returns `r_c, r_h`, expected returns `μ_c, μ_h = 0`, volatilities `σ_c, σ_h > 0` and return correlation between the two equal to `ρ_ch`.

We decide the size of the hedging instrument in order to maximize the Sharpe Ratio of the combined portfolio. We already know how to solve this problem: it is the two-asset Mean-Variance Optimization (MVO) instance we saw in Section 10.1. In that problem, we decided the optimal positions of both assets, not a major difference. The MVO optimization problem
`max_{x_c, x_h} μ_c x_c / √(x_c²σ_c² + x_h²σ_h² + 2ρ_ch σ_c σ_h x_c x_h)`
has solution
`(12.1) x_c* = ρ_ch σ_h / σ_c x_h*`
`(12.2) x_h* = - (ρ_ch σ_c / σ_h) x_c* = -β(r_c, r_h) x_c*`
The ratio `|x_h* / x_c*|` is the optimal hedge ratio and is equal to the beta of the core portfolio’s return to the hedging portfolio’s return.

The unhedged variance is `x_c*²σ_c²`; after hedging it is `(1 - ρ_ch²)x_c*²σ_c²`. The improvement in Sharpe Ratio is equal to the improvement in volatility:
`(12.3) SR(hedged) / SR(native) = 1 / √(1 - ρ_ch²)`

The parameter `β` is estimated either via time-series regression or by using a return covariance matrix, such as one supplied by a factor model. Define `w_c` the core and hedge portfolios, the model beta is
`(12.4) β(r_c, r_h) = w_cᵀΩ_f w_h / (w_hᵀΩ_f w_h)`
From that Equation (12.2) gives the relative size of the hedge, and Equation (12.3) the improvement in Sharpe Ratio from hedging.

In their simplicity, Equations (12.1)-(12.3) are applied widely. A typical application involves the use of a single hedging instrument that is very liquid and inexpensive to trade, and whose expected return is negligible compared to that of the core portfolio. Examples are E-mini S&P500 futures and the SPY, VIX and VOO ETFs, which also track the S&P500 index. We perform intraday or end-of-day hedging in order to remove the associated risk.

**Exercise 12.1 (Comparing a Market FMP and Benchmark as Hedging Instruments).**
1.  For this exercise, you will need two portfolios (maybe for a live strategy), an equity factor model, and the weights of several benchmarks.
    Compare the risk decompositions of the benchmark and of the market FMP. What is their idiosyncratic variance as a percentage of total variance? What are their exposures (this applies to benchmarks only)?
2.  Now, hedge the test portfolios using the FMP and the benchmark. What is the reduction in factor variance in the two cases? What is the increase in non-market, i.e., idiosyncratic, risk? Are these partially hedged out? Are they material?
Perform the analysis over a number of years to verify whether the findings are stable.

**Procedure 12.1: Simple single-asset hedging**
**Inputs:** Core portfolio NAV `x_c`, with returns `r_c`.
Hedge asset with returns `r_h`. Parameter `ρ_ch = ρ(r_c, r_h)` estimated by means of time-series regression, or of an asset covariance matrix and Equation (12.4).
**Output:** Hedge NAV `x_h* = -ρ_ch (σ_c/σ_h) x_c`.

Hedging in this specific instance rests on several implicit and explicit assumptions:
*   We assume that the beta of the core portfolio to the hedging instrument can be estimated accurately.
*   We assume that there is a single hedging instrument.
*   We assume that trading costs are negligible.
*   We assume that the hedging instrument has negligible expected return.
In the remainder of this chapter we re-examine these hypotheses and relax them.

---

**12.2 Factor Hedging**

**12.2.1 The General Case**

We have recurrent use of factor models in this book, and unsurprisingly they make their hedging debut as portfolio performance enhancement tools that take into account the portfolio risk arising from factor exposures and idiosyncratic risk, and generate a portfolio that meets our investment goal. In practice, there are situations in which this is not possible. An important instance is when the core portfolio is the outcome of a portfolio construction process outside of our control. For example, an investment group may have independently developed a portfolio of long-term trading stocks based on their fundamental outlook. The last of these individual portfolios constitutes a core portfolio that is not optimized, and that exhibits undesired systematic risk. In this case, the hedging process takes `w_c` as an input, and seeks to reduce the unwanted risk from factor exposures. We use a factor model with `K` fundamental factors, as in Chapter 7. They are the columns of matrix `F`, and have unit exposure to factor `j`. One way to hedge factor risk would be Procedure 12.2.

**Procedure 12.2: A simple factor hedging procedure**
1.  Compute the core portfolio factor exposure `b_c = Bᵀw_c`.
2.  “Hedge out” the core exposure by finding an amount of factor exposure `-b_c`. We do this by buying a hedge portfolio `-B⁻¹b_c`.

We have achieved zero factor exposure. The solution is simple, elegant, and unfortunately unrealistic. We have ignored two essential aspects of the hedging problem. First, factors have non-zero expected returns. Second, trading factors is expensive. However, we can change the formulation to include these modeling concerns. Let us begin with assuming that the factor-mimicking portfolio of the hedging strategy has zero alpha and zero trading costs. In Section 12.2.2, when the definition of alpha is orthogonal to alpha spanned. In formulas: the expected return of a portfolio is equal to `(α_cᵀ + μ_FᵀB)w`. Regarding the execution costs, we include them in the optimization formulation, using a mean-variance framework, as in Chapter 9. We maximize the expected return of the combined portfolio of a portfolio `w_c` from a starting portfolio `w_0` as `f(w_c)`. The trading cost of a portfolio is `p`. In a single-period setting, we then write the problem as
`(12.5) max_{w_h} α_cᵀ(w_c + w_h) + μ_FᵀBᵀ(w_c + w_h) - (1/2)(w_c + w_h)ᵀΩ(w_c + w_h) + f(w_c, w_h)`
`s.t. Bᵀ(w_c + w_h) = b*`
`α_cᵀ(w_c + w_h) = (expected returns)`
`w_c, w_h ∈ ℝ^n`

I leave it as an exercise to prove that if execution costs are zero, orthogonal and spanned alphas are zero, and factor portfolios have zero idiosyncratic variance, then of course we would hedge out exposure. Not a single one ofthese assumptions holds, and it is worth spending some time commenting on them.
*   Some of the factors do have zero expected returns, some don’t. Hedging them is in fact a trade-off: we accept losses because the gains in risk reduction are (hopefully) worth the losses.
*   The hedging portfolios may also have non-zero alpha orthogonal exposure. This must be taken into account, especially when alpha orthogonal is what determined what the profitability of the strategy depends on, more than our alpha spanned.
*   Even if we traded the pure FMPs of Procedure 7.2, we would add idiosyncratic risk to the core portfolio. This additional idiosyncratic risk reduces the benefits of factor risk reduction. The optimization formulation takes this into account. In fact, the following exercise asks you to derive the details and show that the optimal hedging is not equal to `-b_c`.

**Exercise 12.2:**
Assume that:
1.  factor portfolios have zero expected returns;
2.  we hedge using only factor portfolios;
3.  we have no transaction costs.
Prove that the optimal hedging policy is
`x* = -(BᵀΩ⁻¹B)⁻¹BᵀΩ⁻¹b_c - (BᵀΩ⁻¹B)⁻¹BᵀΩ⁻¹b_h`
Under what condition is the optimal hedging ratio smaller than the perfect factor neutralization of Procedure 12.2?
The solution is in the Appendix. Meanwhile, here is a much easier problem to get you started.

**Exercise 12.3:**
For simplicity, consider the case where asset returns are described by a one-factor model, and there is a hedging portfolio that has exposure to that factor. Starting with Equation (12.4), show that it is optimal not to hedge entirely the exposure of the core portfolio to that factor.

In the simplistic hedging procedures of the first part of this section, we did not have an investment objective, because volatility reduction was a pseudo-investment objective: no execution concerns, no expected factor returns, no idiosyncratic volatility increase. But reality is complicated. The parameter `ρ` quantifies our risk tolerance and determines where we want to be on the curve trading off volatility and expected return. This is a good thing. In practice, we should explore this trade-off and determine the optimal operating point.

In the special case of quadratic costs, Optimization Problem (12.5) can be rewritten as a multi-period optimization problem (see Chapter 11), using the formalism presented in Appendix A and specifically in Procedure 11.1.

**Exercise 12.4:**
Extend Optimization Problem (12.5) to the multiperiod setting. Discuss the implementation complexity and propose some simplifying assumptions.

---

**12.3 Hedging Tradeable Factors with Time Series**

A relatively common use case for hedging is the following. There are non-equity tradeable and liquid instruments that are associated with macroeconomic movements; for example, energy or metal commodity futures, or fixed-income futures. Because of their ability to capture broad macroeconomic themes and their liquidity, we would like to use these instruments for hedging. To fix our ideas further, consider the case of a portfolio of international stocks, and of gold. We decide to hedge the portfolio returns using West Texas Intermediate (WTI) crude oil futures. We assume that the energy portfolio is correlated to energy prices, and at the same time that the portfolio manager or the trading algorithm does not have a view on the future energy price movements. A possible approach is to estimate time-series betas `β_ch = ρ_ch σ_c / σ_h` and then hedge the core portfolio `w_c` using a hedge portfolio `w_h = -β_ch w_c`. This approach won’t work! Surprisingly, or more likely, in real-world instance, the realized risk of the hedged portfolio was worse than the realized risk of the core portfolio. This is somewhat counterintuitive. In this section, we aim to shed some light on hedging for this particular scenario.

As in the previous sections, we denote the return of the tradeable instrument `r_h` with variance `σ_h²`. We model the instrument returns `r_h = β_h r_m + η_h`, in other words, it has factor exposure to a given set of factors `r_m`, and idiosyncratic return `η_h`. We have a random estimation error with covariance matrix `Ω_h` and `β` is the vector of true betas. In order to see what could go wrong, let us hedge with the “optimal” hedge ratio:
`w_h* = - (β - η)ᵀw`
The covariance matrix, augmented with the hedging instrument, is
`Ω̃ = [[Ω_c, Ω_{ch}], [Ω_{hc}, Ω_h]]`
Let us compute the variance of the hedged portfolio:
`var(r_c + r_h*) = E_η[(w_c + w_h*)ᵀΩ̃(w_c + w_h*)]`
`= E_η[w_cᵀΩ_c w_c - 2w_cᵀΩ_{ch}(β-η)w_c + (β-η)ᵀw_cᵀΩ_h w_c(β-η)]`
The variance of the hedged portfolio exceeds the unhedged variance when
`w_cᵀΩ_h w_c > (βᵀw_c)²`
The left-hand side of the inequality is the squared estimation error of the portfolio beta. The right-hand side is the portfolio beta-related variance.

Between the non-hedged and the fully hedged portfolio, maybe there is a hedging level that improves on both. We consider the case where we apply a positive hedging shrinkage factor `γ*` to the optimal hedging `w_h* = -β_ch w_c`. The hedged portfolio is `w_c + γ*w_h* = (1 - γ*β_ch)w_c`, and hence we minimize the expected loss `E_L`. The formula for the variance is similar to the one we performed above:
`E[r_c + r_h*] = E_η[ (w_c + γ*w_h*)ᵀΩ̃(w_c + γ*w_h*) ]`
`= w_cᵀΩ_c w_c - 2γ*w_cᵀΩ_{ch}βw_c + γ*²βᵀw_cᵀΩ_h w_cβ`
which we minimize to find the optimal shrinkage factor and hedge ratio:
`(12.6) γ* = w_cᵀΩ_{ch}β / (βᵀΩ_h β)`
`(12.7) w_h* = -γ* βᵀw = - (w_cᵀΩ_{ch}β / (βᵀΩ_h β)) βᵀw`
Let’s sanity-check this formula.
*   The shrinkage factor `γ*` is independent of the units of the portfolio. If we measure the portfolio in cents or in dollars, we get the same value of `γ*`. Otherwise stated: if we hedge a portfolio 10 times the size of our portfolio, the hedge factor is unchanged, and the dollar hedge is 10 times the hedge of the original portfolio.
*   If there are no estimation errors in the betas, then `Ω_h = 0` and `γ* = 1`; we use the optimal hedge ratio.
*   The numerator is a weighted sum of the estimation errors. The larger the errors, the smaller the shrinkage factor.
*   The ratio `w_cᵀΩ_{ch}β / (βᵀΩ_h β)` can be loosely interpreted as the square of the aggregate noise-to-signal ratio of the betas. The higher the ratio, the smaller the scaling factor.
*   Consider the edge case where the true betas are all zero and errors are independent. Then `Ω_{ch} = 0` and the expected value of the denominator is
    `E[ (w_h*)ᵀΩ_h w_h* ] = w_h*ᵀΩ_h w_h*`
    In expectation, numerator and denominator are equal, and `γ* = 0`. On average, we do not hedge. This is the correct course of action.
In practice, we do the following steps:
1.  Estimate the time-series `β_ch` and its standard error `σ_β`. Define `Ω_h` as the diagonal matrix whose `j`-th term is `σ_β_j²`.
2.  Compute `γ*` using Equation (12.6).
3.  Buy `x_h* = -(γ* β_chᵀw_c)` of the hedge instrument. The lower bound on `γ*` is meant to avoid the situation where we hedge in the opposite direction.
4.  (optional) It is difficult to estimate the correlations between estimation errors, especially in periods of market stress. You can simulate their impact by assuming constant correlations between them and then defining
    `Ω_h = [[σ_β₁², ρσ_β₁σ_β₂, ..., ρσ_β₁σ_β_n], [ρσ_β₁σ_β₂, σ_β₂², ..., ρσ_β₂σ_β_n], ..., [ρσ_β₁σ_β_n, ..., σ_β_n²]]`
    and testing the sensitivity for different values of `ρ`. The hedging ratio decreases linearly as `ρ` increases.
5.  (simplifying Equations (12.6) and (12.7)) Assume that the terms `w_cᵀΩ_{ch}` are cross-sectionally uncorrelated with `w_cᵀβ`. Then,
    `w_cᵀΩ_{ch}w_c* = Σ_j w_{c,j}² σ_{β_j}²`
    `= E_η[ (w_cᵀβ)² ] + E_η[ (w_cᵀ(β̃-β))² ... ]` (This line seems to be a derivation step or an expansion)
    An analogous simplification occurs for the denominator. Then the formula for the optimal hedge ratio becomes
    `(12.8) γ* = E_η[ (w_cᵀβ)² ] / ( E_η[ (w_cᵀβ)² ] + E_η[ (w_cᵀ(β̃-β))² ] )`
    Higher standard errors `σ_β` imply greater shrinkage. Lower dollar exposure to the tradeable factor also means greater shrinkage. Finally, to simplify things dramatically, consider the case where all `β_j` are identical, and the portfolio is long only. The shrinkage factor simplifies to:
    `γ* = (β̃ E[r_c])² / ( (β̃ E[r_c])² + E[ (β̃-β)² E[r_c]² ] ) * H(w)`
    (squared noise-to-signal) (portfolio concentration)
    The ratio `H(w) = ||w||₁² / ||w||₂²`
    is a measure of portfolio concentration that has maximum diversification `H(w) = n` (n positions with identical NAV) and has `H(w) = 1/n`, while a maximally concentrated portfolio has all NAV concentrated in a single stock, so that `H(w) = 1`. The interpretation here is that the shrinkage factor is smaller when the portfolio is more concentrated. The intuition is that the estimation error of the betas averages out more in diversified portfolios.

---

**12.4 Factor-Mimicking Portfolios of Time Series**

A problem related to hedging a portfolio using a tradeable security is that of finding a portfolio that is close to a nontradable security. Such time series abound in practice. A quantitative portfolio manager may be interested in trading them for a few reasons. First, the time series may show high correlation to the securities in her investment universe and therefore the time series could serve as a useful hedging instrument. A common use case is that of the macroeconomic update time series, which has some market impact but is not directly tradable. Developing a tradeable portfolio that “tracks” the time series has no value for her. Lastly, just verifying how well we can track a time series is interesting in itself. It shows us whether the time series is of concrete use. The occasional analysis that finds non-tradeable themes are full of sound and fury, usually signifying sell-side research fees.

We introduced the ingredients of our problem earlier in the chapter. We have `K` assets with returns `r_h`, and a non-tradeable time series `r_c`. We keep the original notation. Since we would not be satisfied with implied factor exposures to this complex form, we have the following ingredients:
*   Two periods and one realized return. Investment decisions are made in period one, profits are realized in period two.
*   `K` assets with returns `r_h`, with covariance matrix `Ω_h`.
*   Nontradable time series `r_c` with returns `r_c`, with covariance matrix `Ω_c`.
*   Returns `r_c` and `r_h` are jointly distributed with covariance matrix `Ω = diag(Ω_c, Ω_h, ..., Ω_h)`.

The problem asks to minimize the tracking error between the time series and a portfolio.
`min_w E[ (r_c - wᵀr_h)² ]`
We condition on `r_h`, as we did earlier in this chapter:
`E[r_c|r_h] = E[r_c] + Ω_{ch}Ω_h⁻¹(r_h - E[r_h])`
`= μ_c + Ω_{ch}Ω_h⁻¹(r_h - μ_h)`
`= μ_c* + β*ᵀr_h`
`w* = (Ω_h + μ_h μ_hᵀ)⁻¹(Ω_{ch} + μ_c μ_hᵀ)`
`= (Ω_h + μ_h μ_hᵀ)⁻¹(Ω_{ch} + μ_c μ_hᵀ)`
The first-order condition on this unconstrained problem gives the optimal portfolio, which we transform by means of the Woodbury-Sherman-Morrison Lemma of the inverse matrix (see Equation A.7).
`w* = [Ω_h⁻¹ - (Ω_h⁻¹μ_h μ_hᵀΩ_h⁻¹) / (1 + μ_hᵀΩ_h⁻¹μ_h) ] (Ω_{ch} + μ_c μ_hᵀ)`
`= [Ω_h⁻¹ - (Ω_h⁻¹μ_h μ_hᵀΩ_h⁻¹) / (1 + μ_hᵀΩ_h⁻¹μ_h) ] Ω_{ch}`
`+ [Ω_h⁻¹ - (Ω_h⁻¹μ_h μ_hᵀΩ_h⁻¹) / (1 + μ_hᵀΩ_h⁻¹μ_h) ] μ_c μ_hᵀ`
Having done most of the heavy lifting, we close with a few remarks:
*   The beta estimation error `β*` serves as a regularizer for the covariance matrix. The larger the expected returns, the higher the importance of the regularization term.
*   When `μ_h = 0` (no estimation error), and `μ_c = 0` (zero return), the optimal portfolio is `w* = Ω_h⁻¹Ω_{ch}`, which is a scaling factor.
*   In a mean-variance portfolio, a minor point: it seems that the scaling factor is `σ_h²`, which would make no sense. The covariance matrix does contain `σ_h²`, though, so that dependency is effectively linear.
*   When `μ_h ≠ 0`, the optimal portfolio approaches, up to a constant, `Ω_h⁻¹μ_h`.
Once we have the optimal portfolio `w*`, hedging is straightforward, in the sense that we can employ Equation (12.6) to reduce the core portfolio’s risk.

**Exercise 12.5:**
Describe how you would hedge to a time-series factor (or an FMP of a time-series) on top of equity FMPs for a pre-existing model. (Hint: Orthogonalization.)

---

**12.5 Appendix**

**Proof**
[Proof of Exercise 12.2] We replace the decision variable `w_h = Px`. From the definition of `P`, it follows that `BᵀPx = x`, and
`xᵀPᵀΩ_h Px = xᵀ(BᵀΩ_h⁻¹B)⁻¹x`
It follows that the Optimization Problem (12.5) can be rewritten
`max_{x} α_cᵀ(w_c + Px) + μ_Fᵀ(Bᵀw_c + x) - (1/2)(w_c + Px)ᵀΩ(w_c + Px) + f(w_c, Px)`
`s.t. Bᵀ(w_c + Px) = x`
`σ_h² = σ_c² - xᵀ(BᵀΩ_h⁻¹B)⁻¹x + b_cᵀ(BᵀΩ_h⁻¹B)⁻¹x - xᵀ(BᵀΩ_h⁻¹B)⁻¹b_c + xᵀ(BᵀΩ_h⁻¹B)⁻¹x`
`w_c, x ∈ ℝ^n`
Assume that `μ_F = 0` and transaction costs equal 0. The objective function becomes
`α_cᵀw_c - (1/2)w_cᵀΩw_c + α_cᵀPx - (1/2)xᵀPᵀΩPx - w_cᵀΩPx`
`= α_cᵀw_c - (1/2)w_cᵀΩw_c + α_cᵀPx - (1/2)xᵀ(BᵀΩ_h⁻¹B)⁻¹x - b_cᵀ(BᵀΩ_h⁻¹B)⁻¹x`
which is minimized at
`x* = -(BᵀΩ_h⁻¹B)⁻¹BᵀΩ_h⁻¹b_c - (BᵀΩ_h⁻¹B)⁻¹BᵀΩ_h⁻¹α_c`
`= -[I + (BᵀΩ_h⁻¹B)⁻¹BᵀΩ_h⁻¹]b_c`

**The Takeaways**

1.  Hedging reduces portfolio risk by adding negatively correlated investments.
2.  Common hedging methods include market and currency hedging.
3.  Additional hedging techniques involve:
    *   Using FMPs from fundamental factor models.
    *   Hedging with futures or liquid assets capturing equity and non-equity risk (e.g., energy futures, sector ETFs).
    *   Employing thematic tradeable baskets offered by banks to hedge or speculate on specific risks.
4.  In a simple hedging scenario we have two assets: core (with expected return `μ_c`) and hedge (with expected return `μ_h = 0`) and want to maximize the Sharpe Ratio of the combined portfolio. The optimal hedge position is `x_h* = -β(r_c, r_h)x_c*`, with `β = ρ_ch σ_c / σ_h`.
5.  In practice, we remove the assumptions in simple hedging: accurate beta estimates, single trading instrument, negligible trading costs, hedging instrument with negligible expected return.
6.  In both cases, we will hedge less than the optimal hedge ratio of the simple hedging case.

**Notes**

1.  We are assuming, again, that the returns of the factors we want to hedge are zero, or negligible.
2.  Sometimes these are referred to as unspanned factors, because we receive no reward for holding their associated risk.
3.  Informally, if the number of assets is large, we should expect the variance of `w_cᵀη` to be small, so that the expected value is a good proxy for `w_cᵀη`.
4.  For a vector `x`, define `E_η[x]` as the average of the values `x_1, ..., x_N`.
5.  The Herfindahl index is usually defined for a set of `N` non-negative numbers `x_i` that sum to one: `H = Σ_{i=1}^N (x_i / Σ_{j=1}^N x_j)²`. It can be extended to arbitrary sets of numbers `x_i` by defining `H = (Σ_{i=1}^N |x_i|)² / (N Σ_{i=1}^N x_i²)` and applying the original definition.
6.  In Section 7.2.2, I defined `β* = (BᵀΩ_D⁻¹B)⁻¹BᵀΩ_D⁻¹r_m`. I have not been lucky enough to meet its members in the wild.

```

Okay, here is the Markdown compilation for Chapter 13.
     Everand

**Chapter 13**
**Dynamic Risk Allocation**

**The Questions**

1.  What are the limitations of single-period portfolio optimization for long-term investment strategies?
2.  How does the Kelly criterion provide both theoretical insights and practical guidance for capital allocation and investment decisions?
3.  In what ways do different capital allocation strategies impact cumulative returns and risk profiles?
4.  How do parameter uncertainty and fractional Kelly allocation strategies improve risk management for investors?
5.  What are the mathematical properties of Kelly strategies that make them desirable for long-term growth?
6.  How are stop-loss policies related to the Kelly criterion?

So far we have focused exclusively on single-period portfolio optimization. This may be appropriate for one-off investment decisions, but is inadequate for long-term investment strategies. This is a trite academic statement because an uninterrupted consequence of decisions is a trite modeling statement: that we make decisions in sequence. Investment in the long run, both at the level of the individual consumer and at the aggregate level. Much of the literature has been ignored by asset managers, for a few possible reasons we comment on below. First, these models require the specification of a utility function and of a discount factor (a discount factor for future utility), something that no investment manager would or could specify. If Quadrifoglio utility had been the main justification of MVO, it would probably have never been adopted. Second, these models don’t capture the institutional reality of asset managers. Consumption of asset managers responds to inflows, not just their own preferences. Asset managers’ utility, if any, is driven by inflows. Moreover, outflows do not bear a direct relationship to the principals’ utilities (i.e., those who provide the investment capital to the manager). The reason for this is that inflows and outflows occur at low rates (they are “sticky”), due to inertia of the principals who avoid changing their asset allocations and to search costs. Third, even with the asset managers (who require long allocations relative to capital withdrawal).

Even if hedge fund managers do not read the academic literature while driving their Ferraris (don’t read and drive), they still have to make decisions about the risk they want to take the next day, week, and month. There is one line of research, initiated by electrical engineers and mostly developed by researchers not employed by economics departments, which is relevant to investors. It is broadly known as the Kelly criterion, Kelly Formula, Kelly Gambling, Growth Portfolios, Optimal Growth Portfolios, or Optimal Growth Investing. It has both descriptive power, in that it is followed by many successful investors, and prescriptive value, in that it is based on first principles and has attractive properties. The rest of this chapter is devoted to presenting the basics of the theory. We start with a simple example and motivation for the Kelly criterion. Then we move to the properties of Kelly, its relation to portfolio optimization and Sharpe Ratio. The way that vodka is not suitable as a dinner drink, “Pure” Kelly is not suitable for investing. Fractional Kelly is to Kelly what Chardonnay is to vodka: more sustainable, better tasting and ultimately more fun. Finally, we introduce a time-varying version of fractional Kelly, which helps manage the occurrence of drawdowns.

---

**13.1 The Kelly Criterion**

To introduce the ideas behind the Kelly criterion, we consider first a very simple example. We have one risky asset in which to invest, which returns `r` with probability `p` or `-r` with probability `1-p`. The single-period expected return of the asset is `μ = (2p-1)r`, and its volatility is `σ = 2r√(p(1-p))`. You have to decide how to invest your initial capital in this asset. Consider two alternatives:

1.  (Constant Capital Allocation) Every day you allocate the same amount of capital to the risky asset. This approach is consistent with solving an MVO problem in each period. The problem faced in every period is
    `(13.1) max_w ( (1-p) log(1-wr) + p log(1+wr) ) ⇒ w* = (2p-1)/r = μ/r²`
    where `w` is the net amount allocated to the risky asset and is independent of the period.

2.  (Static Allocation) On day 0, you allocate a fraction `x` of your capital to the risky asset, and then you let it run. This is consistent with solving an MVO problem once, and letting it run.

3.  (Dynamic Allocation) Every day you allocate a fraction `x` of your capital on that day to the risky asset. We have no motivation for this (yet). The intuition, however, is that it seems reasonable to have a volatility proportional to the available capital in each period. The ratio of the strategy’s return to the available capital is `x r_t`. This is consistent with solving an MVO problem in each period, but with constant `x`.

Figure 13.1 shows the cumulative returns under the three approaches. The constant capital allocation shows low growth. Independently, `x = 1/2`, the static allocation has poor terminal wealth even though the risky asset has positive expected return. Lastly, `x = 1/2`, the dynamic allocation exhibits a variety of behaviors. The slope of the curve (not seen) is not monotonically increasing with `x`. A risk-adjusted performance is good for low values of `x`, but the average returns are low. The most profitable strategy corresponds to `x = 1/2`. Higher values detract from performance.

(Right Sidebar Text from Page 551)
**Figure 13.1:** Cumulative returns under the dynamic and static policies. All the curves are based on the same realization of returns of the risky asset. The returns are plotted on a logarithmic scale.

What is remarkable is that, for each strategy, and for each period, the Sharpe Ratio is identical and equal to `1/2`, because in each period the portfolio, being the combination of a risk-free asset and a risky asset, is mean-variance efficient. This simple example reveals well the subtleties of the Sharpe Ratio as a performance measure. It is an instantaneous measure of performance, and thus abstracting away any complication due to performance measurement, and we obtained the same value for all the strategies in our example. Yet, the behavior of the cumulative returns differs wildly among the strategies. We can interpret this finding in two ways. First, the commonly defined ex-post Sharpe Ratio (realized return divided by realized standard deviation in a single period), is a measure of single period, risk-adjusted performance. Averaging the Sharpe Ratio over the life of a strategy can give us a better estimate of `μ`, but it is not telling us much about the risk-adjusted performance of the strategy over its lifetime. If we instead use the cumulative returns over the strategy lifetime as a measure of performance, and ignore risk considerations—then the dynamic strategy with `x = 1/2` would be the clear favorite.

A second observation is that skill alone, defined as the ability to select a high-Sharpe portfolio in any given period, is necessary but not sufficient to be a successful investor. The size of the overall portfolio over time plays a major role in the long term. Yet, this topic does not receive much attention among academics or practitioners.

To understand where the value `x* = 1/2` comes from, let `r_t(x)` be the random return of the dynamic allocation strategy in period `t`. It is
`(13.2) 1 + r_t(x) = { 1+x, p=1/2; 1-x, p=1/2 }`
The total return of the strategy is `Π_{t=1}^T (1 + r_t(x))`. The average growth rate of the strategy `g_T(x)` is such that
`(13.3) Π_{t=1}^T (1 + r_t(x)) = exp(T g_T(x))`
where `g_T(x) := (1/T) Σ_{t=1}^T log(1 + r_t(x))`
For a fixed number of periods `T`, if we wanted to maximize the expected growth rate of the strategy, we would solve the problem `max_x g_T(x)`. As `T → ∞`, because returns are iid `r_t`, by the Law of Large Numbers,
`g_T(x) → E[log(1 + r_t(x))]`
a.s. The solution to the problem
`(13.4) max_x E[log(1 + r_t(x))]`
is asymptotically equivalent to maximizing the expectation (13.3). The objective function is maximized when the investment fraction `x` is equal to `1/2` (see Figure 13.3 and (13.8)).

**Figure 13.3:** Expected value of the log of the single-period growth, which is maximized at `x* = 1/2`.

(Right Sidebar Text from Page 555)
**Figure 13.2:** (a) Time series of cumulative returns for different fractions of the capital invested in the U.S. market benchmark (cap-weighted average of NYSE, AMEX, NASDAQ) from CRSP database. Monthly excess returns of the benchmark for the period February 1926–March 2018 are from Ken French’s Data Library site. (b) Cumulative returns as a function of the fraction invested in the U.S. market benchmark. The optimal Kelly fraction under the two approximations (Equations (13.9) and (13.10)) is `x* = 1.66` and `x* = 2.2`.

From Figure 13.2, it appears that this strategy performs decidedly better than other strategies with lower investment fractions. By simulation (or from Figure 13.1) one can see that any strategy in which `x > 1` performs worse: this corresponds to borrowing money to invest in the risky asset. Summing up, it appears that the Kelly criterion has maximized the long-term compounded growth rate of wealth by maximizing the expected growth rate, which is mathematically equivalent to maximizing an expected utility with a logarithmic utility function.

Let’s work out in detail an important example.

**Example 13.1 (The Kelly Allocation to a Single Security)**
We have only two assets: a risk-free asset and a risky asset. Let the excess return of the risky asset be `r` with mean `μ` and variance `σ²`. One way to interpret this asset in real-world application is as a portfolio manager to which we want to allocate capital. If we want to maximize the expected growth of the portfolio, then we would solve the problem
`(13.4) max_x g(x) := max_x E[log(1 + rx)]`
In addition to an exact numerical solution, we also produce an approximate solution based on the quadratic approximation of the logarithm:
`(13.5) log(1+x) ≈ x - x²/2 + O(x³)`
`(13.6) max_x E[log(1+rx)] ≈ max_x (μx - (1/2)(σ² + μ²)x²)`
and another approximation, in which we assume `μ² ≪ σ²`:
`(13.7) max_x E[log(1+rx)] ≈ max_x μx - (1/2)σ²x²`
from which
`(13.8) (exact result): x* = argmax E[log(1+rx)]`
`g(x*) = E[log(1+rx*)]`
`(13.9) (quadratic approximation): x* ≈ μ / (σ² + μ²)`
`g(x*) ≈ (1/2) μ² / (σ² + μ²) + 1`
`(assuming that) μ² ≪ σ²: x* ≈ μ/σ²`
`g(x*) ≈ (1/2) SR² + 1`
This approximate result is reliable when the typical fluctuations of `xr` are smaller than 1. A heuristic is to require that the volatility of `x*r` be smaller than 1: `|x*σ| < 1`, or `|SR| < 1`.

Let us consider in some more detail the accuracy of the approximations `x*₁, x*₂`. We consider daily Gaussian returns. The approximation `x*₁` is accurate relative error
`|x*₁ - x*|/x* ≤ 2%`
for daily Sharpe Ratios up to `0.1`, i.e., annualized Sharpe Ratio of `sqrt(252) * 0.1 ≈ 1.6`. The approximation `x*₂` is accurate (relative error
`|x*₂ - x*|/x* ≤ 2%`)
for daily Sharpe Ratios up to `0.02`, i.e., annualized Sharpe Ratio up to `0.3`. The crucial assumption in these calculations is the rebalancing interval. If we rebalance at shorter horizons, the volatility of returns is then smaller, and the quadratic approximation is more accurate. If we rebalanced at shorter horizons, then daily, the approximation would hold for higher values of the annualized Sharpe Ratio.

(Right Sidebar Text from Page 558)
Another way to read this result is that the optimal ratio between dollar volatility and capital is equal to the Sharpe Ratio. Hence the (dollar volatility)/(capital) ratio is
`(13.10) (dollar volatility) / (capital) = (W₀x*)σ / W₀ = SR`
Note that the formulas above hold for volatilities and Sharpe Ratios measured at the rebalancing horizon. For example, if we deploy `x*` of capital to a strategy with annualized Sharpe Ratio of `s`, then we must deploy approximately `x*s` of dollar volatility to run a Kelly-optimal strategy.

Another observation: according to Equation (13.9), the Kelly-optimal expected return is
`(13.11) (expected strategy return) = x*μ = SR²`
`(13.12) (dollar volatility) / (capital) = SR²`

**Example 13.2 (The Kelly Allocation to the U.S. Market)**
We can specialize the analysis above to the important case in which the risky asset is the U.S. market benchmark. This asset is available to retail investors in the form of low-management fees mutual funds (ETFs), both of which track the U.S. market accurately. For the U.S. markets are also available to institutional investors. The S&P500 index is a reasonable proxy for the S&P500 returns. The S&P500 index is a function of the underlying S&P500 returns. It has a Sharpe Ratio of `0.45` and an annualized volatility of `15%`. Based on the observed realization of the historical daily returns, the optimal return is `x*₁ = 1.66` (Equation (13.9)) and `x*₂ = 2.2` (Equation (13.10)). A fraction of `x* = 2.2` means that we borrow money to invest in the market. If we assume that we can borrow at the risk-free rate, then it would be optimal to leverage our capital. In practice, there are borrowing constraints and the fee behavior of a Kelly strategy also drawbacks: the historical PnL from a large `x` shows large drawdowns, which makes the overall fraction `x` have a very dramatic impact on capital appreciation.

The S&P500 example shows the attractive features, but also the drawbacks of Kelly strategies.

**Example 13.3 (Sizing a Bet)**
Consider a bet with a binary outcome: if we invest `$x`, we receive a payout equal to `r_w > 0` with probability `p` and `-r_l < 0` with probability `q = 1-p`. The optimization problem is
`max_x p log(1+xr_w) + q log(1-xr_l)`
`p r_w / (1+x*r_w) - q r_l / (1-x*r_l) = 0` (first-order condition)
`⇒ x* = p/r_l - q/r_w`
Introduce the win-loss ratio `ρ = q/p`, and the winning skew `s_w = r_w/r_l`:
`x* = (1/r_l) (1 - ρ/s_w)` (win-loss ratio) (winning skew)
The higher the win-loss ratio and the winning skew, the higher the size of the bet. If both win-loss ratio and winning skew are smaller than one, the optimal size can be negative.
We close this section with a more advanced example.

**Example 13.4 (Optimal Strategy for a Geometric Brownian Motion)**
Consider a simple risk-adjusted excess return `r` in a single period and rebalance the same period, which is then driven by `dW_t = x(t)μ dt + x(t)σ dW_t`. The strategy has initial value `W_0` and reliable equality `x = E[r] / (σ² + E[r]²)`. We start with capital `W_0`. Over the interval `[0,T]`, `x(t) = x_0`, the continuous-time process governing the capital accumulation at time `t` is given by
`dW_t = x(t)μ W_t dt + x(t)σ W_t dB_t`
Here, `B_t` is standard Brownian process. It can be shown that the distribution at time `t` is given by
`W_T = W_0 exp [ ∫₀^T (x(t)μ - (1/2)x(t)²σ²) dt + ∫₀^T x(t)σ dB_t ]`
Hence
`g_T(x) = (1/T) ∫₀^T (x(t)μ - (1/2)x(t)²σ²) dt + (1/T) ∫₀^T x(t)σ dB_t`
For `T → ∞`, the second integral converges to zero a.s. (for intuition, `B_t` scales like `√T`). The first integral is maximized when the integrand is maximized for all `t`, which occurs when
`x(t) = μ/σ² = SR / σ`

(Right Sidebar Text from Page 561)
We have recovered Equation (13.13).
In our presentation, we have ignored two important features:
*   The Sharpe Ratio is a decreasing function of the capital `x` allocated to the active strategy. Modeling this dependency explicitly is challenging, and to my knowledge there is no analysis where `μ` is a function of `x`.
*   The formula `x* = SR/σ` (or does not hold any longer. At the very least, we should acknowledge this dependency in the ideal formula, and allow for the allocation to depend on the available capital `W_t`).
*   There are transaction costs even in the case of a static `x*`. Whenever the active strategy has a positive PnL, in order to maintain a fraction `x*` in the active strategy, we need to partially trade out of the policy and allocate to the risk-free asset. The dollar amount we need to trade in order to rebalance the fraction `x*` is
    `W_T*(1+r_1) - x* = W_T r_1`
    `W_T*(1-r_2) + x* = W_T r_2`
    Trading costs are super-linear in `Δx`, and therefore super-linear in `W_T`, and become dominant as wealth grows. HIC SVNT LEONES.

The next section is devoted to describing the attractive mathematical properties of Kelly strategies.

---

**13.2 Mathematical Properties**

We now generalize the case in which we can choose to invest across a portfolio of `n` strategies `dp_i`, and the associated returns `r_i(θ)` are independent of `x_i` for all `i = 1, ..., d`. These results were proved first by Breiman (1961) and Dubins and Savage (1965) for iid returns, and the results that follow apply to this case. Some of them have also been established for dependent random variables; see Algoet and Cover (1988).

1.  Let `X_t` be the cumulative returns of the Kelly strategy, and `Y_t` of an alternative strategy with lower expected growth rate.
    The first property is that the Kelly strategy grows faster than any other strategy. Let `X_t, Y_t` be the cumulative returns of the Kelly strategy and alternative strategy respectively. Then, with probability 1,
    `(13.13) Y_t/X_t → 0` as `t → ∞`
2.  The second property concerns the long-term growth of a strategy based on expected value of its log returns. Let
    `g = E[log(1+r_t)]`
    and `X_t` the associated cumulative return process. Then, with probability 1,
    `g > 0 ⇒ X_t → ∞`
    `g < 0 ⇒ X_t → 0`
    `g = 0 ⇒ lim sup_t X_t = ∞, lim inf_t X_t = -∞`
3.  The expected time to reach capital level `C*` is equal to `log C* / g` in the limit `C* → ∞`, and the drawdown time is Kelly strategy.

**Insight 13.1: The Intuition behind Kelly Strategies**
The Kelly criterion has several intuitive and attractive features:
*   Goal: The allocation strategy achieves the highest long-term capital growth.
*   Strategy: The optimal strategy is simple, since it allocates a constant fraction of total capital to the risky strategy.
*   Lower and Upper Bounds on Risky Allocation: The fraction of capital allocated to a risky strategy increases with high `μ` and `σ` (up to `g > 0`) and is around `μ/σ²`.
*   Sharpe Proportional: To a first approximation, the optimal fraction of invested capital and the volatility/capital ratio are proportional to the Sharpe Ratio of the strategy.

(Right Sidebar Text from Page 564)
What these results say is that a Kelly strategy has many very desirable features. In the long run, it beats almost surely any other strategy that has a different expected growth rate. It reaches a certain capital level faster than any other strategy, and the approximate time needed to reach this return can be expressed as a function of `g`. Finally, a positive expected growth rate is necessary and sufficient condition for any strategy to have a growing cumulative return over time.

What the results don’t say is that a Kelly strategy is maximizing the Sharpe Ratio, even if we were able to compute it exactly from knowledge of the true expected returns and volatility of the strategy. There is no guarantee that any Kelly strategy will outperform a drawdown, which can be severe, as seen in the simulations above. In Example 13.2, as the fraction `x` invested increases from 0 to the growth-maximizing level `g**`, both the growth rate and the size of the drawdowns increase with `x`. The scale of the y-axis is logarithmic. The existence of this trade-off is therefore properly captured by the simulations. As we move from the optimal level, the average returns (as expected) and the drawdowns increase further. For fractions of the invested wealth lower than `g**`, there is a trade-off between expected log returns and volatility of the log returns: we get lower returns, in exchange for lower risk. We explore this trade-off next.

---

**13.3 The Fractional Kelly Strategy**

The fractional Kelly strategy consists of investing `x*` in a strategy with iid return `P_t`, a fraction `x_{frac}` of the available capital (smaller than `x*`) such that it will satisfy that
`E[log(1+r_t x_{frac})] > 1`
It can be interpreted in several ways:
*   Combination of risk-free asset and full Kelly. Fractional Kelly is a combination of two investments: a risk-free asset and the full Kelly strategy.
*   The most common interpretation is a utility-based one. In a series of analyses pursued by MacLean et al. (1992) they show (MacLean et al., 2010, 2012) that the fractional Kelly strategy does indeed trade off growth for security. Assume, for example, that in each period we are considering a percentage return `r` greater than the risk-free rate `r_f`. We would be willing to accept a maximum drawdown per period that we can accept. From Equation (13.10), `x* = SR/σ`. We choose the minimum of the
    `x* = min(p/σ, SR)`

**Example 13.5:**
We deploy $/X of capital, and have a Sharpe Ratio of `s`. The strategy has an average annual return of `5%`. We can lose at most `p%` of capital in a year. We find that
`3 × (weekly dollar volatility) = 0.01 × (capital)`
i.e.,
`(weekly dollar volatility) / (capital) = 0.01/3`
`p = (weekly dollar volatility) / (capital) = 0.01/3`
So that `p/σ = 0.11`. This is smaller than the weekly Sharpe Ratio `2/√52 ≈ 0.27`, which corresponds to the optimal Kelly position.
Higher risk aversion. We start from Equation (13.4), which approximates the log-objective function with a near-quadratic one. The quadratic penalty:
`max_x μx - λ/2 (σ² + μ²)x², θ > 1`
The optimization point is
`x_{frac}^* = μ / (λ(σ² + μ²))`
Fractional Kelly is thus a modified Kelly strategy for investors who are more risk-averse than logarithmic utility would suggest.

Parameter uncertainty. Thorp (2006) makes the case that uncertainty about the properties of returns should result in fractional Kelly. Indeed, being wrong can have terrible consequences. Imagine, for example, that we have a strategy with a volatility of `15%`, and an estimate of Sharpe Ratio equal to `0.45`. The Kelly fraction is `x* = 2`. We over-leverage the portfolio by a factor of 2. We can perform a Monte Carlo simulation based on the returns of the market.
We have introduced parameter uncertainty already in Section 10.3.2, in the context of MVO. Here we model parameter uncertainty as follows. Percentage returns are `r_t = r(ω_t, θ_t)`, where `P_t` is a function of a random variable `ω_t` (the sample path of returns) and of a random variable `θ_t` (the quality of the estimate). We have a sample of `N` pairs of `(ω_t, θ_t)` drawn from a probability measure `P_N`. And `θ_t` is `θ` in random parameter setting values in a set `Θ` with probability measure `P_Θ`. The interpretation is that in every period we have a noisy estimate of the true parameter `θ* = E_Θ[θ_t]`. We make the crucial assumption that `ω_t` and `θ_t` are independent. Also, `ω_t` and `θ_t` are independent. Also `ω_t` and `θ_t` are independent. Also `ω_t` and `θ_t` are independent.
The expectation is taken with respect to the random variables `ω ~ P_ω` and `θ ~ P_Θ`. We want to maximize `g(x)`. The first-order condition is `g'(x) = 0`.
`g(x) = (1/T) Σ_{t=1}^T log(1+xr(ω_t, θ_t))`
`g(x) = lim_{T→∞} g_T(x)`
`= E_{ω,θ} [log(1+xr(ω,θ))]` a.s.
`g'(x) = E_{ω,θ} [ r(ω,θ) / (1+xr(ω,θ)) ]`
`g'(x_{concert}^*) = 0`
As a function of `x`, the function `h(τ(θ)) = E_ω[log(1+xτ(ω,θ))]` is increasing and strictly concave. Then it follows that, as a function of `θ`, `h(τ(θ))` is concave, because
`∂²h(τ(θ))/∂θ² = h''(τ(θ))τ'(θ)² + h'(τ(θ))τ''(θ) ≤ 0`
By Jensen’s inequality,
`E_θ [ r(ω,θ) / (1+xτ(ω,θ)) ] ≤ E_θ[r(ω,θ)] / (1+xE_θ[τ(ω,θ)])`
And therefore, taking expectations over `ω`,
`g'(x) = E_ω E_θ [ r(ω,θ) / (1+xτ(ω,θ)) ] ≤ E_ω [ E_θ[r(ω,θ)] / (1+xE_θ[τ(ω,θ)]) ] = g_0(x)`
The function `g_0(x)` on the left-hand side is the derivative of the expected log return in the absence of parameter uncertainty. The function `g(x)` on the right-hand side is the derivative of the expected log return when the parameter is known. It follows that `x_{concert}^* ≤ x_{known}^*`. Figure 13.4 visually illustrates the location of the two solutions.

**Figure 13.4:** The optimal Kelly size in the presence of parameter uncertainty is always smaller than the optimal size when parameters are known.

Let us consider two examples that have some general application: uncertainty about a strategy’s expected return and about its variance.

**Example 13.6 (Strategy with Uncertain Expected Return)**
Let `r = θ + ε`, where `E_ω[ε] = 0`, `var_ω[ε] = σ²`, `E_θ[θ] = μ_0` and `var_θ[θ] = σ_θ²`.
`E[log(1+rx)] ≈ μ_0 x - (1/2) (σ² + μ_0² + σ_θ²) x²`
so that the Kelly fraction is
`x_{frac}^* ≈ μ_0 / (σ² + μ_0² + σ_θ²)`
Let us use the S&P500 market estimates from previous examples: `σ = 0.15`, `μ_0 = 0.08`, and `σ_θ = 0.04`. We get `x*_{frac} = 1.81`, compared to an estimate of `1.66` in absence of estimation error.

**Example 13.7 (Strategy with Uncertain Volatility)**
Let `r = μ + ε`, where `E_ω[ε] = 0`, `var_ω[ε] = θ` and `E_θ[θ] = σ_0²` and `var_θ[θ] = σ_θ⁴`. We assume that `E_θ[√θ]` and `θ` are independent. Also in this case `E_θ[√θ]² / σ_0² = 0`.
`E[log(1+rx)] ≈ μx - (1/2) (E_θ[θ] + μ²) x²`
`= μx - (1/2) (σ_0² + σ_θ² + μ²) x²`
so that the Kelly fraction is again
`x_{frac}^* ≈ μ / (σ_0² + σ_θ² + μ²)`
Let us use the S&P500 market estimates from previous examples: `σ_0 = 0.15`, `μ = 0.08`, and `σ_θ = 0.1` for the market return. We get `x*_{frac} = 1.04`, compared to an estimate of `1.66` in the absence of estimation error.

**Insight 13.2: All reasonable investors use fractional Kelly without knowing**
All reasonable investors allocate capital to a risky strategy so that the volatility/capital ratio is constant, or slowly varying. This is because the Kelly criterion is the only one that, in the long run, allows them to allocate as much capital as possible, compatibly with the drawdowns that their investors can bear. In a series of papers (Part VI of MacLean et al. (2010)) Ziemba (jointly collects the contributions on this subject).
Ziemba and coauthors provide anecdotal evidence that successful investors follow Kelly allocations. The likely reason is not that they are aware of the Kelly criterion, but rather that they use the simple common-sense (inspired) heuristic, which turns out to be equal to fractional Kelly.

---

**13.4 Fractional Kelly and Drawdown Control**

In an influential paper, Grossman and Zhou (1993) address a question related to the issue of finding an optimal trading strategy and of controlled growth/optimal consumption. In the Grossman–Zhou framework (and henceforth), the investor wants to maximize the long-term growth and with probability one avoids reaching a drawdown threshold. As formulated in their original paper, the model only considers a risk-free asset and a risky one. However, it generates different results than pure Kelly. We define the high watermark of the wealth process `W_t` in order to formulate the policy, we define the high watermark of the wealth process `W_t`:
`M_k = max_{0≤s≤k} W_s`
Let `d_k` be the current drawdown percentage from the high watermark: `d_k = 1 - W_k/M_k`. Let the maximum allowed percentage drawdown be `D`. The optimal policy gives the optimal fraction invested in the risky asset and is given by
`(13.15) f_k = (μ/σ²) ( (1-D) / (1-d_k) )`
This policy is elegant and intuitive. For some intuition, fix first `D = 1`, i.e., we can tolerate any drawdown. Then the strategy is to use the unconstrained Kelly allocation `f_k = μ/σ²`. If `d_k = 0`, i.e., then the optimal policy is to invest a fraction `f* (1-D)` where `f*` is the high watermark `M_k = W_k`. This means that we are more prudent than in the simple Kelly scenario, and we are more prudent if our threshold `D` is conservative, a “dynamic fractional Kelly” with maximum drawdown. Moreover, we decrease the investment fraction as we approach the drawdown threshold, and we liquidate the risky asset. Figure 13.5 shows the optimal fraction as a function of the threshold. The reduction rate is nearly constant over the range of allowed drawdowns.

(Right Sidebar Text from Page 576)
**Figure 13.5:** Percentage reduction factor `(1-D)/(1-d_k)`.

**Insight 13.3: Modulating volatility reduces the Sharpe Ratio**
The GZ criterion changes expected returns, and hence reduces the Sharpe Ratio. Over time, changing the volatility of a strategy when the volatility is independent of the expected return of the strategy is Sharpe reducing. To gain intuition about this fact, consider the simple example of a strategy with Sharpe Ratio equal to `s`. Half of the year we deploy it at volatility `σ₁/2`, and half of the year at volatility `(3/2)σ₁`. The expected PnL for the entire year is
`((1/2)sσ₁ + (3/2)sσ₁) / 2 = sσ₁`
The annualized volatility is
`√((σ₁/2)² + (3/2)²σ₁²) / 2 = √(11/8)σ₁`
The Sharpe Ratio is `√(8/11)s`. Compare to the case in which we had kept the volatility constant at the value `√(11/8)s`. The Sharpe Ratio would have been `s`. This example shows that drawdown control doesn’t come for free.

The strategy is a continuous version of the stop-loss policies employed by many hedge funds and successful investors. In the presence of a large drawdown, a portfolio manager operating autonomously within the fund is required to partially or completely liquidate her portfolio. The strategy has many interpretations. One interpretation of a stop-loss policy is a real insurance policy on the strategy itself. View the policy as a synthetic put option, whose price is `W_0`. Imagine that we hold an out-of-the-money put.

To understand the trade-offs between optimizing for variance control and optimizing for drawdown control, it is useful to compare the GZ and fractional Kelly strategies in a numerical example. Specifically, we consider the case of a risky asset with independent, identically distributed returns. Its expected daily return is `0.08%` and its daily volatility is `1%`, corresponding to a Sharpe Ratio of `1.23`. The two strategies are parameterized by the Kelly fraction and the drawdown threshold, respectively `f_k, D`.
`(13.16) f_k(D) = (μ/σ²) P` (fractional Kelly)
`(13.17) f_k(D) = (μ/σ²) ( (1-D) / (1-d_k) )` (Grossman-Zhou)
with `p ∈ (0,1), d_k ∈ (0,1)`
I then simulate the performance of the two strategies over a one-year period (i.e., 25,200 days) and compare the realized volatility and the maximum drawdown for strategies having the same expected log-return. Figure 13.6 shows the results. As expected, the fractional Kelly strategy has a better profile than GZ in the mean-variance sense, and is superior up to the maximum allowed drawdown (10%). A numerical optimization for reduction of GZ seems more desirable than the associated increase in volatility.

(Right Sidebar Text from Page 580)
**Figure 13.6:** Comparison of fractional Kelly and Grossman–Zhou strategies. Both strategies’ performance measures are estimated over the same sequence of 25,200 returns, but with different parameters `P_k`, `D_k`. (a) Standard deviation of daily log-returns versus mean log-return. (b) Maximum drawdown.

For example, consider a max tolerated drawdown of `10%`. GZ achieves an average daily return of approximately `0.025%`, while fractional Kelly achieves an average daily return of `0.035%`, a `20%` increase. More importantly, GZ controls the maximum drawdown ex-ante, with probability one and independently of misspecification of the problem. In the fractional Kelly approach, even if we provide a maximum drawdown threshold, this threshold is not guaranteed to be met. The optimization problem assumes this bound will be respected as well. These considerations suggest that the GZ strategy may be preferable. There is an important qualification to this statement. Throughout this chapter, we have ignored the role played by transaction costs. As mentioned above, a pure fractional Kelly policy implies the continuous rebalancing of capital from a risky asset to a risk-free one. GZ, in the event of a drawdown sufficient to trigger itself in wiping over time, sometimes very rapidly in the fraction allocated to the strategy, then we may force a complete liquidation of the risky asset when we reach the threshold. This in turn may allow for a large reduction in transaction costs. Beyond the scope of this book, we would then need to extend to the case of transaction costs which, in the absence of analytical results, may only be tractable with numerical experiments. These objections notwithstanding, GZ is a useful heuristic that can be used as an overlay to a Kelly-like strategy.

---

**The Takeaways**

1.  The policy that generates the highest capital growth in the long run is the Kelly criterion.
2.  The Kelly criterion prescribes that we allocate a constant fraction of our capital over time to our active strategy that is equal to the Sharpe Ratio of our strategy divided by its annualized volatility.
3.  The Kelly criterion has the undesirable property of incurring large drawdowns over time.
4.  To alleviate this problem, we can adopt the fractional Kelly criterion, which allocates a constant, smaller fraction of capital to the active strategy. It trades off growth for higher security.
5.  Parameter uncertainty is another way to justify the fractional Kelly criterion.
6.  It is further possible to modify the Kelly criterion so that the fraction of capital is a function of the maximum tolerable drawdown, and this fraction is linearly decreasing as a function of the drawdown size. Once the strategy hits its loss limit, it is liquidated. A deterministic guarantee on the experienced drawdown.
7.  Many successful investors naturally follow a fractional Kelly with drawdown control.
8.  All of these simple strategies are valid in the absence of transaction costs. They need to be simulated and calibrated in real-world applications, in order to account for such costs.

---

**Notes**

1.  For an intuitive treatment of the Kelly criterion, with plenty of examples and applications, see Haghani and White (2022). Marku’s Kurtis’ blog “Outcast Beta” is also bridging the world of application and the mostly academic literature.
2.  A. Damodaran maintains a page (home.stern.nyu.edu/~adamodar/) with S&P500 and Treasury returns.
3.  Before January 1931, the S&P500 had 90 components. The returns for 1926–1930 are from S&P90 index.
4.  For the other properties of the Kelly strategy, See MacLean et al. (2010a) for a review (or Part IV of the book MacLean et al. (2010b) for a diversity of views.
5.  The relationship between this mean-variance approximation and power utility function `u(x) = x^(1-γ)/(1-γ)`, for `γ > 0`, is explored by Pulley (1981).
   

Okay, here is the Markdown compilation for Chapter 14.
     Everand

**Chapter 14**
**Ex-Post Performance Attribution**

**The Questions**

1.  Is portfolio performance primarily due to skill or luck?
2.  What is the breakdown of PnL between factor-driven and idiosyncratic sources?
3.  In idiosyncratic space, is asset selection or sizing a more significant contributor to PnL?
4.  How can factor-based PnL be analyzed in a consistent and meaningful way?
5.  What are effective methods for decomposing portfolio performance in dynamic and complex markets?
6.  How does uncertainty in model parameters affect performance attribution accuracy?

“After the horses have run,” summarizes the plain sense of things.[1] So begins the most poetic, which describes well the spirit of this chapter. Out of metaphor, the “run” is the realized performance of our strategy, and the plain sense of things is our ability to understand what happened after the fact, namely:
*   Is our performance due to luck or skill?
*   How did we make or lose money? What is the contribution of factor PnL and idiosyncratic PnL?
*   In idiosyncratic space, did we drive our PnL? Asset selection or sizing?
*   Sizing is betting on the right side of a bet; the second is the ability to size appropriately asset bets that yield higher returns.
*   How can we explain factor PnL concisely and insightfully, i.e., using only factors that are of interest to us?

Performance attribution is about asking these questions. First, it provides the portfolio manager with a multi-faceted reality check. If she lost money, maybe she can explain the source of the loss, and identify countermeasures to apply going forward, sometimes the remedies are straightforward and contained in the output of the performance attribution itself. If she made money, maybe she did so as the result of unintended bets on factors that were not in her plan, and she can investigate.
The first principle is that you must not fool yourself—and you are the easiest person to fool.[2] This statement, made by Richard Feynman in his 1974 CalTech commencement address, holds true for scientists and traders alike. Second, performance attribution requires the information to be used as appropriately. The principal may be the hedge fund manager and the agent the portfolio manager, or, descending one step down in the decision-making hierarchy, the principal may be the portfolio manager and the agent may be the analyst who works in the portfolio manager’s team. There are other benefits. A portfolio manager is bound to use a specific factor model for ex-ante portfolio construction. An ex-post limitation exists after the fact, though. We can look at the performance of the portfolio using a set of different risk factors. For example, a global risk model, sometimes too coarse for country-specific investing, could reveal cross-country exposures. We can also use statistical models in addition to fundamental models.

Performance attribution is conceptually simple but is not trivial. The remainder of this chapter is broadly organized into two parts. First, we introduce characteristics-based performance attribution (also known as holdings-based), and then review the concept of time-based attribution.

---

**14.1 Performance Attribution: The Basics**

Recall the short introduction to performance attribution in Section A.1.2. The PnL can be decomposed into the sum of factor and idiosyncratic components. The performance decomposition process is slightly more involved. Trading time is not discrete, whereas performance attribution occurs in discrete time. To reconcile the two views, the time axis is partitioned into intervals delimited by epochs `t_k`. Denote the PnL by `PnL_k`, the PnL driver `(r_k - r_{f,k})`, and the total returns `r_k`, and the total factor returns `f_k`. In the case of discrete returns, we define the net holdings `w_k`. We have done previously `b_k = Bᵀw_k`. Then we can isolate the trading PnL with the decomposition
`PnL = Σ (PnL_k - r_{f,k}w_k) + r_{f,k}w_k`
`= Σ (PnL_k - r_{f,k}w_k) + Σ b_kᵀf_k + Σ ε_kᵀw_k`
(trading PnL) (factor PnL) (idiosyncratic PnL)
(position PnL)

The sum of factor and idiosyncratic PnL is sometimes referred to as position PnL. This is the PnL we would experience if we traded instantaneously and with no transaction costs, so that it is very far away from the actual PnL, even at the terminus of the interval’s total returns. To fix ideas on the interpretation of the trading PnL, it is helpful to consider the case of an idealized high-frequency trader (HFT). Let the epochs be the close of trading days. The HFT ends the day flat: `W_N = 0`. The sum over `k` of the trading PnL is the total PnL. It is also the PnL from providing “intraday alpha, i.e., “price discovery,” compensation for providing liquidity by submitting limit orders and removing a fraction of the bid-ask spread, and costs incurred by taking liquidity by submitting market orders.

The factor PnL can be decomposed into separate time series for the contribution of each factor:
`(14.1) Factor PnL = Σ_{j=1}^m [ Σ_{t=1}^T b_{j,t} f_{j,t} ]`

This could be the end of a simple story: take portfolio snapshots at each epoch, decompose PnL into three terms, and then dive into the contribution of individual factors and of individual securities to idiosyncratic PnL. But the world is more complex. First, we need to unveil the illusion of certainty that comes with the simple decomposition of Equation (14.1).

---

**14.2 Performance Attribution with Errors**

**14.2.1 Two Paradoxes**

To motivate the importance of having a more nuanced view of factor-based performance attribution, we introduce two paradoxical facts, both related to FMPs:
*   Factor-Mimicking Portfolios have idiosyncratic risk but not PnL. Each FMP has, by construction, zero exposure to all other factors, and therefore `b_kᵀf_k = 0`. Necessarily, the FMP has non-zero idiosyncratic variance `σ_ε²`. Otherwise, the FMP would be an exact linear combination of the factors, which can be seen intuitively by the fact that the return of the factor is the return of the portfolio itself. More rigorously, let `P` be the matrix whose columns are the FMPs, as defined in Equation (7.2). Then their idio PnL is
    `Pᵀε_k = (B(BᵀΩ⁻¹B)⁻¹)ᵀ(I_n - B(BᵀΩ⁻¹B)⁻¹Bᵀ)Ωε_k = (B(BᵀΩ⁻¹B)⁻¹)ᵀ(Ω - B(BᵀΩ⁻¹B)⁻¹BᵀΩ)ε_k = 0`
    and therefore the idio PnL is null. This holds for all factor portfolios, including those that have an idiosyncratic variance percentage close to 99%, and for all periods. This is especially concerning given that factor model performance is often evaluated via factor portfolios.
*   Factor-Neutral Portfolios. On the other side, consider a portfolio `w` with no exposure to any factor: `Bᵀw = 0`. Hence, its variance comes entirely from idiosyncratic risk: `wᵀΩw = wᵀεεᵀw`. Consider a portfolio `w = λv`, where `v` is an FMP and `λ ∈ ℝ`. The idiosyncratic risk of this portfolio is the same for any value of `λ`, since `v` has no idio PnL. However, the idiosyncratic volatility of `w = λv` depends on `λ`: `σ_ε(λv) = λ²σ_ε(v)²`.
    Hence, even though the same sequence of returns `r_k` generated via simulation of portfolio `w` with different volatility `σ_ε(λv)`, we can make the realized idiosyncratic PnL of the portfolio arbitrarily different than the predicted idiosyncratic volatility, thus greatly undermining the credibility of the model. How can this be?
One could argue that in practice factor portfolios do have low idiosyncratic PnL. This is due precisely to the construction of the portfolio, so that factor portfolios as of time `t` are slightly stale when applied to time `t+1`. This criticism doesn’t address the concerns exemplified by the paradoxes for two reasons. First, because even in the ideal case in which the world is stationary and we have accurately estimated parameters, the average factor PnL of a factor-neutral portfolio would be in any event much smaller than what would be compatible with the idiosyncratic volatility predicted by the model.

(Right Sidebar Text from Page 590)
In the next three sections I present a possible solution to these paradoxes. The overall takeaway is the analysis is that the returns of the FMPs are estimates of the actual factor returns, and not the factor returns per se. In addition, the portfolio’s factor exposures `b_k` are also estimates. Accordingly, both factor PnL and idiosyncratic PnL have distributions in addition to their true factor returns. Once we account rigorously for the estimation error, the factor PnL and idiosyncratic PnL can be characterized as random variables whose mean and several moments can be estimated from the model and portfolio. The next section presents the details about model estimation. The next section derives the main formulas. We then give explanations for the paradoxes.

**14.2.2 Estimating Attribution Errors**

Let us rewrite the attribution equations, but paying attention to the fact that we are using factor and idiosyncratic return estimates `f̃_k, ε̃_k`. We consider the case of a time-independent factor model. Recall from Section A.1.1 that the factor returns can be written as
`f̃_k = f_k + η_k, η_k ~ N(0, B(BᵀΩ⁻¹B)⁻¹)`
Analogously, for the idiosyncratic returns, we have
`ε̃_k = r_k - B f̃_k`
`= r_k - B f_k - B η_k`
`ε̃_k ~ N(0, B(BᵀΩ⁻¹B)⁻¹Bᵀ)`
`(estimated factor PnL)_k = w_kᵀB f̃_k`
`(estimated idiosyncratic PnL)_k = w_kᵀε̃_k`
`= w_kᵀ(r_k - B f̃_k)`
`(true factor PnL)_k ~ N(0, (w_kᵀB)(BᵀΩ⁻¹B)⁻¹(Bᵀw_k))`
When we attribute the PnL over multiple periods, we have
`(true factor PnL)_T = (estimated factor PnL)_T = Σ_k w_kᵀB f̃_k`
`(true idiosyncratic PnL)_T = (estimated idiosyncratic PnL)_T = Σ_k w_kᵀε̃_k`
Finally, this gives us two useful results. First, it provides confidence intervals around the attributed PnL:
`(true factor PnL)_T ~ N(Σ_k w_kᵀB f̃_k, Σ_k (w_kᵀB)(BᵀΩ⁻¹B)⁻¹(Bᵀw_k))`
`(true idiosyncratic PnL)_T ~ N(Σ_k w_kᵀε̃_k, Σ_k w_kᵀB(BᵀΩ⁻¹B)⁻¹Bᵀw_k)`
The idiosyncratic PnL is no longer independent of the hedge `Aw_k`. A portfolio with large idiosyncratic PnL must therefore have large factor PnL. The uncertainty is linear in hedge.

If, for example, we observe a negative idiosyncratic PnL over a given time interval, we can determine whether it falls inside the 95% confidence interval or not. The same applies to factor PnL. Overall, this leads to the true factor, factor and idiosyncratic PnL to be in general negatively correlated. Take the case of a constant portfolio, and constant factor exposures `b_k`. The covariance between factor and idiosyncratic PnL is given by
`-b_kᵀ(BᵀΩ⁻¹B)⁻¹b_k`
This is sometimes observed in practice.

**14.2.3 Paradox Resolution**
We first discuss the paradoxes introduced in the first section.
*   Factor Portfolios: Factor portfolio `j` has exposure vector `b_j = (0, ..., 0, 1, 0, ..., 0)`
    ...where the 1 is in the `j`-th position, so `(b_j)_k = δ_{j,k}`. Therefore
    `(true factor PnL)_j ~ N(f_{j,T}, T(BᵀΩ⁻¹B)⁻¹_{j,j})`
    So the factor portfolio has a non-zero mean idiosyncratic PnL, whose variance grows linearly in `T`.
*   Factor-Neutral Portfolios: Let `w` be a portfolio with no exposure to any factor, i.e., `Bᵀw = 0`. The portfolio `w = λv`, where `v` is the first FMP, has exposure
    `b_v = (λ, 0, ..., 0)`
    The factor and idiosyncratic PnL are
    `(true factor PnL)_T ~ N(λ Σ_t f_{1,t}, λ²T(BᵀΩ⁻¹B)⁻¹_{1,1})`
    `(true idiosyncratic PnL)_T ~ N(0, λ²T(BᵀΩ⁻¹B)⁻¹_{1,1})`

(Right Sidebar Text from Page 594)
**Insight 14.1: Reporting standard errors for attributions**
When reporting factor-based performance attributions, always include (either graphically, or in tabular form), the standard errors of the factor and idiosyncratic PnLs, using the formulas from Section 14.2.2 (or (14.2)). This will help the portfolio manager better understand the uncertainty associated with her attributed performance.

Summing up, the current factor-based attribution methodology universally assigns a numeric factor and idiosyncratic PnL to a strategy; these are deterministic functions of the portfolio over time, the stock returns, and additional available data, such as asset characteristics. Ignoring the estimation error of these attributions leads to misleading conclusions, and does not help in reducing uncertainty in performance of factor portfolios and hedged portfolios, or in the portfolio risk management and to understanding the performance of a strategy. As a simple resolution to these paradoxes, we saw that, even if we are employing the true factor model, the returns of the FMPs are unbiased estimates of the actual factor returns, and not the factor returns themselves. Given this, the estimation error can propagate its impact to the performance attribution process, and view the factor and idiosyncratic PnLs as random variables for which we have the full distributions (under the assumption of normality of returns) and the confidence intervals.

---

**14.3 Maximal Performance Attribution**

A different way to summarize the previous section is: do performance attribution results make sense? The common sense answer is “yes.” In this section, we go deeper into this question by covering exotics, a similarly ex-ante summary, do performance attribution, but to reduce confusion. If we had to attempt a parallel to real life, performance attribution is like falling in love: fundamentally good, but certainly dangerous, and potentially confusing. Where does the confusion come from? Consider the case of a portfolio manager who has generated a large positive PnL from a large exposure to a factor, say, momentum. He then cuts momentum exposure to zero, as a defensive measure. The day after, the factor has a very large negative return. We ask: is the portfolio’s reported PnL equal to zero? The answer is no. Another way to state the issue is that the relationship between ex-ante performance attribution and ex-post performance attribution is not one-to-one. A portfolio’s ex-ante performance is given by the covariance between portfolio returns and the factor’s returns, divided by the factor’s variance. In formulas:
`β(w, f_k) = b_kᵀΩ_{f_k} e_k / (e_kᵀΩ_{f_k} e_k)`
The beta is in general non-zero even if `b_k = 0`. Because
`β = Σ_{j≠k} ρ_{kj} b_j (σ_k / σ_j) + σ_k`
Factors other than momentum, but that are correlated to it, are responsible for the transmission of the shock.

Let us go through another example. You are developing a risk model with a country factor (whose loadings are all ones) and a historical beta factor. You have the option of a missing data model and beta loadings. The choice does not affect individual asset PnL, and aggregated factor PnL does not change if you score or not. Nor is present, and aggregated factor risk does not change if you score or not the individual beta and country factors change. The puzzling attribution in the beta, does much less so in the “right” factor model. What can we say? This is an extreme example of the fact that the factor PnL can have factor drawdowns. It is possible that the PnL be spread across multiple factors and that no factor stands out. It is also possible that these factor losses may be correlated. For example, losses in momentum could be “explained” as momentum losses, or crowded losses, or value losses, or even sector losses, with positive weights. The PnL associated with a factor depends on the representation of the factor itself in the risk model. By this, we mean that the information contained in a given set of factors can be represented in different ways. The same factor may have zero correlation to other factors in one representation, and positive correlation in another. We can even choose to have a single factor that explains the most variance. Performance attribution and risk to a subset of factors, such that it explains the PnL and the risk of the portfolio as much as possible?

The answer is in the affirmative. There is a procedure to assign unequivocally maximum risk and PnL to a subset of factors. There are four different ways to formulate and model the problem, all yielding the same result.
We introduce some notation. Denote the sets
`U := {1, ..., m}`
`S := {1, ..., p}`
`S̄ := {p+1, ..., m}`
so we write `f_S` instead of `f_U` and `Ω_{f,S}` instead of `Ω_{f,U}`.
1.  Maximal Cross-Sectional Factor Explanation. Consider the problem of describing the asset returns as a function of the returns of factors `S`, as well as possible, i.e.,
    `r = B_S f_S + B_S̄ f_S̄ + η`
    where `β ∈ ℝ^{n×p}` and `η` is uncorrelated with `f_S`. By construction, this is the maximum amount of returns we can attribute to factors `S`. Once we identify beta, the return attributed to factors `S`, `f_S*`, which is in general different than `B_S f_S`. We solve the problem
    `(14.3) min_{B_S, B_S̄} E[||r - B_S f_S - B_S̄ f_S̄ - η||²]`
    `s.t. r = B_S f_S + B_S̄ f_S̄ + η`
    `B_S ∈ ℝ^{n×p}, B_S̄ ∈ ℝ^{n×(m-p)}`
    This is equivalent to
    `min_{B_S, B_S̄} E[||f_S - B_S f_S||²]`
    which is solved by `B_S = I_p`. Then the attribution using factor set `S` is given by:
    `(14.4) wᵀB_S f_S = wᵀ[β_S, 0] [f_S; f_S̄]`
    The term `wᵀB_S f_S` is the maximal attribution to factors in `S`. When factors in `S` are uncorrelated to factors in `S̄`, the factor covariance matrix `Ω_f` is block-diagonal and `B_S = β_S`. The maximal attribution is the same. But in general, the factors in `S` and `S̄` are correlated and `Ω_f ≠ Ω_{f,S} ⊕ Ω_{f,S̄}`. Maximal attribution shifts the PnL attributable to factors in `S` from the other factors.
2.  Conditional Expectation. There is another way to interpret these formulas, based on conditional distribution of the multivariate Gaussian distribution. Given returns `r`, `f_S`, `f_S̄`, the conditional expected returns of factors in `S` are statistically and are given by the vector
    `E[f_S | f_S̄] = Ω_{f,S} Ω_{f,S̄}⁻¹ f_S̄`
    The formula for the maximal performance attribution is
    `b_SᵀE[f_S | f_S̄] = b_SᵀΩ_{f,S} Ω_{f,S̄}⁻¹ f_S̄`
    and this is identical to the maximal attribution term in Equation (14.4).
3.  Maximal Portfolio PnL Explanation. Start with the factor PnL of the portfolio `w`, with factor exposure `b_S`. Try to explain as much of the PnL by means of the returns of factors in set `S`. In formulas, we solve the problem
    `min_{b_S^*} E[||b_Sᵀf_S - b_S^*ᵀf_S||²]`
    `s.t. b_S^* ∈ ℝ^p`
    and the PnL attribution is `b_S^*ᵀf_S`, which is, again, what we obtain in Equation (14.4).
    This suggests an interpretation of the vector `b_S^*` as the adjusted dollar bets of the portfolio to factors in set `S`.
4.  Uncorrelated Factor Rotation. We have seen in Section A.2 that factor models are not uniquely determined. One can transform the loadings matrix by right-multiplying it by a non-singular square matrix `C`, and correspondingly transform the factor returns by left-multiplying them by `C⁻¹`. The resulting risk model has factor covariance matrix `C⁻¹Ω_f(C⁻¹)ᵀ`. It makes the same predictions as the original risk model, and the total factor PnL attribution `wᵀB_S f_S` is identical, and the total factor PnL attribution `wᵀB_S̄ f_S̄` is not the same as `wᵀ[BC]_S [C⁻¹f]_S`. We ask whether there is an equivalent rotation that yields the above “maximal attribution” to factors `S`, and what is the PnL attributable to factors in `S̄` for this particular example, given the previous derivations. We need to find `C` such that
    `(14.5) [b_S^*, b_S̄^*] = [b_S, b_S̄]C⁻¹`
    Define the matrix `A_S = [I_{p,S}, 0]` and the rotation matrix `C` as
    `C := [[I_{p,S}, 0], [A, I_{S̄,S̄}]]`
    `C⁻¹ = [[I_{p,S}, 0], [-A, I_{S̄,S̄}]]`
    Direct calculation shows that
    `(14.6) [b_S^*, b_S̄^*]C = [b_S^*, b_S̄^*A + b_S̄^*]`
    which is the same as Equation (14.5). In the rotated risk model the covariance matrix is
    `(14.7) Ω_f(C⁻¹)ᵀ = [[Ω_{f,S}, Ω_{f,S}Aᵀ - Ω_{f,S S̄}], [AΩ_{f,S} - Ω_{f,S̄ S}, AΩ_{f,S}Aᵀ - AΩ_{f,S S̄} - Ω_{f,S̄ S}Aᵀ + Ω_{f,S̄ S̄}]]`
    The interpretation of the transformation is that it makes the first `p` factors independent from the remaining ones. The returns and volatilities of the first `p` factors are unchanged, and the volatilities of the remaining ones are reduced. This is unintuitive at first sight, but has a simple interpretation: we have orthogonalized the factors in `S̄` and pushed the explanatory power in the first `p` group. On the other side, the dollar exposures of a portfolio for the first `p` factors, on the other side, are changing from `b_S` to `b_S^*` (see Equation (14.5)), so the PnL and the probability of the performance attribution is increasing as well.

Let us go through an example. We have a factor strategy for which we run daily factor performance attribution, which is shown in Figure 14.1 (top). We select to maximalize the factors market, momentum, and crowding factors. After rotating the remaining factors, the performance attribution changes significantly and is shown in Figure 14.1 (bottom). The market is responsible for a higher loss, crowding factors are larger than in the regular attribution, whereas growth is responsible for a smaller loss.

**Figure 14.1:** Top: PnL from factor performance attribution. Bottom: Maximal attribution on three factors: market, momentum, and crowding.

We close this section with two observations. First, we focused on the “maximal contribution” factors. Alternatively, we could focus on the set `S̄`, i.e., the performance attributable to factors in `S̄` once we have removed “maximal attribution” factors. The model has been rotated so that the portfolio performance has been described by a smaller dimensional space.

Second, we can perform a nested maximal performance attribution. Instead of having a “maximal attribution” set and a “minimal attribution” set, we extend the approach to a partition of the factor set `{1, ..., m}` by factor sets `S_1, ..., S_k`. Factor set `S_1` explains the maximal PnL, and so on. The most granular instance is where `S_i = {i}`, so that we orthogonalize the model sequentially one factor at a time. In practice, however, it may be more sensible to create a coarse partition, every element of which describes a common theme. For example, we may have a “market factor” set comprising country, market, and volatility factors; then a “value factor” set comprised of earnings yield, earning variation, dividend yield, book-to-price, and quality; a “sentiment factor” set, an “industry” set, and so on. The steps involved in simple maximal attribution and nested attribution are described in Procedures 14.1 and 14.2.

**Procedure 14.1: Maximal attribution**
1.  Inputs: Factor covariance matrix `Ω ∈ ℝ^{m×m}`;
    Universe `U := {1, ..., m}`; set `S ⊂ U`; universe `S̄ := U \ S`;
    portfolio `w`.
2.  Set
    `B := bᵀw`
    `A := Ω_{f,S} Ω_{f,S̄}⁻¹`
    `C := [[I_{p,S}, 0], [A, I_{S̄,S̄}]]`
3.  Output:
    Factor maximal PnL: `PnL_S = b_SᵀA f_S̄`.
    for all `k ∈ S̄`, `PnL_k = (b_k - A_{k,S}b_S)f_k`.
    Rotated factor covariance matrix `Ω̃ = C⁻¹Ω_f(C⁻¹)ᵀ`.

**Procedure 14.2: Nested maximal attribution**
1.  Inputs: Factor covariance matrix `Ω ∈ ℝ^{m×m}`;
    `U := {1, ..., m}`; set partition `S_1, ..., S_p` of `U`;
    portfolio `w`.
2.  For `i = 1, ..., p`:
    `U_i := U \ (∪_{j=1}^{i-1} S_j)`
    Perform maximal attribution (Procedure 14.1)
    Set `S := S_i`, `Ω_f := Ω_{f,U_i}`, `S̄ := U_i \ S_i`.
    `B_i = B_i - B_i Ω_{f,S_i S̄_i} Ω_{f,S̄_i S̄_i}⁻¹`.
3.  Store `PnL_{S_i}` for `g = 1, ..., p` and the related risk model.
    `Σ⁽¹⁾   0    ...   0`
    `0    Σ⁽²⁾  ...   0`
    `...  ...  ...  ...`
    `0    ...  ...  Σ⁽ᵖ⁻¹⁾`
    `0    ...  ...   0    Ω`

---

**14.4 Selection versus Sizing Attribution**

In factor-based attribution, the idiosyncratic PnL of a strategy is the most crucial performance term, representing the PnL that cannot be explained by factor exposures. While factor-based attribution identifies the non-systematic portion of the PnL, it fails to explain the source of idiosyncratic performance. Portfolio managers often consider asset selection and sizing as the primary sources of their skill. Selection refers to the ability to be long on stocks with positive returns and short on those with negative returns. Sizing refers to the ability to size portfolio positions right when right than when wrong. These skills have practical implications for portfolio construction and can lead to improved risk-adjusted performance. Quantitative analysts have developed “tilting” and “hugging” metrics to quantify selection and sizing, respectively. These metrics typically involve calculating the percentage of holdings in the ratio between the average PnL of profitable and unprofitable investments. Despite their intuitive appeal, these measures have two drawbacks: they lack a direct relationship with profitability measures like the Information Ratio, and do not provide clear guidance for portfolio managers.

This section aims to address these problems. We show how a new selection-sizing decomposition achieves two objectives:
1.  It links through an analytical, interpretable formula the IR of a strategy to the selection, sizing, and breadth of a portfolio.
2.  It provides guidance for portfolio managers. In the case that the strategy has positive sizing skill and that it has negative sizing skill.
The IR is the expected value of the idiosyncratic PnL divided by its standard deviation. If we restrict our attention to a single period, an estimate of the IR is
`(Idio PnL)_t / (Idio Vol)_t`
An estimate for the IR that employs the available time series of portfolios in epochs `1, 2, ..., T` is
`IR̂ = (1/T) Σ_{t=1}^T (Idio PnL)_t / (Idio Vol)_t`
The IR can be expressed as a simple combination of intuitive terms. The decomposition is
`IR̂ = √(1/T) Σ_{t=1}^T (selection)_t × (diversification)_t + (sizing)_t`
The terms in the identity are:
A selection skill
`(selection)_t = (1/n) Σ_{i=1}^n ε̃_{i,t} sgn(w_{i,t})`
We score the idiosyncratic return `ε̃_{i,t}` of an asset to obtain `sgn(ε̃_{i,t})`. If `sgn(ε̃_{i,t})` and `sgn(w_{i,t})` have the same sign, then `sgn(ε̃_{i,t}) sgn(w_{i,t}) = 1`. Sizing of a security bet is a specific period and the contribution to selection is positive. The scoring puts assets with different volatility on the same scale, so that selection does not reward the magnitude of the return.
Diversification. Instead of worrying about the rational value of diversification, we use the dollar volatility of each position, defined as `w̃_{i,t} = |w_{i,t}|σ_{i,t}`. Then we define
`(diversification)_t = ||w̃||₁ / ||w̃||₂`
When all the dollar volatilities are identical, then the portfolio diversification is `√n`. If, on the other end, the portfolio is concentrated, then the portfolio diversification is 1. The diversification squared ranges between 1 and `n`, and can be interpreted as the effective number of assets. This diversification term has a well-known connection to the Herfindahl index, which is a measure of concentration. To be more specific, define weights
`x_i = |w̃_{i,t}| / Σ_j |w̃_{j,t}|`
The Herfindahl Index is defined as `H = Σ_i x_i²`. The relationship is then
`(diversification)_t² = 1/√H`
The relationship between diversification and portfolio construction was first explored by Bouchaud et al. (1997).
The last term is sizing. It is equal to
`(sizing)_t = √(n) (1/n) Σ_{i=1}^n ε̃_{i,t} sgn(w_{i,t}) (w̃_{i,t} / ||w̃||₁)`
Here, `√(n)σ(ε̃, σ sgn(w))` where we treated the quantities associated to individual securities as empirical observations `ε̃_i`. The interpretation of sizing is that it measures the correlation between `sgn(ε̃_{i,t})` and `sgn(w_{i,t})` (the selection skill), and the dollar volatility `w̃_{i,t}`. Sizing is positive if, when the portfolio manager is right about the sign of a position, she is right about its size by having a relatively large position. In formulas, we first define
`(sizing)_t = (n / ||w||₁) Σ_{i=1}^n ε̃_{i,t} sgn(w_{i,t}) |w_{i,t}|`
(right side today) (bet size)
This equation can be used in several ways. To achieve a higher IR, a portfolio manager has the following three options:
*   Increase diversification. Markowitz famously said that diversification is the only free lunch in investing. This equation shows that benefits from diversification are via selection, i.e., the marginal benefit obtained by increasing diversification. This reasoning is not widely understood, however. Managers can increase diversification in two ways. The first one is by increasing the number of assets. This does not require additional effort. Alternatively, the portfolio manager could add stocks to the investment universe. This operation is not costless, since it would involve spending time on each stock and possibly commission costs. By increasing diversification, the manager may come to the stock selection from this decision.
*   Improve selection skill. The decomposition helps by providing a simple measure, which makes use of information dataset at a manager’s disposal. Once selection skill has been measured, and all the individual positions. Once selection skill has been measured, several actions are possible. For example, the portfolio manager can track the selection skill at the sub-industry or at the thematic level, or the portfolio manager can compare selection skill across various outside earnings.
*   Improve sizing skill. There is value already in having portfolio managers assess their sizing skill relative to selection; most portfolio managers overestimate their sizing skill, and find the true sizing skill, or even the overall trend, counterintuitive. If their sizing skill is negative, the portfolio manager should consider reducing the average position size. In doing so, they will eliminate the drag from negative sizing and magnify the benefit of stock selection, by maximizing breadth. If there is positive sizing skill, the portfolio manager can optimize the size of the high-conviction positions to maximize the IR. This is the subject of the next subsection.

**14.4.1 Connection to the Fundamental Law of Active Management**
The IR decomposition bears some resemblance to Grinold and Kahn’s Fundamental Law of Active Management (Grinold and Kahn, 1999). That law related the IR to the product of the Information Coefficient and of the breadth of the portfolio `√N`. This formula uses a different portfolio breadth—the effective breadth—which treats not all positions as equal. For example, a portfolio of 100 stocks with 99% of its gross exposure in each of two of them does not have the same breadth as a portfolio of 100 stocks with equal gross exposure in each stock and `N` in the remaining 99. In their seminal article, Bouchaud et al. (1997) present a modified mean-variance portfolio formulation that puts a lower bound on our definition of diversification. This results in using a shrunken covariance matrix (see also Ledoit and Wolf, 2003; DeMiguel et al., 2009b; Pedersen et al., 2021) and penalized covariance estimation methodologies (Ledoit and Wolf, 2003).

**14.4.2 Long-Short Performance Attribution**
The selection component of our performance attribution is linear, and therefore lends itself naturally to be further processed in different performance sub-terms. A natural way to decompose selection versus sizing is the sum of selection skill that arises from being on the right side of returns when positions are long versus when positions are short. The decomposition follows from the chain of equalities below:
`(selection)_t = (1/n) Σ_{i=1}^n ε̃_{i,t} sgn(w_{i,t})`
`= (n_{long}/n) (1/n_{long}) Σ_{i∈long} ε̃_{i,t} sgn(w_{i,t}) + (n_{short}/n) (1/n_{short}) Σ_{i∈short} ε̃_{i,t} sgn(w_{i,t})`
`= (n_{long}/n) (selection_{long})_t + (n_{short}/n) (selection_{short})_t`
where `n_{long}, n_{short}` are the number of long and short positions, and `Φ_{long}, Φ_{short}` are the fraction of the total portfolio positions that are long and short, respectively.
Summing up, in Figure 14.2 we show the dependency tree of the decomposition terms.

**Figure 14.2:** A taxonomy of performance attribution.
Total PnL -> Factor PnL, Idio PnL
Idio PnL -> Information Ratio
Information Ratio -> Diversification X (Long Positions), Diversification X (Short Positions), Sizing

---

**14.5 Appendix**

**14.5.1 Proof of the Selection versus Sizing Decomposition**

**Theorem 14.1:**
Consider a portfolio sequence `w_t ∈ ℝ^n`, and `n` names of iid idiosyncratic returns `ε̃_{i,t}`. Let `w̃_{i,t} = |w_{i,t}|σ_{i,t}` with `var(ε̃_{i,t}) = σ_i²`. Define the empirical Information Ratio:
`IR̂ = (1/T) Σ_{t=1}^T (Idio PnL)_t / (Idio Vol)_t`
Then the identity holds
`(14.11) IR̂ = √(1/T) Σ_{t=1}^T (selection)_t × (diversification)_t + (sizing)_t`
where the terms in the equation above are defined as follows:
`w̃_{i,t} := |w_{i,t}|σ_{i,t}`
`ũ_{i,t} := w̃_{i,t} / ||w̃||₁`
`ẽ_{i,t} := Ω⁻¹/²ε̃_{i,t}`
`(selection)_t := E[ẽ_{i,t} sgn(ũ_{i,t})]`
`(diversification)_t := √(n E[ũ_{i,t}²])`
`(sizing)_t := √(n) cov(ẽ_{i,t} sgn(ũ_{i,t}), |ũ_{i,t}|)`
Proof:
In period `t`, the risk-adjusted PnL of the portfolio at time `t` is given by
`IR̂_t = w_tᵀε̃_t / √(w_tᵀΩw_t)`
Set `w_t = Ω⁻¹/²w̃_t` and `ẽ_t = Ω⁻¹/²ε̃_t`. The vector `w̃_t` has a familiar interpretation. It is a portfolio whose positions are not expressed as NAV but rather as dollar volatilities of each asset. The return vector `ẽ_t` contains the idiosyncratic asset returns. Its covariance matrix is the identity. With these transformations, IR takes a simpler form:
`IR̂_t = w̃_tᵀẽ_t / ||w̃_t||`
This follows from the fact that the numerator is
`w_tᵀẽ_t = Σ_i w_{i,t} ẽ_{i,t} = Σ_i (σ_i w̃_{i,t}) (ε̃_{i,t}/σ_i)`
`= Σ_i w̃_{i,t} ε̃_{i,t}`
and the denominator is
`√(w_tᵀΩw_t) = √( (Ω⁻¹/²w̃_t)ᵀ Ω (Ω⁻¹/²w̃_t) ) = ||w̃_t||`
We can further simplify the formula by considering a breadth-rescaled percentage of the total dollar volatility
`IR̂_t = Σ_i w̃_{i,t} ẽ_{i,t} / ||w̃_t||`
`= Σ_i ẽ_{i,t} sgn(w̃_{i,t}) |w̃_{i,t}| / ||w̃_t||`
`= √(n) Σ_i ẽ_{i,t} sgn(w̃_{i,t}) (|w̃_{i,t}| / (√n ||w̃_t||))`
`= √(n) Σ_i ẽ_{i,t} sgn(ũ_{i,t}) |ũ_{i,t}|`
where we set
`ũ_{i,t} := w̃_{i,t} / (√n ||w̃_t||)`
We denote the cross-sectional empirical average and the cross-sectional empirical covariance
`E[X] := (1/n) Σ_i X_i`
`cov(X,Y) := E[XY] - E[X]E[Y]`
The formula becomes
`IR̂_t = √(n E[ẽ_{i,t} sgn(ũ_{i,t}) |ũ_{i,t}|])`
where we have used the notation `ũ` to denote the (double-indexed) product of two vectors, `ũ_i = u_{1,i} u_{2,i}`. Finally, in the last step we use the identity
`E[XY] = cov(X,Y) + E[X]E[Y]`
with `X = ẽ_{i,t} sgn(ũ_{i,t})` and `Y = |ũ_{i,t}|`. It follows that
`IR̂_t = √(n) (cov(ẽ_{i,t} sgn(ũ_{i,t}), |ũ_{i,t}|) + E[ẽ_{i,t} sgn(ũ_{i,t})] E[|ũ_{i,t}|])`
A possible interpretation of the above formula is as a sample of the realized IR over a single observation, or period. An estimate of the IR over the period `1, ..., T` is then given by its time series average:
`IR̂ = (1/T) Σ_{t=1}^T IR̂_t`
`= √(n) ( (1/T) Σ_{t=1}^T cov(ẽ_{i,t} sgn(ũ_{i,t}), |ũ_{i,t}|) + (1/T) Σ_{t=1}^T E[ẽ_{i,t} sgn(ũ_{i,t})] E[|ũ_{i,t}|] )`
This is equal to Equation (14.11) once we define
`(selection)_t = E[ẽ_{i,t} sgn(ũ_{i,t})]`
`(diversification)_t = √(n E[|ũ_{i,t}|])`
`(sizing)_t = √(n) cov(ẽ_{i,t} sgn(ũ_{i,t}), |ũ_{i,t}|)`

---

**The Takeaways**

*   Performance attribution helps determine if results are due to luck or skill and identifies sources of profit or loss.
*   Decomposing PnL into factor PnL and idiosyncratic PnL provides deeper insights into portfolio performance.
    Two paradoxes in performance attribution:
    1. Factor-Mimicking Portfolios: They have idiosyncratic risk but no idiosyncratic PnL, which is counterintuitive.
    2. Factor-Neutral Portfolios: They can have the same idiosyncratic PnL despite different volatilities.
    These paradoxes highlight the need to consider estimation errors in performance attribution models.
*   Accounting for estimation errors allows factor and idiosyncratic PnLs to be characterized as random variables.
*   Maximal Performance Attribution: Assigns as much PnL as possible to selected factors for clearer insights.
    Methods for maximal attribution include cross-sectional return explanation, conditional expectation, and model rotation.
*   Nested maximal attribution allows sequential attribution to different sets of factors, enhancing analysis granularity.
*   Selection versus sizing attribution decomposes idiosyncratic PnL into stock selection (right asset choice) and sizing (position size) components.
*   The Information Ratio (IR) links to selection skill, diversification, and sizing skill, providing a measure of performance.
*   Increasing diversification increases the marginal benefits of selection skill in a portfolio.
*   Enhancing selection and sizing skills can lead to better risk-adjusted returns and overall portfolio performance.

---

**Notes**

1.  W. Stevens, “The Plain Sense of Things,” in Stevens (1990).
2.  Non-idealized HFTs do not necessarily close the day flat, but instead rebalance the book and/or partially hedge it.
3.  By “any,” we mean that the return covariance matrix can be decomposed into the sum of a dense low-rank matrix and a sparse full-rank one.
4.  We use the notation `e_k` for the vector having a 1 in the `k`-th position and 0 elsewhere. (p. 596) We also assume that the factor portfolios have negligible idiosyncratic variance.
5.  We refer the reader to the Appendix, Section A.2.1 for derivations of the formulas below.
    A short derivation for two vectors `x,y ∈ ℝ^n`:
    `cov(X,Y) = (1/n) Σ x_i y_i - ( (1/n) Σ x_i ) ( (1/n) Σ y_i ) = E[XY] - E[X]E[Y]`
6.  The analysis presented here does not take into account transaction costs. This is a reasonable approximation for small portfolios. A more comprehensive model is possible, but outside of our scope.
   

Okay, here is the Markdown compilation for Chapter 15, the References, and the Index.

```markdown
Everand

**Chapter 15**
**A Coda ad Laborem**

It seems almost requisite to abruptly close a book with a chapter on performance attribution. In “The Return of the King,” the coda of the movie lasted 30 minutes, enough to make us forget the satisfying spectacle of Mordor’s fall. I promise this one will be shorter. This chapter summarizes the main themes in the book, by highlighting them. I hope to provide the quantitative investment strategy developer with some principles to inspire them in their daily endeavor.

1.  Use legible methods. With few exceptions, the mathematics used in the book is no more than 100 years old. The exceptions are Rademacher complexity, which dates back to the work of Vapnik and Chervonenkis in the early 1970s, and the spectral properties of spiked covariance matrices, which date back to the turn of the century. Using established methods makes the theory visible: at any time you know what is going on. Calculus speaks of visibility. Good math makes the invisible visible. What is visible can be communicated, inspected, critiqued, and improved.
2.  Use simple mathematical methods. Theory is cheap. You can make theory arbitrarily complicated. The hard part is to summon from the void the simplest tools that answer your question. Everything in the book is linear and quadratic. Don’t restrict yourself to these families; however, even if your problem does not show linear structure in a toy model, postulate that it will have it in a more complex one.
3.  Think deeply of simple things. Start with simple questions, possibly identifying them within a more complex system. And then solve them from first principles as much as you can. For example, do not make up measures of stock selection and sizing. Link performance metrics to the Sharpe Ratio. Or link factor modeling with risk decomposition of your space of strategies.
4.  Take errors into account from the start. “Certainty is beautiful, but uncertainty is more beautiful still.” All measurement has error. The entire edifice of optimization and error. However, errors propagate in portfolio optimization, in intertemporal volatility allocation, in backtesting. Modeling uncertainty from the start is sound theoretically and addresses the shortcomings of known methods, like mean-variance optimization.
5.  Derive answers from first principles. So many processes we have advocated resonate deeply with our everyday decision-making process. Exponential weighting, update what you learned so far by mixing with new evidence. Shrinkage: incorporate uncertainty by downweighting your estimate. Hierarchical models: combine information from complex decision. Decompose single-period one. Over and over, successful researchers are the ones that achieve principled simplicity.

**Notes**
1.  I am borrowing a verse from “Love at first sight,” a poem by W. Szymborska (Szymborska, 2015).

---

**References**

1.  V. Agarwal and N. Y. Naik. Risks and portfolio decisions involving hedge funds. The Review of Financial Studies, 17(1):63–98, 2004.
2.  Y. Aït-Sahalia, P. A. Mykland, and L. Zhang. How often to sample a continuous-time process in the presence of market microstructure noise. Review of Financial Studies, 20(2):351–416, 2007.
3.  Y. Aït-Sahalia, P. A. Mykland, and L. Zhang. Ultra-high-frequency volatility estimation with dependent microstructure noise. Journal of Econometrics, 160(1):160–175, 2011.
4.  R. Almgren. Execution costs. In S. N. Durlauf and L. E. Blume, editors, The New Palgrave Dictionary of Economics. Palgrave Macmillan, 2008.
5.  R. Almgren and N. Chriss. Optimal execution of portfolio transactions. Journal of Risk, 3(2):5–39, 2001.
6.  R. Almgren and N. Chriss. Value under liquidation. Risk, 12(12):61–63, 1999.
7.  R. Almgren, C. Thum, F. Hauptmann, and H. Li. Equity market impact. Risk, pages 57–62, 2005.
8.  T. Amemiya. The estimation of the variances in a variance-components model. International Economic Review, 18(1):1–13, 1977.
9.  T. G. Andersen, T. Bollerslev, F. X. Diebold, and P. Labys. Exchange rate returns standardized by realized volatility are (nearly) Gaussian. Multinational Finance Journal, 4(3/4):159–179, 2000.
10. T. G. Andersen, T. Bollerslev, F. X. Diebold, and H. Ebens. The distribution of realized stock return volatility. Journal of Financial Economics, 61(1):43–76, 2001.
11. T. G. Andersen, T. Bollerslev, and F. X. Diebold. Parametric and nonparametric volatility measurement. In L. P. Hansen and Y. Aït-Sahalia, editors, Handbook of Financial Econometrics, volume 1, chapter 12, pages 677–738. Elsevier, 2010.
12. T. G. Andersen, R. A. Davis, J.-P. Kreiss, and T. Mikosch, editors. Handbook of Financial Time Series. Springer, 2009.
13. T. G. Andersen, T. Bollerslev, F. X. Diebold, and C. Vega. Real-time price discovery in stock, bond and foreign exchange markets. Journal of International Economics, 73(2):251–277, 2007.
14. T. G. Andersen and T. Bollerslev. Deutsche mark–dollar volatility: Intraday activity patterns, macroeconomic announcements, and longer run dependencies. The Journal of Finance, 52(1):219–265, 1997.
15. T. G. Andersen and T. Bollerslev. Answering the skeptics: Yes, standard volatility models do provide accurate forecasts. International Economic Review, 39(4):885–905, 1998.
16. T. G. Andersen, T. Bollerslev, and N. Meddahi. Analytic evaluation of volatility forecasts. International Economic Review, 45(4):1079–1110, 2004.
17. T. G. Andersen, T. Bollerslev, F. X. Diebold, and P. Labys. Great depreciations. The Review of Economics and Statistics, 92(4):717–733, 2010.
18. J. Ang and J. Chen. CAPM over the long run: 1926–2001. Journal of Empirical Finance, 14(1):1–40, 2007.
19. J. Ang, R. J. Hodrick, Y. Xing, and X. Zhang. The cross-section of volatility and expected returns. The Journal of Finance, 61(1):259–299, 2006.
20. J. Ang, R. J. Hodrick, Y. Xing, and X. Zhang. High idiosyncratic volatility and low returns: International and further U.S. evidence. Journal of Financial Economics, 91(1):1–23, 2009.
21. J. Y. Campbell, A. W. Lo, and A. C. MacKinlay. The Econometrics of Financial Markets. Princeton University Press, 1997.
22. J. Y. Campbell, M. Lettau, B. G. Malkiel, and Y. Xu. Have individual stocks become more volatile? An empirical exploration of idiosyncratic risk. The Journal of Finance, 56(1):1–43, 2001.
23. J. Bai and S. Ng. Large dimensional factor analysis. Foundations and Trends in Econometrics, 3(2):89–163, 2008.
24. J. Bai and J. Yao. Central limit theorems for eigenvalues in a spiked population model. Annales de l’Institut Henri Poincaré, Probabilités et Statistiques, 44(3):447–474, 2008.
25. J. Baik and J. W. Silverstein. Eigenvalues of large sample covariance matrices of spiked population models. Journal of Multivariate Analysis, 97:1382–1408, 2006.
26. J. Baik, G. Ben Arous, and S. Péché. Phase transition of the largest eigenvalue for normal complex sample covariance matrices. Annals of Probability, 33(5):1643–1697, 2005.
27. M. Baker, B. Bradley, and J. Wurgler. Benchmarks as limits to arbitrage: Understanding the low-volatility anomaly. Financial Analysts Journal, 70(1):38–50, 2014.
28. R. Banz. The relationship between return and market value of common stock. Journal of Financial Economics, 9(1):3–18, 1981.
29. E. Barndorff-Nielsen. Power and Bipower Variation with Stochastic Volatility and Jumps. Journal of Financial Econometrics, 2(1):1–37, 2004.
30. E. Barndorff-Nielsen and N. Shephard. Non-Gaussian Ornstein–Uhlenbeck-based models and some of their uses in financial economics. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 63(2):167–241, 2001.
31. E. Barndorff-Nielsen and N. Shephard. Econometric analysis of realized volatility and its use in estimating stochastic volatility models. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 64(2):253–280, 2002.
32. E. Barndorff-Nielsen and N. Shephard. Realized power variation and stochastic volatility models. Bernoulli, 9(2):243–265, 2003.
33. E. Barndorff-Nielsen, P. R. Hansen, A. Lunde, and N. Shephard. Designing realized kernels to measure the ex post variation of equity prices in the presence of noise. Econometrica, 76(6):1481–1536, 2008.
34. E. Barndorff-Nielsen, P. R. Hansen, A. Lunde, and N. Shephard. Multivariate realised kernels: Consistent positive semi-definite estimators of the covariation of equity returns with noise and non-synchronous trading. Journal of Econometrics, 160(1):150–165, 2011.
35. O. E. Barndorff-Nielsen. On the utility theoretic foundations of mean-variance analysis. Journal of Finance, 52(3):1183–1197, 1997.
36. M. S. Bartlett. A note on the multiplying factors for various χ² approximations. Journal of the Royal Statistical Society. Series B (Methodological), 16(2):296–298, 1954.
37. S. Basu. Investment performance of common stocks in relation to their price-earnings ratios: A test of the efficient market hypothesis. The Journal of Finance, 32(3):663–682, 1977.
38. F. Beckers, R. J. Henriksson, and A. D. Oppenheimer. Optimal trading strategies for investors who forecast returns. The Journal of Finance, 41(2):385–397, 1986.
39. G. Bekaert and R. J. Hodrick. International Financial Management. Cambridge University Press, 2nd edition, 2012.
40. G. Bekaert, R. J. Hodrick, and X. Zhang. International stock return comovements. The Journal of Finance, 64(6):2591–2626, 2009.
41. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Liquidity and expected returns: Lessons from emerging markets. The Review of Financial Studies, 20(6):1783–1831, 2007.
42. G. Bekaert, C. R. Harvey, and A. Ng. Market integration and contagion. Journal of Business, 78(1):39–69, 2005.
43. G. Bekaert and G. Wu. Asymmetric volatility and risk in equity markets. The Review of Financial Studies, 13(1):1–42, 2000.
44. G. Bekaert and J. H. Liu. Conditional correlation and volatility in nominal and real asset returns. Journal of Empirical Finance, 11(4):413–449, 2004.
45. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Does financial liberalization spur growth? Journal of Financial Economics, 77(1):3–55, 2005.
46. G. Bekaert, C. R. Harvey, and R. L. Lumsdaine. Dating the integration of world equity markets. Journal of Financial Economics, 65(2):203–247, 2002.
47. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Growth volatility and financial liberalization. Journal of International Money and Finance, 25(3):370–403, 2006.
48. G. Bekaert, R. J. Hodrick, and X. Zhang. The idiosyncratic volatility puzzle: A global perspective. Working Paper 13805, National Bureau of Economic Research, February 2008.
49. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Emerging equity market volatility. Journal of Financial Economics, 88(3):595–629, 2008.
50. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Global growth opportunities and market integration. The Journal of Finance, 62(3):1081–1137, 2007.
51. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Liquidity and expected returns: Lessons from emerging markets. The Review of Financial Studies, 20(6):1783–1831, 2007.
52. G. Bekaert, C. R. Harvey, and C. T. Lundblad. The dynamics of emerging market equity flows. Journal of International Money and Finance, 22(3):295–350, 2003.
53. G. Bekaert, C. R. Harvey, and C. T. Lundblad. The effect of U.S. monetary policy on emerging market equity returns. Journal of Banking & Finance, 37(12):5077–5094, 2013.
54. G. Bekaert, C. R. Harvey, and C. T. Lundblad. The political risk premium. Journal of International Money and Finance, 30(6):1031–1057, 2011.
55. G. Bekaert, C. R. Harvey, and C. T. Lundblad. What segments equity markets? Financial Analysts Journal, 63(4):58–74, 2007.
56. G. Bekaert, C. R. Harvey, and C. T. Lundblad. World market integration. Journal of Financial Economics, 75(2):233–248, 2005.
57. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Does financial liberalization spur growth? Journal of Financial Economics, 77(1):3–55, 2005.
58. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Emerging equity market volatility. Journal of Financial Economics, 88(3):595–629, 2008.
59. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Global growth opportunities and market integration. The Journal of Finance, 62(3):1081–1137, 2007.
60. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Liquidity and expected returns: Lessons from emerging markets. The Review of Financial Studies, 20(6):1783–1831, 2007.
61. G. Bekaert, C. R. Harvey, and C. T. Lundblad. The dynamics of emerging market equity flows. Journal of International Money and Finance, 22(3):295–350, 2003.
62. G. Bekaert, C. R. Harvey, and C. T. Lundblad. The effect of U.S. monetary policy on emerging market equity returns. Journal of Banking & Finance, 37(12):5077–5094, 2013.
63. G. Bekaert, C. R. Harvey, and C. T. Lundblad. The political risk premium. Journal of International Money and Finance, 30(6):1031–1057, 2011.
64. G. Bekaert, C. R. Harvey, and C. T. Lundblad. What segments equity markets? Financial Analysts Journal, 63(4):58–74, 2007.
65. G. Bekaert, C. R. Harvey, and C. T. Lundblad. World market integration. Journal of Financial Economics, 75(2):233–248, 2005.
66. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Does financial liberalization spur growth? Journal of Financial Economics, 77(1):3–55, 2005.
67. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Emerging equity market volatility. Journal of Financial Economics, 88(3):595–629, 2008.
68. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Global growth opportunities and market integration. The Journal of Finance, 62(3):1081–1137, 2007.
69. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Liquidity and expected returns: Lessons from emerging markets. The Review of Financial Studies, 20(6):1783–1831, 2007.
70. G. Bekaert, C. R. Harvey, and C. T. Lundblad. The dynamics of emerging market equity flows. Journal of International Money and Finance, 22(3):295–350, 2003.
71. G. Bekaert, C. R. Harvey, and C. T. Lundblad. The effect of U.S. monetary policy on emerging market equity returns. Journal of Banking & Finance, 37(12):5077–5094, 2013.
72. G. Bekaert, C. R. Harvey, and C. T. Lundblad. The political risk premium. Journal of International Money and Finance, 30(6):1031–1057, 2011.
73. G. Bekaert, C. R. Harvey, and C. T. Lundblad. What segments equity markets? Financial Analysts Journal, 63(4):58–74, 2007.
74. G. Bekaert, C. R. Harvey, and C. T. Lundblad. World market integration. Journal of Financial Economics, 75(2):233–248, 2005.
75. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Does financial liberalization spur growth? Journal of Financial Economics, 77(1):3–55, 2005.
76. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Emerging equity market volatility. Journal of Financial Economics, 88(3):595–629, 2008.
77. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Global growth opportunities and market integration. The Journal of Finance, 62(3):1081–1137, 2007.
78. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Liquidity and expected returns: Lessons from emerging markets. The Review of Financial Studies, 20(6):1783–1831, 2007.
79. G. Bekaert, C. R. Harvey, and C. T. Lundblad. The dynamics of emerging market equity flows. Journal of International Money and Finance, 22(3):295–350, 2003.
80. G. Bekaert, C. R. Harvey, and C. T. Lundblad. The effect of U.S. monetary policy on emerging market equity returns. Journal of Banking & Finance, 37(12):5077–5094, 2013.
81. G. Bekaert, C. R. Harvey, and C. T. Lundblad. The political risk premium. Journal of International Money and Finance, 30(6):1031–1057, 2011.
82. G. Bekaert, C. R. Harvey, and C. T. Lundblad. What segments equity markets? Financial Analysts Journal, 63(4):58–74, 2007.
83. G. Bekaert, C. R. Harvey, and C. T. Lundblad. World market integration. Journal of Financial Economics, 75(2):233–248, 2005.
84. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Does financial liberalization spur growth? Journal of Financial Economics, 77(1):3–55, 2005.
85. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Emerging equity market volatility. Journal of Financial Economics, 88(3):595–629, 2008.
86. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Global growth opportunities and market integration. The Journal of Finance, 62(3):1081–1137, 2007.
87. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Liquidity and expected returns: Lessons from emerging markets. The Review of Financial Studies, 20(6):1783–1831, 2007.
88. G. Bekaert, C. R. Harvey, and C. T. Lundblad. The dynamics of emerging market equity flows. Journal of International Money and Finance, 22(3):295–350, 2003.
89. G. Bekaert, C. R. Harvey, and C. T. Lundblad. The effect of U.S. monetary policy on emerging market equity returns. Journal of Banking & Finance, 37(12):5077–5094, 2013.
90. G. Bekaert, C. R. Harvey, and C. T. Lundblad. The political risk premium. Journal of International Money and Finance, 30(6):1031–1057, 2011.
91. G. Bekaert, C. R. Harvey, and C. T. Lundblad. What segments equity markets? Financial Analysts Journal, 63(4):58–74, 2007.
92. G. Bekaert, C. R. Harvey, and C. T. Lundblad. World market integration. Journal of Financial Economics, 75(2):233–248, 2005.
93. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Does financial liberalization spur growth? Journal of Financial Economics, 77(1):3–55, 2005.
94. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Emerging equity market volatility. Journal of Financial Economics, 88(3):595–629, 2008.
95. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Global growth opportunities and market integration. The Journal of Finance, 62(3):1081–1137, 2007.
96. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Liquidity and expected returns: Lessons from emerging markets. The Review of Financial Studies, 20(6):1783–1831, 2007.
97. G. Bekaert, C. R. Harvey, and C. T. Lundblad. The dynamics of emerging market equity flows. Journal of International Money and Finance, 22(3):295–350, 2003.
98. G. Bekaert, C. R. Harvey, and C. T. Lundblad. The effect of U.S. monetary policy on emerging market equity returns. Journal of Banking & Finance, 37(12):5077–5094, 2013.
99. G. Bekaert, C. R. Harvey, and C. T. Lundblad. The political risk premium. Journal of International Money and Finance, 30(6):1031–1057, 2011.
100. G. Bekaert, C. R. Harvey, and C. T. Lundblad. What segments equity markets? Financial Analysts Journal, 63(4):58–74, 2007.
101. G. Bekaert, C. R. Harvey, and C. T. Lundblad. World market integration. Journal of Financial Economics, 75(2):233–248, 2005.
102. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Does financial liberalization spur growth? Journal of Financial Economics, 77(1):3–55, 2005.
103. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Emerging equity market volatility. Journal of Financial Economics, 88(3):595–629, 2008.
104. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Global growth opportunities and market integration. The Journal of Finance, 62(3):1081–1137, 2007.
105. G. Bekaert, C. R. Harvey, and C. T. Lundblad. Liquidity and expected returns: Lessons from emerging markets. The Review of Financial Studies, 20(6):1783–1831, 2007.
106. G. Bekaert, C. R. Harvey, and C. T. Lundblad. The dynamics of emerging market equity flows. Journal of International Money and Finance, 22(3):295–350, 2003.
107. G. Bekaert, C. R. Harvey, and C. T. Lundblad. The effect of U.S. monetary policy on emerging market equity returns. Journal of Banking & Finance, 37(12):5077–5094, 2013.
108. G. Bekaert, C. R. Harvey, and C. T. Lundblad. The political risk premium. Journal of International Money and Finance, 30(6):1031–1057, 2011.
109. G. Bekaert, C. R. Harvey, and C. T. Lundblad. What segments equity markets? Financial Analysts Journal, 63(4):58–74, 2007.
110. G. Bekaert, C. R. Harvey, and C. T. Lundblad. World market integration. Journal of Financial Economics, 75(2):233–248, 2005.
... (The list of references continues for several pages)
193. L. Harris. Trading and Exchanges, Market Microstructure for Practitioners. Oxford University Press, 2003.
194. A. C. Harvey. Forecasting, Structural Time Series Models and the Kalman Filter. Cambridge University Press, 1989.
195. A. C. Harvey and N. Shephard. Estimation of an asymmetric stochastic volatility model for asset returns. Journal of Business & Economic Statistics, 14(4):429–434, 1996.
196. C. R. Harvey and A. Siddique. Autoregressive conditional skewness. Journal of Financial and Quantitative Analysis, 34(4):465–487, 1999.
197. C. R. Harvey and Y. Liu. Lucky factors. Working paper, 2018.
198. C. R. Harvey, Y. Liu, and H. Zhu. ...and the cross-section of expected returns. The Review of Financial Studies, 29(1):5–68, 2016.
199. J. Hasbrouck. Empirical Market Microstructure. Oxford University Press, 2007.
200. R. Haugen and N. Baker. Commonality in the determinants of expected stock returns. Journal of Financial Economics, 41(3):401–439, 1996.
201. R. A. Haugen. The Inefficient Stock Market: What Pays Off and Why. Prentice Hall, 1999.
202. R. A. Haugen and J. M. Lakonishok. The Incredible January Effect: The Stock Market’s Unsolved Mystery. Dow Jones-Irwin, 1988.
203. C. He and T. Teräsvirta. Fourth moment structure of the GARCH(p, q) process. Econometric Theory, 12(5):851–866, 1996.
204. L. Heston and S. Nandi. A closed-form GARCH option pricing model. The Review of Financial Studies, 13(3):585–625, 2000.
205. L. Heston and K. G. Rouwenhorst. Industry and country effects in international stock returns. The Journal of Portfolio Management, 21(3):53–58, 1995.
206. P. R. Hsin and C. R. Johnson. Matrix Analysis. Cambridge University Press, 2nd edition, 2013.
207. K. Hou, C. Xue, and L. Zhang. Replicating anomalies. Review of Financial Studies, 33(5):2019–2133, 2020.
208. C. M. Huang and R. H. Litzenberger. Foundations for Financial Economics. Prentice Hall, 1988.
209. D. W. K. H. Huang, F. T. Serman, and R. A. Lempicki. Bioinformatics enrichment tools: Paths toward the comprehensive functional analysis of large gene sets. Nucleic Acids Research, 37(1):1–13, 2009.
210. J. Huberman and W. Stanzl. Price manipulation and quasi-arbitrage. Econometrica, 72(4):1247–1275, 2004.
211. R. Hyndman, A. B. Koehler, J. K. Ord, and R. D. Snyder. Forecasting with Exponential Smoothing: The State Space Approach. Springer, 2008.
212. J. P. Im, J. Park, and C. K. Kim. Why most published research findings are false. PLOS Medicine, 12(8):1–11, 2015.
213. M. Isichenko. Quantitative Portfolio Management. Wiley, 2021.
214. M. Jacobs. What explains the dynamics of 100 anomalies? Journal of Banking and Finance, 92:65–85, 2018.
215. R. Jagannathan and Z. Ma. Risk reduction in large portfolios: Why imposing the wrong constraints helps. Journal of Finance, 58(4):1651–1683, 2003.
216. N. Jegadeesh. Evidence of predictable behavior of security returns. Journal of Finance, 45(3):881–898, 1990.
217. N. Jegadeesh. Seasonality in stock price (and underlying earnings) data. Journal of Financial and Quantitative Analysis, 24(4):431–449, 1989.
218. N. Jegadeesh and S. Titman. Returns to buying winners and selling losers: Implications for stock market efficiency. Journal of Finance, 48(1):65–91, 1993.
219. N. Jegadeesh and S. Titman. Momentum. Annual Review of Financial Economics, 3(1):493–509, 2011.
220. H. Jiang, A. Habib, and M. M. Hasan. Short selling: A review of the literature and implications for future research. European Accounting Review, 27(4):753–779, 2018.
221. A. Johnson and D. W. Wichern. Applied Multivariate Statistical Analysis. Pearson, 6th edition, 2007.
222. D. J. Johnstone and J. H. Pedersen. Is there a replication crisis in finance? Journal of Finance, 77(3):1493–1528, 2022.
223. I. M. Johnstone. On the distribution of the largest eigenvalue in principal components analysis. Annals of Statistics, 29(2):295–327, 2001.
224. I. M. Johnstone and D. Paul. PCA in high dimensions: An orientation. Proceedings of the IEEE, 97(8):1277–1292, 2009.
225. J. P. Kahan, E. E. C. van de Riet, S. C. M. van der Veeke, S. M. van der Sluijs-Gelling, and J. H. M. de Vries. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences, 374(2080):20160002, 2016.
226. R. E. Kalman. A new approach to linear filtering and prediction problems. Journal of Basic Engineering, 82(1):35–45, 1960.
227. G. Karni. Bounds on the expectation of the maximum of samples from a given distribution. Journal of Applied Probability, 20(4):868–875, 1983.
228. K. S. Kedia. Random difference equations and interval theory for products of random matrices. Acta Mathematica, 137:207–248, 1975.
229. A. Kyle. Continuous auctions and insider trading. Econometrica, 53(6):1315–1335, 1985.
230. O. Ledoit and M. Wolf. Improved estimation of the covariance matrix of stock returns with an application to portfolio selection. Journal of Empirical Finance, 10:603–621, 2003a.
231. O. Ledoit and M. Wolf. Honey, I shrunk the sample covariance matrix. Journal of Portfolio Management, 30(4):110–119, 2004a.
232. O. Ledoit and M. Wolf. A well-conditioned estimator for large-dimensional covariance matrices. Journal of Multivariate Analysis, 88(2):365–411, 2004b.
233. O. Ledoit and M. Wolf. Nonlinear shrinkage estimation of large-dimensional covariance matrices. Annals of Statistics, 48(5):2654–2680, 2020.
234. O. Ledoit and M. Wolf. Spectrum estimation: a unified framework for covariance matrix estimation and PCA in large dimensions. Journal of Multivariate Analysis, 139:389–410, 2015.
235. O. Ledoit and M. Wolf. Analytical nonlinear shrinkage of large-dimensional covariance matrices. Annals of Statistics, 48(5):2681–2705, 2020.
236. R. N. Lehmann. Fads, martingales and market efficiency. Quarterly Journal of Economics, 105(1):1–28, 1990.
237. S. Li. Should passive investors actively manage their trades?, 2021. URL https://ssrn.com/abstract=3799781.
238. S. Li, N. Sullivan, and L. Garcia-Feijoo. The cross-sectionally ‘Anomalous’ Returns of Idiosyncratic Risk vs. Volatility in Financial Analysis. Journal of Investing, 31(1):36–42, 2016.
239. A. M. Lindner. Stationary, mixing, distributional properties and moments of GARCH(p,q)-processes. In T. G. Andersen, R. A. Davis, J. P. Kreiss, and T. Mikosch, editors, Handbook of Financial Time Series, pages 43–69. Springer, 2009.
240. R. Litterman and J. Scheinkman. Common factors affecting bond returns. The Journal of Fixed Income, 1(1):54–61, 1991.
241. R. Litterman and K. Winkelmann. Does anything beat 1-minute vol? Journal of Portfolio Management, 22(4):129–137, 1996.
242. A. W. Lo. The statistics of Sharpe ratios. Financial Analysts Journal, 58(4):36–52, 2002.
243. A. W. Lo. Hedge Funds: An Analytic Perspective. Princeton University Press, 2008.
244. D. Luenberger. Optimization by Vector Space Methods. Wiley, 1969.
245. D. G. Luenberger and Y. Ye. Linear and Nonlinear Programming. Springer, 3rd edition, 2008.
246. A. C. MacKinlay. Multifactor models do not explain deviations from CAPM. Journal of Financial Economics, 38(1):3–28, 1995.
247. L. C. MacLean, W. T. Ziemba, and G. Blazenko. Growth versus security in dynamic investment analysis. Management Science, 37(11):1580–1585, 1991.
248. L. C. MacLean, E. O. Thorp, and W. T. Ziemba. Good and bad properties of the Kelly criterion. In L. C. MacLean, E. O. Thorp, and W. T. Ziemba, editors, The Kelly Capital Growth Investment Criterion, pages 359–374. World Scientific, 2011.
249. L. C. MacLean, E. O. Thorp, and W. T. Ziemba, editors. The Kelly Capital Growth Investment Criterion. World Scientific, 2011.
250. S. Mallat. The New Palgrave Dictionary of Economics, chapter Efficient Market Hypothesis, pages 1–7. Palgrave Macmillan, 2018.
251. J. Marcinkiewicz and A. Zygmund. Sur les fonctions indépendantes. Fundamenta Mathematicae, 29(1):60–90, 1937.
252. I. Marusza. On the convergence of the threshold estimator of integrated variance. Stochastic Processes and their Applications, 126(9):2647–2659, 2016.
253. H. M. Markowitz. Portfolio Selection. Journal of Finance, 7(1):77–91, 1952.
254. H. M. Markowitz. Portfolio Selection: Efficient Diversification of Investments. Blackwell, 2nd edition, 1991.
255. J. Masreliez, L. Eder, and J.-P. Bouchaud. Trading. Risk, July 2017.
256. R. O. Merton and P. A. Samuelson. Fallacy of the log-normal approximation to optimal portfolio decision-making over many periods. Journal of Financial Economics, 1(1):67–94, 1974.
257. R. C. Micu and M. P. Pálfi. Does academic research destroy stock return predictability? Journal of Finance, 67(1):57–93, 2012.
258. S. Mittnik, M. S. Paolella, and S. T. Rachev. Diagnosing and treating the fat tails in financial returns data. Journal of Empirical Finance, 7(3–4):389–416, 2000.
259. S. Mittnik, M. S. Paolella, and S. T. Rachev. Stationarity of GARCH processes: A survey. Statistical Papers, 40(2):111–155, 1999.
260. S. Mittnik, M. S. Paolella, and S. T. Rachev. Unconditional and conditional distributional models for asset returns. In S. Rachev, editor, Handbook of Heavy Tailed Distributions in Finance, chapter 1, pages 1–68. Elsevier, 2003.
261. J. L. Morales Marcén, J. L. Morales Quirós, and J. L. Miralles. The role of country and industry factors during volatile times. Journal of International Financial Markets, Institutions and Money, 27:259–279, 2013.
262. J. L. Morales Marcén. Mean-variance gauge functions. The Quarterly Journal of Mathematics, 71(1):35–59, 2020.
263. M. Mitchell, L. H. Pedersen, and T. Pulvino. Slow moving capital. American Economic Review, 97(5):215–220, 2007.
264. M. J. I. Jordan. Graphical models. Statistical Science, 19(1):140–155, 2004.
265. M. Mohri, A. Rostamizadeh, and A. Talwalkar. Foundations of Machine Learning. MIT Press, 2012.
266. J. F. Muth. Optimal properties of exponentially weighted forecasts. Journal of the American Statistical Association, 55(290):299–306, 1960.
267. K. R. Nayak. Black Box. Wiley, 3rd edition, 2014.
268. M. W. Nelson. Is the difference in the GARCH(1,1) model. Economic Theory, 6:188–192, 1990.
269. W. K. Newey and K. D. West. A simple, positive semi-definite, heteroskedasticity and autocorrelation consistent covariance matrix. Econometrica, 55(3):703–708, 1987.
270. S. Niu. Stock return comovements: Does the market index matter? https://www.blackrock.com/corporate/literature/whitepaper/blackrock-viewpoint-2017.
271. R. Novy-Marx. The other side of value: The gross profitability premium. Journal of Financial Economics, 108(1):1–28, 2013.
272. A. Obizhaeva and J. Wang. Optimal trading strategy and supply/demand dynamics. Journal of Financial Markets, 16(1):1–32, 2013.
273. A. V. Olsson-Yaola and V. DeMiguel. Technical note—a robust perspective on transaction costs in portfolio optimization. Operations Research, 68(2):579–590, 2020.
274. P. Onatski. Determining the number of factors from empirical distributions of eigenvalues. Review of Economics and Statistics, 87(4):1004–1016, 2005.
275. S. C. Park. Science Collaboration: Estimating the reproducibility of psychological science. Science, 349(6251):aac4716, 2015.
276. D. P. Palomar. Portfolio Optimization. Cambridge University Press, Wiley and Berlin, 2020.
277. R. Paolino. The Evaluation and Optimisation of Trading Strategies. Wiley, 2014.
278. A. J. Patton. Volatility forecast comparison using imperfect volatility proxies. Journal of Econometrics, 160:246–256, 2011.
279. A. J. Patton and K. Sheppard. Evaluating volatility and correlation forecasts. In T. G. Andersen, R. A. Davis, J. P. Kreiss, and T. Mikosch, editors, Handbook of Financial Time Series, pages 801–838. Springer, 2009.
280. D. Paul. Asymptotics of the leading sample eigenvalues for a spiked covariance model. Statistica Sinica, 17:1617–1642, 2007.
281. S. E. Pia. The Sharpey Ratio. Chapman & Hall/CRC, 2013.
282. J. H. Pedersen. Efficiently Inefficient: How Smart Money Invests and Market Prices Are Determined. Princeton University Press, 2015.
283. J. H. Pedersen. Financial Markets in a New Era. Wiley, 2021.
284. M. Podolskij and M. Vetter. Bipower type estimation in a noisy diffusion setting. Stochastic Processes and their Applications, 119(9):2803–2827, 2009.
285. M. Pohl, A. Ristig, M. Schienle, and C. Tungs. The amazing power of beta-portfolios: Quantifying market impact. Market Microstructure and Liquidity, 1(01), 1550001, 2015.
286. M. Potters. Conditional Covariance Estimation. Wiley, 2013.
287. A. V. Putilin, D. Sadeh, and M. Davis. Sources of return in global equity portfolio management. Journal of Portfolio Management, 32(2):12–21, 2005.
288. L. B. Pulley. A general mean-variance approximation to expected utility for short holding periods. The Journal of Financial and Quantitative Analysis, 16(3):361–373, 1981.
289. E. J. Qian, R. H. Hua, and E. H. Sorensen. Quantitative Equity Portfolio Management. Chapman & Hall/CRC, 2007.
290. E. J. Qian, R. H. Hua, M. T. Koehler, and E. H. Tiu. Revisiting stylized facts for modern stock markets, 2013.
291. A. C. Rencher and W. F. Christensen. Methods of Multivariate Analysis. Wiley, 2012.
292. C. P. Robert, G. Celeux, and E. Benveniste. Optimal turnover, liquidity and auto-correlation. 2020.
293. C. P. Robert. The Bayesian Choice. Springer, 2nd edition, 2007.
294. R. Roll. A simple implicit measure of the effective bid-ask spread in an efficient market. Journal of Finance, 39(4):1127–1139, 1984.
295. P. Rosenbaum and M. Wolf. Optimal inference for the correlation in a bivariate normal setting. Econometrica, 71(4):1327–1382, 2003.
296. S. A. Ross. The arbitrage theory of capital asset pricing. Journal of Economic Theory, 13(3):341–360, 1976.
297. S. A. Ross. An introduction to Probability Models. Academic Press, 11th edition, 2014.
298. D. Ruppert and D. S. Matteson. Statistics and Data Analysis for Financial Engineering. Springer, 2nd edition, 2015.
299. A. Saxena and S. Stubbs. The alpha alignment factor: A solution to the unconstrained risk in optimized active portfolios. Journal of Risk, 15(2):3–26, 2012.
300. M. Scholes and J. Williams. Estimating betas from nonsynchronous data. Journal of Financial Economics, 5(3):309–327, 1977.
301. SEC. Form PF: Information required of institutional investment managers. 2011. Available at https://www.sec.gov/rules/final/2011/ia-3308.pdf.
302. W. F. Sharpe. Capital asset prices: A theory of market equilibrium under conditions of risk. Journal of Finance, 19(3):425–442, 1964.
303. W. F. Sharpe. Adjusting for risk in portfolio performance measurement. Journal of Portfolio Management, 1(2):29–34, 1975.
304. W. F. Sharpe. The Sharpe ratio. Journal of Portfolio Management, 21(1):49–58, 1994.
305. W. F. Sharpe. Equilibrium in a capital asset market. Econometrica, 34(1):13R–28R, 1966.
306. D. Shen, H. Shen, M. Zhu, and J. S. Marron. The statistics and mathematics of high dimension low sample size asymptotics. Statistica Sinica, 25(3):853–879, 2015.
307. R. C. Shephard. Second order risk, 2018.
308. R. H. Shumway and D. S. Stoffer. Time Series Analysis and Its Applications. Springer, 2011.
309. J. P. Simonsen and D. O. Nielsen. G-VaR Demystified. Life after plucking. Working paper presented at the 10th Annual Meeting of the Society for Personality and Social Psychology, New Orleans, LA, 2013.
310. D. Simon. Optimal State Estimation: Kalman, H∞, and Nonlinear Approaches. Wiley, 2006.
311. S. Singh. Bayesian Data Analysis. Oxford University Press, 2014.
312. S. Smale. Understanding Complex Datasets: Data Mining with Matrix Decompositions. Chapman & Hall/CRC, 2007.
313. W. Stevens. The Collected Poems. Vintage, 1990.
314. C. Strang. Linear Algebra and Learning from Data. Wellesley - Cambridge Press, 2019.
315. S. Stubbs and P. Vance. Computing return attribution error matrices for robust optimization. Technical Report 7, Axioma Research Paper, 2015.
316. S. Suzuki. Statistical, Algorithmic, Latent Dirichlet Allocation. 2016.
317. S. Suzuki, M. C. Hutter, W. H. Lumsdaine, M. R. Botev, editor. See also [299]. The Journal of Portfolio Management, 37(2):11–22, 2010.
318. W. Szymborska. Map: Collected and Last Poems. Ecco, 2016.
319. S. J. Taylor. Modelling Financial Time Series. Wiley, 1986.
320. S. J. Taylor. Asset Price Dynamics, Volatility, and Prediction. Princeton University Press, 2005.
321. Terran. An introduction to univariate GARCH models. In T. G. Andersen, R. A. Davis, J.-P. Kreiss, and T. Mikosch, editors, Handbook of Financial Time Series, pages 17–33. Springer, 2009a.
322. Terran. Multivariate GARCH models. In T. G. Andersen, R. A. Davis, J.-P. Kreiss, and T. Mikosch, editors, Handbook of Financial Time Series. Springer, 2009b.
323. E. O. Thorp. The Kelly criterion in blackjack sports betting, and the stock market. In S. A. Zen
Okay, here is the continuation of the Markdown compilation, covering the rest of the References and the complete Index.
     ... (References continued from previous response)
Banking and Finance, 37(B):3018–3034, 2013.
324. K. van Handel. Probability in High Dimension. Technical report, 2016.
325. K. van Handel. Universality of the local spectral statistics of random matrices. Annals of Probability, 45(3):1449–1528, 2017.
326. R. Velu, M. Hardy, and D. Nehren. Algorithmic Trading and Quantitative Strategies. CRC Press, 2020.
327. R. Vershynin. High-Dimensional Probability. Cambridge University Press, 2018.
328. G. Wahba. A least squares estimate of satellite attitude. SIAM Review, 7(3):409, 1965.
329. S. Wang, T. Lin, M. A. Alvarez, J. Jossa, A. Wang, and C. Bohal. Seven sins of quantitative investing. Technical Report, Deutsche Bank, 2017.
330. M. Wang and J. Yao. Asymptotics of variance estimators for high dimensional spiked covariance. Annals of Statistics, 45(3):1242–1274, 2017.
331. L. T. Wasserman. All of Statistics. Springer, 2004.
332. T. T. Webster. Handbook of Price Impact Modeling. Chapman & Hall/CRC, 2015.
333. P. Whittle. Optimal Control: Basics and Beyond. Wiley, 1996.
334. T. West. Momentum: What do we know 20 years after Jegadeesh and Titman’s seminal paper? Financial Markets and Portfolio Management, 27:111–142, 2013.
335. S. Zheng and Z. Zhu. Large Sample Covariance Matrices and High-Dimensional Data Analysis. Cambridge University Press, 2015.
336. L. Zuck. The Handbook of Equity Market Anomalies. Wiley, 2011.
337. L. Zuck, P. A. Mykland, and Y. Aït-Sahalia. A tale of two time scales: Determining integrated volatility with noisy high-frequency data. Journal of the American Statistical Association, 100(472):1394–1411, 2005.
338. E. Zivot. Practical issues in the analysis of univariate GARCH models. In T. G. Andersen, R. A. Davis, J.-P. Kreiss, and T. Mikosch, editors, Handbook of Financial Time Series, pages 113–155. Springer, 2009.
339. E. Zivot and J. Wang. Modeling Financial Time Series with S-Plus. Springer, 2007.

---

**Index**

Adjusted Dollar [14]
Bias Statistic [6]
Black-Litterman [16]
Bloomberg [21]
Bonds [7]
Book-to-Price Ratio [21]
Borrowing Costs [18]
Broker-Dealers [7]
Brownian Process [102]
Buy Side [6, 7]

**A**
ACF *See*Autocorrelation
Active Managers [12]
ADR [10]
Aggregate Comovement [19, 20]
Akaike Information Criterion (AIC) [22]
Alpha [5, 6, 80]
Intraday [10]
Orthogonal [14, 16, 215, 216, 222]
Risk Model [10]
Alternative Trading System [211]
American Depositary Receipt *See*ADR
Amibud’s Liquidity Measure [21]
Announcement Date [22]
Arbitrageurs [7]
Assets Under Management [12]
AUM *See*Assets Under Management
Autocorrelation [20]
Absolute unavoidable returns [17]
Univariate Returns [16]

**B**
Backtesting
Cross-Validation [202, 211]
Protocol [2]
Roll-Back and-Settle (against backtesting lines) [202]
Walk-Forward [1]
Bayesian Information Criterion [20]
Beginners’ Mind [1]
Benchmark [202]
Beta [7]
Betas

**C**
CA *See*Clearing Auction
Cancel-and-Requote [7]
Capital Adequacy Model [16]
CAPM *See*Capital Asset Pricing Model
Capital Asset Pricing Model [16]
Cash Equivalents [22]
CDS *See*Credit Default Swaps
Central Limit Theorem [18, 20]
Characteristics [16]
Child Order [211]
ChRM *See*Conditional Heteroscedastic Models
Clearing
Clearing Auction [7]
Client Inform [12]
Closing Auction [7]
Clustering
K-Means [19]
Coefficient of Determination [202, 242]
Condition Number of a Matrix [16]
Conditional Heteroscedastic Models [20]
Constraint
on Penalties [21]
on Turnover [17]
Long-Only [22]
Market Beta [7, 8]
Non-Convex [211]
on Factor exposures [17]
on Holding Period [17]
on the Number of Assets [21]
on Volatility [224]
Portfolio Turnover [16]
Pricing *See*CAE [211]
Quality of Execution [17]
Tracking Error [16]
Consumer Price Index [16]
Correlation
Cross-Sectional [17]
Covariance Similarity, *see*Idly [201, 202, 221]
Covariance Matrix [16]
Autocorrelation Correction [14]
Empirical [20]
Factor [17]
Cross Market Impact [187]
Cross-Sectional Empirical Average [14]
Cross-Sectional Empirical Covariance [154]
Cross Validation [187]
Currency
Quote [16]

**D**
Dark Pools [7]
Data
Categorical [17]
Structured [7]
Unstructured [7]
Data Leakage [202, 204]
Dataset
Training [202, 204]
Validation [202]
Dealers [7]
Inventory [7]
Dealweek [7]
Degrees of Freedom [202]
Deming’s Funnel [1]
Determinant Lemma [14]
Dimensional Analysis [21]
Dina’s Delta Function [179]
Diversification [20]
Dividend [16]
Dual Traders *See*Broker-Dealers
Dummy Variables [1]

**E**
Efficient Market [1]
Eigenfunctions [15, 17, 20–22, 174, 175, 225, 229]
Eigenvalues [16]
Bulk [17]
Concentration [16]
Spike [17]
Eigenvectors [20, 21, 152, 153, 170, 171, 174, 180, 181]
Equity [7]
Estimation Universe [128, 129]
ETF *See*Exchange-Traded Funds
EWMA *See*Exponentially Weighted Moving Average
Exchange Rate [17]
Exchange-Traded Funds [7]
Exchanges [7]
Exponentially Weighted Moving Average [22]
Exposure
to Factors [17]
to Systematic Risk [17]

**F**
Factor
Betting Against Beta [143]
Book-to-Price [143]
Carry [17]
Crowding [17]
Intercept [17]
Liquidity [143]
Low Volatility [143]
Momentum [143]
Orthogonal [17]
Quality [143]
Return Skewness [144]
Reversal [14]
Returns [143]
Sentiment [144]
Unpriced [202]
Value [143]
Volatility [14]
Factor Model [14]
Approximation [1]
as. Decomposition of loadings [17]
Characteristics [17]
Currency Rebasing [128]
Definition [14]
Factors [17]
Graphical Model [14]
Idiosyncratic Component [1]
Interpretations [14, 17]
Linking Local Models [17]
Local [17]
Macroeconomic [1]
Nested [17]
Projection [14, 17]
Push-Out [14, 17]
Rotation [14, 17, 202]
Shrinkage [17]
Statistical Arbitrage [7]
Statistical vs. risk [147]
Strict [1]
Systematic Component [1]
Time-Varying Loadings [14]
Uses [14]
False Discovery Rate [202]
FDR *See*False Discovery Rate
Fed Funds Under New Conditions [128]
Flow predictability [7]
FOMC *See*Fed Funds Under New Conditions
Fractional Kelly Strategy [167, 167]
Fraud-Resistant Backtest [202]
Fundamental Law of Active Management [211]
Futures [7]

**G**
GARCH Models [17–19, 34]
GDR [10]
General Autoregressive Conditional Heteroskedastic *See*GARCH Models
General Factors [17]
Generalized Least Squares [202]
GMV *See*Gross Market Value
Graphical model [14]
Gross Market Value [17]
Grossman-Chiu Strategy [157, 157]

**H**
Hat Matrix [87]
Heavy Tails [17]
Hedge Funds [7]
Hedging [17]
Herfindahl-Hirschman Index [20]
Heteroskedastic noise [7]
HFT *See*High-Frequency Trader
HHG *See*HHI, SVHT, LEONI [157, 157]
High-Frequency Trader [7]
History [202]

**I**
IC *See*Information Coefficient
Idempotent Operator [14]
Idiosyncratic Variant [14, 17, 20]
iid vs. iinid
iinid [14]
Rebalancing [14]
Reconstitution [14]
Index Huggers [7]
Index Providers [7]
Indices [7]
Information Coefficient [157, 159, 160, 202, 204, 211]
Information Ratio [14, 17, 147, 148, 211]
Empirical [14]
Information Set [14]
Interest Rate Swaps [7]
IRS *See*Interest Rate Swaps
IS [14]

**K**
Kalman Filter [17, 45, 46]
Optimal Gain [14]
Kelly criterion [224, 224, 224]
Kolmogorov-Smirnov distance [34]

**L**
Lagrange Multiplier [21]
Leverage [14]
Leverage Effect [14]
Likelihood [14]
Limit Order Book [7, 211]
Limited Partners [7]
Linear Regression [14, 214]
Linear Transformation [14]
Decomposition [14]
Features [7]
Frobenius-Weighted Least Squares *See*Frobenius-Weighted Theorem
Model Design [14]
Linear State Space Models [17, 43, 44]
Liquidity [14]
Liquidity Provisioning [7]
Liquidity Spreads [14]
Log-Likelihood [14]
Definition [14]
Orthonormal [14]
Z-scored [22]
Learning [1]
LOB *See*Limit Order Book

**M**
Mahalanobis distance [202]
Market Efficiency [1]
Market Impact [7, 177]
Market Makers [7]
Market Orders [7]
Marketable Order [211]
Markowitz’s Method [14]
Maximum Likelihood Estimator [14, 16]
Meta-Order *See*Parent Order
MFRD [1]
MLE *See*Maximum Likelihood Estimator
Moore-Penrose Pseudo Inverse [202,211]
MSE Statistic [16, 17]

**N**
Net Market Value [7]
Net Market Value (NMV) [17]
Net Market Value
NMV *See*Net Market Value
Newey-West Estimator [224, 224]
Noise [14]
p-Norm, w≥0
Operator, w≥0 [14]
Strictly Invariant [14]
Numeraires [14]

**O**
Optimization
Mean-Distance [111, 112, 202, 211, 212, 217, 221, 224, 226, 231, 254, 257]
Orthogonal Complement [14]
Orthogonal Projection [14]
OTC *See*Over-the-Counter
Over-the-Counter [7, 211]

**P**
Parent Order [211]
Partial Correlation [202]
Participation Rate [211]
Passive Investing [14]
Payment for Order Flow [7, 12]
PCA *See*Principal Components Analysis
P-Means
Probabilistic [20]
Penalty
1-Norm [21]
2-Norm [21]
Performance Attribution [14, 17, 20, 22, 102]
Characteristics [17]
Maximal [14]
Portfolio [14]
Selection Sizing [147]
Time Series [20]
Permanent Market Impact [211]
PFOF *See*Payment for Order Flow
Pick
Factor [14, 17]
Idiosyncratic [17]
Position [17]
Trading [211]
Portfolio
Basis [17]
Characteristic [17]
Construction [17, 21, 24]
Liquidity [17]
Mean-Monitoring [17, 202, 204, 207–209, 211–213, 215–217, 247]
Market [17]
Mean-Variance [17, 202]
Penalties [202, 211]
Production [17]
Thematic [17]
Portfolio Management [7, 80, 202, 204, 207, 211, 217]
POV *See*Participation Rate
Precision Matrix [14, 221]
Price
Ask [7]
Bid [7]
Proprietary [7, 211]
Prior Manipulation [7]
Principal Component [202, 211]
Principal Component Analysis [202, 211]
Principal Components Analysis [14, 17, 20, 152, 153, 170–172, 174, 175, 229]
Private Trading Floor [7]
Probability PCA [14, 20]
Product
Scalar, w≥0
Projection [14]
Projection Matrix [14]
Projections [14]
Publicly Available Information [14]

**Q**
QUBE Statistic [211]
Quasi-Likelihood *See*QUBE Statistic

**R**
R-Squared *See*Coefficient of Determination
Rademacher Complexity [1]
Random Recursive Equations [14, 17]
Random Variables
Heavy Tailed [17, 20, 34]
Independent [14]
Rank One [14]
Reconstitution Date [17]
Regression [17]
Cross-Sectional [17]
Ordinary Least Squares [17]
Ridge [17]
Stepwise [17]
Weighted Least Squares [17, 20, 21]
Returns [17, 20, 34]
Compounded [21]
Continuously Adjusted [14]
Cross-Sectional [14, 17, 20]
Idiosyncratic [14, 17, 20, 80]
Logarithmic [20]
Risk-Free [17, 20, 24]
Specific [17]
Stylized Facts [17]
Ricatti Equations
Discrete Time Algebraic [43]
Variance Formula [43]
Risk [14, 17]
Marginal Contribution [1]
Risk Management [14, 17, 20, 80, 83]
Risk Model [14]
Integrated [20]
Risk-Free Rate [43]
RREs *See*Random Recursive Equations
Russell [202]

**S**
Scalar Product [21]
Screen plot [21]
Second Oversight Financing Rate [1, 2]
Securities [7]
Sell Side [7]
Sentiment [7]
Shadow Price [202, 211]
Sharpe Ratio [14, 17, 20, 102, 103, 127, 128, 202, 204, 207, 211]
Shrinkage [17, 20, 224]
Confidence Interval [1]
Dimension [1]
Efficiency (SRE) [221]
Sensitivity [1]
Side Interest [1]
Short-Term Rate Updating [20]
Short-Term Volatility Updating [20]
Shrinkage [17, 20, 222, 223, 225, 247, 262–270]
Ledoit-Wolfe [223, 224]
Signal [17]
Singular Value Decomposition [14, 17, 20, 152, 153]
Singular Values [20]
Skill
Selection [147]
S&P 500 Index Lock [7]
SOFR *See*Second Oversight Financing Rate
Sort Beta [17]
Spiked Covariance Model [17]
Spread
Best Cost [211]
Square Root of a Matrix [17]
Stochastic Process
Non-Anticipative [21]
Strict Stationarity [20]
Strategy
191/209 [211]
Capacity [1]
Long-Only [17]
Short-Only [17]
Stochastic Discount Factor [SDF]
Sub-Gaussian Distribution [211]
Sub-Sampling [1]
Subspace
Column [21]
Similarity Between Two Subspaces [21]
Survivorship Bias [204]
SVD *See*Singular Value Decomposition

**T**
Tail
GARCH (1,1) Processes [34]
Kurtosis [34]
Tail Index [1]
Temporary Market Impact [211]
Time series [14]
Parking Error [21]
Trading [7]
Trading
Informational Effect [211]
Mimetic Effect [21]
Strategy [211]
Traffic Shaping [211]
Turnover [211]
Eigenvectors [21]
Hierarchical [21]
Linear [21]
Model [21]
Quadratic [21]

**U**
Unintended Bets [154]
Utility Theory [211]

**V**
Vanilla Options [7]
Variance [17]
Volatility [17]
At-Ask [7]
Clustering [17]
Decomposition [14]
Realized (RV) [7]
Short-Term Volatility Updating [222]

**W**
Wald’s Problem [21]
Winsorization [202, 222]
Wrong Sleep [1]
Winsorization [154, 202, 214]
Wirehouses *See*Broker-Dealers
Woodbury-Sherman-Morrison Lemma [144, 144, 202]
   


