**Chapter 15**
**A Coda ad Laborem**

It seems almost requisite to abruptly close a book with a chapter on performance attribution. In “The Return of the King,” the coda of the movie lasted 30 minutes, enough to make us forget the satisfying spectacle of Mordor’s fall. I promise this one will be shorter. This chapter summarizes the main themes in the book, by highlighting them. I hope to provide the quantitative investment strategy developer with some principles to inspire them in their daily endeavor.

1.  Use legible methods. With few exceptions, the mathematics used in the book is no more than 100 years old. The exceptions are Rademacher complexity, which dates back to the work of Vapnik and Chervonenkis in the early 1970s, and the spectral properties of spiked covariance matrices, which date back to the turn of the century. Using established methods makes the theory visible: at any time you know what is going on. Calculus speaks of visibility. Good math makes the invisible visible. What is visible can be communicated, inspected, critiqued, and improved.
2.  Use simple mathematical methods. Theory is cheap. You can make theory arbitrarily complicated. The hard part is to summon from the void the simplest tools that answer your question. Everything in the book is linear and quadratic. Don’t restrict yourself to these families; however, even if your problem does not show linear structure in a toy model, postulate that it will have it in a more complex one.
3.  Think deeply of simple things. Start with simple questions, possibly identifying them within a more complex system. And then solve them from first principles as much as you can. For example, do not make up measures of stock selection and sizing. Link performance metrics to the Sharpe Ratio. Or link factor modeling with risk decomposition of your space of strategies.
4.  Take errors into account from the start. “Certainty is beautiful, but uncertainty is more beautiful still.” All measurement has error. The entire edifice of optimization and error. However, errors propagate in portfolio optimization, in intertemporal volatility allocation, in backtesting. Modeling uncertainty from the start is sound theoretically and addresses the shortcomings of known methods, like mean-variance optimization.
5.  Derive answers from first principles. So many processes we have advocated resonate deeply with our everyday decision-making process. Exponential weighting, update what you learned so far by mixing with new evidence. Shrinkage: incorporate uncertainty by downweighting your estimate. Hierarchical models: combine information from complex decision. Decompose single-period one. Over and over, successful researchers are the ones that achieve principled simplicity.

**Notes**
1.  I am borrowing a verse from “Love at first sight,” a poem by W. Szymborska (Szymborska, 2015).

---

